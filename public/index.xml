<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Chatomics on Chatomics</title>
    <link>/</link>
    <description>Recent content in Chatomics on Chatomics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Ming &#39;Tommy&#39; Tang</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Biotech Data Strategy: Building a Scalable Foundation for Startups</title>
      <link>/post/biotech-data/</link>
      <pubDate>Fri, 03 Jan 2025 00:00:00 +0000</pubDate>
      
      <guid>/post/biotech-data/</guid>
      <description>&lt;p&gt;In a biotech startup, an early data strategy is key to ensure public and private data remain useful and valuable. As AI hype reaches new heights, I want to emphasize that a data strategy must precede any AI strategy.&lt;/p&gt;
&lt;p&gt;Data is the oil of the AI engine. Unfortunately, the real-world data are usually messy and not AI-ready. Without a robust data strategy, you are building an AI system on a shaky foundation.&lt;/p&gt;
&lt;p&gt;Below are the notes I collected from &lt;a href=&#34;https://www.linkedin.com/posts/daniel-dacey_lifesciences-biotech-pharma-activity-7257457684776472576-6Jpb&#34;&gt;an event&lt;/a&gt; I participated as a panelist.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/biotech_data.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I will cover essential strategy components from my personal experience working at a small biotech. I will cover:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;data governance,&lt;/li&gt;
&lt;li&gt;management,&lt;/li&gt;
&lt;li&gt;team collaboration,&lt;/li&gt;
&lt;li&gt;and the balance between custom and standard tools.&lt;/li&gt;
&lt;li&gt;Moreover, practical examples will show how these elements create a strong data foundation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data governance is essential as companies scale and transition data to the cloud. However, for a small startup, establishing good governance practices can feel overwhelming.&lt;/p&gt;
&lt;p&gt;Effective data governance should ensure integrity, compliance, and security from the outset. For example, when data shifts to the cloud, it’s crucial to define access, and set rules for documentation and security.&lt;/p&gt;
&lt;p&gt;Simple actions, like establishing access controls and basic security, can avert future issues. Moreover, ensuring data accuracy and consistency from the start is vital. This prevents problems as more data is added.&lt;/p&gt;
&lt;p&gt;In many startups, the bioinformatics or computational biology team also handles IT tasks. This can be tough. However, training from cloud providers like Google Cloud or AWS can ease the process.&lt;/p&gt;
&lt;p&gt;These vendors offer key training on security, compliance, and cloud management. This helps teams work better without needing IT expertise. Data security is crucial. Thus, vendor support is vital for small teams to meet compliance requirements more easily.&lt;/p&gt;
&lt;p&gt;Data management goes hand-in-hand with governance. Organizing and storing data in scalable ways is essential to avoid chaos as data volumes grow. A consistent folder structure on the cloud storage bucket is essential for scientists to navigate to find the right data efficiently.&lt;/p&gt;
&lt;p&gt;In addition, enforcing consistent metadata practices is as important. Data without metadata is like a library without labels—nearly impossible to navigate.&lt;/p&gt;
&lt;p&gt;Biotech startup data always starts with a spreadsheet until it is not manageable. To build a strong foundation, standardized data entry in spreadsheets is a good starting point.&lt;/p&gt;
&lt;p&gt;For instance, always use “Female” instead of “female” or “F”. Also, avoid spaces and special characters in column names. Educate wet lab scientists on best practices. This ensures consistency and reduces cleanup time later.&lt;/p&gt;
&lt;p&gt;Of course, there is ‘technical debt’ that might be incurred in the early stage. Startups are constantly under the pressure of raising the next round of funding and meeting deadlines.&lt;/p&gt;
&lt;p&gt;The initial data infrastructure can be scrappy. In five years, if some new hire complains about the data infrastructure, congratulations! You survived for five years!&lt;/p&gt;
&lt;p&gt;But it does not give you the excuse to follow some basic best practices.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;EVERYONE needs to read this article: &lt;a href=&#34;https://www.tandfonline.com/doi/full/10.1080/00031305.2017.1375989&#34;&gt;Data Organization in Spreadsheets&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Most biotech data originates from two sources: public datasets and in-house generated data. Public data is easy to access but often messy. It needs cleanup and metadata alignment to be useful. For instance, public datasets may have inconsistent metadata. It requires harmonization to make them useful for meta-analysis.&lt;/p&gt;
&lt;p&gt;In-house data, especially from high-throughput assays, is different. Early integration with a Laboratory Information Management System (LIMS) is beneficial. A LIMS tracks samples, experiments, and metadata as data grows. Starting with a LIMS can streamline workflows. Combining it with metadata alignment makes data ready for AI.&lt;/p&gt;
&lt;p&gt;Making data storage meet &lt;a href=&#34;https://www.go-fair.org/fair-principles/&#34;&gt;FAIR&lt;/a&gt; principles—Findable, Accessible, Interoperable, and Reusable—seems tough for small startups. Yet, adopting “Good-enough” practices can help.&lt;/p&gt;
&lt;p&gt;For instance, using a consistent cloud folder structure is a good start. Create main folders for “Internal Data” and “Public Data.” Then, add subfolders for data types like RNA-seq, WGS, ChIP-seq, and single-cell data.&lt;/p&gt;
&lt;p&gt;Each dataset needs a README file. This file should explain when and how the data was collected and link to preprocessing code. For example, linking to a GitHub repository with scripts helps future team members understand the data’s origins and changes.&lt;/p&gt;
&lt;p&gt;Startups often face challenges in balancing quick data analysis with making it reproducible. They frequently need to quickly answer questions from leaders or investors.&lt;/p&gt;
&lt;p&gt;In such cases, ensuring every analysis is perfectly reproducible isn’t always feasible. For example, a simple answer might suffice for an investor’s quick question, even if it’s not fully reproducible.&lt;/p&gt;
&lt;p&gt;This approach, however, leads to “technical debt.” Startups can address these shortcuts later if they succeed. For big projects, aiming for reproducibility is key. But, it’s okay to be flexible with exploratory work.&lt;/p&gt;
&lt;p&gt;I will talk about reproducibility for computing in a future blog post.&lt;/p&gt;
&lt;p&gt;Startups often face the choice between building custom tools and buying commercial ones. Custom tools offer flexibility but require significant time and resources. Meanwhile, off-the-shelf solutions save time and are often more reliable, provided they meet current needs.&lt;/p&gt;
&lt;p&gt;The decision should align with the startup’s vision, resources, and expected returns. For example, a tool that boosts reproducibility, ensures data consistency and allows the team to focus on complex analysis is a smart investment. It’s crucial to avoid burdening the team with too many platforms. Focus on those that offer clear, scalable benefits.&lt;/p&gt;
&lt;p&gt;As data infrastructure improves, the focus shifts from tools to people. An in-house team boosts collaboration between computational biologists and wet lab scientists. Data scientists, working with wet lab teams, offer quick analysis and feedback.&lt;/p&gt;
&lt;p&gt;I highly recommend bench scientists sit next to the computational scientists so they can communicate quickly.&lt;/p&gt;
&lt;p&gt;This collaboration sparks new insights and innovation. Constant communication helps both teams understand each other’s challenges. This leads to better experiments, deeper analysis, and faster discoveries.&lt;/p&gt;
&lt;p&gt;For instance, computational biologists can conduct initial single-cell analyses. They create Seurat or Scanpy objects for wet lab scientists. This allows wet lab scientists to explore data themselves using a GUI tool (&lt;a href=&#34;https://www.pythiabio.com/multiomics-analysis-software&#34;&gt;Pythia’s CDIAM platform&lt;/a&gt; is a good one, disclaimer, I am on their scientific advisory board) as a bridge to explore the objects.&lt;/p&gt;
&lt;p&gt;Furthermore, giving wet lab scientists access to their data on interactive platforms promotes independence. It allows them to perform basic analyses and generate ideas without always relying on the computational team.&lt;/p&gt;
&lt;p&gt;I firmly believe that giving the wet lab scientist the capability to explore their data helps form hypotheses. Meanwhile, the computational team can tackle more complex analyses.&lt;/p&gt;
&lt;p&gt;Data analysis in biotech aims to inform future research or development. Data scientists play an important role in decision-making.&lt;/p&gt;
&lt;p&gt;Usually, a computational biologist presents the findings in a slide deck. This includes conclusions from the current experiment, new experiment suggestions, and a GitHub link for code access. This approach provides clear guidance to the wet lab team. It also allows them to trace and repeat analyses when needed.&lt;/p&gt;
&lt;p&gt;Biotech startups may struggle to build a data strategy. Yet, focusing on governance, management, reproducibility, and collaboration can speed up R&amp;amp;D. This approach turns data into insights, guiding decisions and ensuring success in a competitive market.&lt;/p&gt;
&lt;div id=&#34;references-and-further-reading&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References and further reading:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/has-ai-changed-the-course-of-drug-development/&#34;&gt;Has AI changed the course of Drug Development?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://michelebusby.tumblr.com/&#34;&gt;So You Want to Start a Biotech: A Bioinformatics Approach That Works&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@jfeala/the-digital-biotech-startup-playbook-398aeafca8a4&#34;&gt;The digital biotech startup playbook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scalingbiotech.substack.com/p/data-and-metadata-beat-models&#34;&gt;Data (and metadata) beat models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.booleanbiotech.com/biotech-data-infrastructure.html&#34;&gt;Modern biotech data infrastructure&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Review 2024</title>
      <link>/post/review-2024/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      
      <guid>/post/review-2024/</guid>
      <description>&lt;p&gt;As 2024 wraps up, it’s the perfect time to reflect and prepare for the new year.
I wrote the review for 2023 &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/review-2023/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;goals-reached&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Goals reached&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;✅ I lost 12 lb in 6 weeks!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;✅ Supported the clinical trial to identify bio markers for potential responders to our drug at Immunitas. Helped with indication selection for the second and third program. I moved to Astrazeneca in August. I really appreciate my experience at Immunitas and learned a lot. Now I want to learn more at AstraZeneca!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;✅ Go to one conference that is not local. (I am spoiled to attend many conferences in Boston last year). I went to EMBL for &lt;a href=&#34;https://biont-training.eu/CarpentryConnect2024.html&#34; class=&#34;uri&#34;&gt;https://biont-training.eu/CarpentryConnect2024.html&lt;/a&gt; conference at Heidelberg, Germany. This is my first time traveling to Europe. Thanks again for the invitation!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;❌ I did not Host another AI for drug discovery conference in 2024. I co-organized this one in 2023.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;❌ I did not Finish this deep learning course &lt;a href=&#34;https://course.fast.ai/&#34; class=&#34;uri&#34;&gt;https://course.fast.ai/&lt;/a&gt;. This will be in 2025.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;✅ Take one more leadership training session. I took a &lt;a href=&#34;https://www.red10dev.com/&#34;&gt;Red10 leadership session&lt;/a&gt; for influence at AstraZeneca. It is a great program and I will post some notes on Saturdays.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;✅ Make at least one video a week; one blog post/tutorial (42 posts in 2024)every two weeks. 7.5K subscribers after 1.5 years! &lt;a href=&#34;https://www.youtube.com/@chatomics/videos&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/@chatomics/videos&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;✅ Post every day on Linkedin pre-scheduled with &lt;a href=&#34;http://buffer.com&#34; class=&#34;uri&#34;&gt;http://buffer.com&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;✅ Write 500 words every day. (either my learning from podcasts on my commute or any reading)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;✅ Read at least 12 books again! Some of them:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The Motive by Patrick Lencioni&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Trillion Dollar coach by Eric Schmidt, Jonathan Rosenberg and Alan Eagle.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Alchemist by Paulo Coelho.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The War of Art by Steven Pressfield&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Never split the difference by Chris Voss&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The pychology of Money by Morgan Housel&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tribes by Seth Godin&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tools of Titans by Tim Ferris&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Crossing the chasm by Geoffery Moore&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Zero to one by Peter Thiel&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Building reproducible analytical pipelines with R by Bruno Rodrigues&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Software engineering for Data scientists by Catherine Nelson&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;goals-in-2025&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Goals in 2025&lt;/h3&gt;
&lt;p&gt;New Year’s resolutions are popular, but how much have you achieved? Consistency is the key.&lt;/p&gt;
&lt;p&gt;Consistency transforms actions into results.&lt;/p&gt;
&lt;p&gt;When you prioritize your most important goal, break it down into daily tasks. Those consistent days turn into consistent weeks…&lt;/p&gt;
&lt;p&gt;Consistent weeks lead to consistent months.&lt;/p&gt;
&lt;p&gt;And consistent months create consistent years.&lt;/p&gt;
&lt;p&gt;All of that builds an epic life.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;For me, my technical skill goal is to finish the deep learning course on Fast.ai &lt;a href=&#34;https://course.fast.ai/&#34; class=&#34;uri&#34;&gt;https://course.fast.ai/&lt;/a&gt;. It was on my to-do last year, but I didn’t finish. Failure isn’t scary—it’s a chance to learn and keep moving forward.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;My goal for LinkedIn? Post long, high-quality content every day.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I batch schedule posts on Sundays:&lt;/p&gt;
&lt;p&gt;• Mon-Fri/Sunday: Bioinformatics (technical)&lt;/p&gt;
&lt;p&gt;• Sat: Leadership &amp;amp; management &amp;amp; life lessons&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;For self-improvement, I keep a daily reflection diary.It’s been 2 years, and my goal is to continue this habit every day. It helps me grow.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In management, my focus is building trust with my team. I aim to support their growth—both technically and with soft skills.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;At work, my single goal is to deliver portfolio support analysis on time and consistently drive the project to have novel biological insights.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Read another 12 books!&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I wish you all a prosperous 2025!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Cancer-specific innate and adaptive immune rewiring drives resistance to PD-1 blockade in classic Hodgkin lymphoma</title>
      <link>/publication/2024-12-30-scrnaseq-pd1/</link>
      <pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate>
      
      <guid>/publication/2024-12-30-scrnaseq-pd1/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Removing roadblocks to accessing single cell research</title>
      <link>/talk/2024-10x_roundtable/</link>
      <pubDate>Tue, 19 Nov 2024 11:00:00 +0000</pubDate>
      
      <guid>/talk/2024-10x_roundtable/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;/img/10x_roundtable.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Panel discussion: Coding and data science skills in industry</title>
      <link>/talk/2024-embl/</link>
      <pubDate>Mon, 11 Nov 2024 11:00:00 +0000</pubDate>
      
      <guid>/talk/2024-embl/</guid>
      <description>&lt;p&gt;I was invited to EMBL, Germany to participate the panel discussion for data science training
for industry.&lt;/p&gt;

&lt;p&gt;It was my first time to go to Europe. I enjoyed the trip a lot!&lt;/p&gt;

&lt;p&gt;I even met Dr.Wolfgang Huber in person!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/biont.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I regret not doing so</title>
      <link>/post/learn-linear-algebra/</link>
      <pubDate>Sun, 27 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/learn-linear-algebra/</guid>
      <description>&lt;p&gt;&lt;strong&gt;To not miss a post like this, sign up for my &lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/profile&#34;&gt;newsletter&lt;/a&gt; to learn computational
biology and bioinformatics.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;My regret is not learning linear algebra well during college.&lt;/p&gt;
&lt;p&gt;I barely passed the exam for it (and calculus, it was a nightmare :) ).&lt;/p&gt;
&lt;p&gt;To be fair..&lt;/p&gt;
&lt;p&gt;It was not taught well and it sounded too boring. I did not know what the application of matrix multiplication was, not until…&lt;/p&gt;
&lt;p&gt;Many years later, I started to learn bioinformatics. I find many data are just data matrices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;an RNAseq expression matrix is a gene-by-sample matrix, with entries to be read counts for each gene&lt;/li&gt;
&lt;li&gt;a single-cell expression matrix is a gene-by-cell matrix, with entries to be read counts for each gene&lt;/li&gt;
&lt;li&gt;a ChIP-seq count matrix is a peak-by-sample matrix, with entries to be the number of reads in each peak&lt;/li&gt;
&lt;li&gt;a drug response matrix is a drug-by-sample matrix, with entries to be IC50 for example&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and many more… in other words,&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Matrix is EVERYWHERE for bioinformatics (and many other data science topics)!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Many of the bioinformatics problems can be rephrased as matrix manipulation.&lt;/p&gt;
&lt;p&gt;Read this blog post on &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/matrix-factorization-for-single-cell-rnaseq-data/&#34;&gt;Matrix factorization on single-cell RNAseq data&lt;/a&gt; to see how useful it is!&lt;/p&gt;
&lt;p&gt;I have written two &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/cca-alignment/&#34;&gt;blog posts&lt;/a&gt; on how Seurat PCA projection/CCA alignment and label transfer work for single-cell RNAseq data in low-level details.&lt;/p&gt;
&lt;p&gt;Man, it was hard. I spent 8 hours for each post spanning serveral nights. But I enjoyed it as I also learned the topic deeper.&lt;/p&gt;
&lt;p&gt;During the writing of the posts, I really wished I learned linear algebra better during college:) but it is never too late to learn. You can take MIT1806, which is a great course for linear algebra.&lt;/p&gt;
&lt;p&gt;And I am re-watching &lt;a href=&#34;https://www.3blue1brown.com/lessons/eigenvalues&#34;&gt;eigenvalues and eigenvectors from 3blue1brown&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You know what? Deep learning is also closely related with matrix calculations, so understand it is definitely helpful.&lt;/p&gt;
&lt;p&gt;What’s your regret?&lt;/p&gt;
&lt;p&gt;Happy Learning!&lt;/p&gt;
&lt;p&gt;Tommy&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How CCA alignment and cell label transfer work in Seurat</title>
      <link>/post/cca-alignment/</link>
      <pubDate>Sat, 19 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/cca-alignment/</guid>
      <description>&lt;p&gt;&lt;strong&gt;To not miss a post like this, sign up for my &lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/profile&#34;&gt;newsletter&lt;/a&gt; to learn computational
biology and bioinformatics.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;understand-cca&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Understand CCA&lt;/h3&gt;
&lt;p&gt;Following my last blog post on &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/pca-projection/&#34;&gt;PCA projection and cell label transfer&lt;/a&gt;, we are
going to talk about &lt;code&gt;CCA&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In single-cell RNA-seq data integration using &lt;code&gt;Canonical Correlation Analysis (CCA)&lt;/code&gt;, we typically align two matrices representing different datasets, where both datasets have the same set of genes but different numbers of cells. CCA is used to identify correlated structures across the two datasets and align them in a common space.&lt;/p&gt;
&lt;p&gt;Let’s denote the two datasets as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;: a matrix with dimensions &lt;span class=&#34;math inline&#34;&gt;\(p \times n1\)&lt;/span&gt; (where &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the number of genes and
&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the number of cells in dataset 1, e.g., PBMC 3k)&lt;/p&gt;
&lt;p&gt;Y: a matrix with dimensions &lt;span class=&#34;math inline&#34;&gt;\(p \times n2\)&lt;/span&gt; (where &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the number of genes and
&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the number of cells in dataset 2, e.g., PBMC 10k)&lt;/p&gt;
&lt;p&gt;In this case, the number of genes (rows) is the same in both matrices, but the number of cells (columns) is different.&lt;/p&gt;
&lt;p&gt;The goal of &lt;code&gt;CCA&lt;/code&gt; here is to find linear combinations of the genes in both datasets that produce correlated cell embeddings in a lower-dimensional space. Essentially, we aim to align the two datasets by identifying the correlated patterns in gene expression that are shared between the two sets of cells.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-cca-works&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;How CCA Works&lt;/h3&gt;
&lt;p&gt;Given the two datasets &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, CCA finds the linear combinations of the gene expression profiles that are maximally correlated. This means that for each cell in &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and each cell in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; we find directions in the gene expression space that maximize the correlation between the two datasets.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;formulas-for-cca&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Formulas for CCA&lt;/h3&gt;
&lt;p&gt;Input Data:&lt;/p&gt;
&lt;p&gt;a matrix &lt;span class=&#34;math inline&#34;&gt;\(X \in \mathbb{R}^{p \times n_1}\)&lt;/span&gt; is the matrix of gene expression from the first dataset (3k cells), and &lt;span class=&#34;math inline&#34;&gt;\(Y \in \mathbb{R}^{p \times n_2}\)&lt;/span&gt; is the matrix of gene expression from the second dataset (10k cells).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Canonical Variates&lt;/strong&gt;:
We aim to find vectors &lt;span class=&#34;math inline&#34;&gt;\(a \in \mathbb{R}^p\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(b \in \mathbb{R}^p\)&lt;/span&gt; such that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
u = X^T a \quad (\text{canonical variate for cells in } X)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
v = Y^T b \quad (\text{canonical variate for cells in } Y)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; are the canonical variates, and the goal is to maximize the correlation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{corr}(u, v) = \frac{\text{cov}(u, v)}{\sqrt{\text{var}(u)} \cdot \sqrt{\text{var}(v)}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Covariance Matrices&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
\Sigma_{XX} = \frac{1}{n_1 - 1} XX^T \quad \text{(covariance matrix of dataset } X)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\Sigma_{YY} = \frac{1}{n_2 - 1} YY^T \quad \text{(covariance matrix of dataset } Y)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\Sigma_{XY} = \frac{1}{\min(n_1, n_2) - 1} X^TY \quad \text{(cross-covariance matrix between } X \text{ and } Y)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Generalized Eigenvalue Problem (GEP)&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;To find the canonical weights &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, we solve the generalized eigenvalue problem:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\Sigma_{XX}^{-1} \Sigma_{XY} \Sigma_{YY}^{-1} \Sigma_{YX} a = \lambda a
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Similarly for &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\Sigma_{YY}^{-1} \Sigma_{YX} \Sigma_{XX}^{-1} \Sigma_{XY} b = \lambda b
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The eigenvalue &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; corresponds to the canonical correlation.
&lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; is the canonical weight vector for dataset &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the canonical weight vector for dataset &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Solving the eigenvalue problem involves finding the eigenvalues and eigenvectors that maximize the correlation between the datasets, but it effectively solves the same problem as the &lt;code&gt;SVD&lt;/code&gt; for the covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\Sigma XY\)&lt;/span&gt;. One can demonstrate that mathematically using matrix calculation. I am not a math person, I will leave it to you to do the proof :). Again, I really wish I learned linear algebra better.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; watch &lt;a href=&#34;https://www.3blue1brown.com/lessons/eigenvalues&#34;&gt;this for eigenvalues and eigenvectors&lt;/a&gt; from 3blue1brown.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; read this blog post &lt;a href=&#34;https://xinmingtu.cn/blog/2022/CCA_dual_PCA/&#34; class=&#34;uri&#34;&gt;https://xinmingtu.cn/blog/2022/CCA_dual_PCA/&lt;/a&gt; by Xinming Tu (with nice visuals!)
to understand the relationship between CCA and PCA in a more mathematical way.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-svd-is-used-and-how-it-relates-to-the-gep.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;How SVD is used and how it relates to the GEP.&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Perform SVD on the Cross-Covariance Matrix&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;The SVD of the cross-covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\Sigma_{XY}\)&lt;/span&gt; can be expressed as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
   \Sigma_{XY} = U D V^T
   \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where:&lt;br /&gt;
- &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; is a matrix of left singular vectors (canonical directions for dataset &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;,&lt;br /&gt;
- &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; is a matrix of right singular vectors (canonical directions for dataset &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;,&lt;br /&gt;
- &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; is a diagonal matrix containing singular values, which represent the strength of correlations.&lt;/p&gt;
&lt;p&gt;The matrix &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; contains the left singular vectors of &lt;span class=&#34;math inline&#34;&gt;\(\Sigma_{XY}\)&lt;/span&gt;, which correspond to the canonical directions for dataset &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. These directions are the axes along which the data in &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is maximally correlated with the data in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, as measured by the singular values in &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;. Thus, &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; represents the canonical variates (directions) for &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, just as &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; represents the canonical variates for &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-see-an-example-in-action&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Let’s see an example in action&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Seurat)
library(Matrix)
library(irlba)  # For PCA
library(dplyr)
# devtools::install_github(&amp;#39;satijalab/seurat-data&amp;#39;)
library(SeuratData)
#AvailableData()
#InstallData(&amp;quot;pbmc3k&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The pbmc3k data and pbmc10k data have different number of gene names, let’s subset
to the common genes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# download 10k dataset here curl -Lo pbmc_10k_v3.rds https://www.dropbox.com/s/3f3p5nxrn5b3y4y/pbmc_10k_v3.rds?dl=1 

pbmc3k&amp;lt;-UpdateSeuratObject(pbmc3k)
pbmc10k&amp;lt;- readRDS(&amp;quot;~/blog_data/pbmc_10k_v3.rds&amp;quot;)
pbmc10k&amp;lt;-UpdateSeuratObject(pbmc10k)

pbmc3k_genes &amp;lt;- rownames(pbmc3k)
pbmc10k_genes &amp;lt;- rownames(pbmc10k)

# Find common genes
common_genes &amp;lt;- intersect(pbmc3k_genes, pbmc10k_genes)

# reorder the genes to the same order
pbmc3k &amp;lt;- subset(pbmc3k, features = common_genes)
pbmc10k &amp;lt;- subset(pbmc10k, features = common_genes)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How the pbmc10k data look like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# routine processing for 3k dataset
pbmc3k&amp;lt;- pbmc3k %&amp;gt;% 
  NormalizeData(normalization.method = &amp;quot;LogNormalize&amp;quot;, scale.factor = 10000) %&amp;gt;%
  FindVariableFeatures(selection.method = &amp;quot;vst&amp;quot;, nfeatures = 5000) %&amp;gt;%
  ScaleData() %&amp;gt;%
  RunPCA(verbose = FALSE) %&amp;gt;%
  FindNeighbors(dims = 1:10, verbose = FALSE) %&amp;gt;%
  FindClusters(resolution = 0.5, verbose = FALSE) %&amp;gt;%
  RunUMAP(dims = 1:10, verbose = FALSE)

DimPlot(pbmc10k, label = TRUE, repel = TRUE) + NoLegend()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-19-how-seurat-cca-label-transfer_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The pbmc3k dataset comes with annotations (the seurat_annotations column). In
this experiment, we will pretend we do not have it and use the 10k pbmc data to
transfer the labels. Also the pbmc10k cell labels are a little more granular.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbmc10k &amp;lt;- NormalizeData(pbmc10k)
pbmc10k &amp;lt;- FindVariableFeatures(pbmc10k, selection.method = &amp;quot;vst&amp;quot;, nfeatures = 5000)
pbmc10k &amp;lt;- ScaleData(pbmc10k)

# Find common variable features, Seurat has a more complex function
# we will take the intersection
#variable_genes &amp;lt;- SelectIntegrationFeatures(list(pbmc3k, pbmc10k), nfeatures = 3000)

variable_genes &amp;lt;- intersect(VariableFeatures(pbmc3k), VariableFeatures(pbmc10k))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note we need to scale them by genes across the cells first.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Step 1: Center the datasets
centered_pbmc3k &amp;lt;- t(scale(t(pbmc3k@assays$RNA@data[variable_genes,]), center =TRUE, scale =TRUE))
centered_pbmc10k &amp;lt;- t(scale(t(pbmc10k@assays$RNA@data[variable_genes,]), center= TRUE, scale =TRUE))

dim(centered_pbmc3k)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 2376 2700&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(centered_pbmc10k)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 2376 9432&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;SVD&lt;/code&gt; directly computes the singular values (canonical correlations) and singular vectors (canonical variates) by decomposing &lt;span class=&#34;math inline&#34;&gt;\(\Sigma XY\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The singular value decomposition (SVD) can be mathematically related to solving the generalized eigenvalue problem.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Sigma_XY&amp;lt;- (1 / (min(ncol(centered_pbmc3k), ncol(centered_pbmc10k)) - 1)) * t(centered_pbmc3k) %*% centered_pbmc10k

dim(Sigma_XY)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 2700 9432&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Perform SVD
k &amp;lt;- 20  # Number of CCA dimensions
cca_svd &amp;lt;- irlba::irlba(Sigma_XY, nu=k, nv=k)

# Get canonical variates and correlations
canonical_variates_3k &amp;lt;- cca_svd$u  # PBMC3k canonical variates
canonical_variates_10k &amp;lt;- cca_svd$v  # PBMC10k canonical variates

# cca_svd$d contains the singular values
canonical_cors &amp;lt;- cca_svd$d  # Canonical correlations

range(canonical_cors)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]   4.70585 165.14183&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# normalize it so the first CCA dimension has a correlation close to 1 
canonical_cors&amp;lt;- cca_svd$d / sum(cca_svd$d)

barplot(canonical_cors, 
        main=&amp;quot;Canonical Correlations&amp;quot;, 
        xlab=&amp;quot;Canonical Dimension&amp;quot;, 
        ylab=&amp;quot;Correlation&amp;quot;,
        col=&amp;quot;lightblue&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-19-how-seurat-cca-label-transfer_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;
The sum of the first few CCA dimension should have a corrrelation close to 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;l2-normalization-of-canonical-correlation-vectors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;L2 Normalization of Canonical Correlation Vectors&lt;/h3&gt;
&lt;p&gt;From the Seurat V3 paper: &lt;a href=&#34;https://pmc.ncbi.nlm.nih.gov/articles/PMC6687398/&#34; class=&#34;uri&#34;&gt;https://pmc.ncbi.nlm.nih.gov/articles/PMC6687398/&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;While MNNs have previously been identified using L2-normalized gene expression, significant differences across batches can obscure the accurate identification of MNNs, particularly when the batch effect is on a similar scale to the biological differences between cell states. To overcome this, we first jointly reduce the dimensionality of both datasets using diagonalized canonical correlation analysis (CCA), then apply L2-normalization to the canonical correlation vectors (Figure 1A,B). We next search for MNNs in this shared low-dimensional representation&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Purpose of L2 Normalization: After computing the canonical variates (the linear combinations of the original variables that maximize correlation), L2 normalization (also known as Euclidean normalization) is applied to these vectors. This process scales the vectors so that their lengths (norms) equal one.&lt;/p&gt;
&lt;p&gt;Mathematical Formulation: For a vector &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt;
L2 normalization can be expressed as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(v_{\text{normalized}} = \frac{v}{\|v\|_2}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\|v\|_2\)&lt;/span&gt; is the L2 norm (Euclidean norm) of the vector.&lt;/p&gt;
&lt;p&gt;Benefits of L2 Normalization:&lt;/p&gt;
&lt;p&gt;Stabilization: It helps to stabilize the comparison of canonical correlation vectors across datasets, making the downstream analysis more robust.&lt;/p&gt;
&lt;p&gt;Interpretable Scale: Normalized vectors provide a more interpretable scale for distances and similarities in the integrated dataset.&lt;/p&gt;
&lt;p&gt;Apply the L2 normalization for each cell.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;l2_normalize &amp;lt;- function(x) {
  x / sqrt(rowSums(x^2))
}

# L2-normalize the canonical variates for PBMC 3k
canonical_variates_3k&amp;lt;- l2_normalize(canonical_variates_3k)

# L2-normalize the canonical variates for PBMC 10k
canonical_variates_10k &amp;lt;- l2_normalize(canonical_variates_10k)

# Check dimensions to make sure they remain the same
dim(canonical_variates_3k)  # Should be 2700 by 20&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 2700   20&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(canonical_variates_10k)  # Should be 9432 by 20&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 9432   20&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;function-to-find-mutual-nearest-neighbors-mnn&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Function to find Mutual nearest neighbors (MNN)&lt;/h2&gt;
&lt;p&gt;We will use &lt;code&gt;RANN&lt;/code&gt; package to do it at a high level. We used &lt;code&gt;RcppAnnoy&lt;/code&gt; in the last
post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(RANN)

# Step 1: Find Nearest Neighbors using RANN
k &amp;lt;- 30  # Number of neighbors to consider
nn_result_10k &amp;lt;- nn2(data = canonical_variates_10k, query = canonical_variates_3k, k = k)
nn_indices_10k &amp;lt;- nn_result_10k$nn.idx  # Indices of nearest neighbors in pbmc10k

# Find the nearest neighbors in pbmc3k for pbmc10k cells
nn_result_3k &amp;lt;- nn2(data = canonical_variates_3k, query = canonical_variates_10k, k = k)
nn_indices_3k &amp;lt;- nn_result_3k$nn.idx  # Indices of nearest neighbors in pbmc3k

# Step 2: Identify Mutual Nearest Neighbors
find_mnn &amp;lt;- function(nn_indices_10k, nn_indices_3k) {
  mnn_list &amp;lt;- vector(&amp;quot;list&amp;quot;, length = nrow(canonical_variates_3k))
  
  for (i in 1:nrow(canonical_variates_3k)) {
    neighbors_10k &amp;lt;- nn_indices_10k[i, ]  # Neighbors in pbmc10k
    mutual_neighbors &amp;lt;- c()
    
    for (neighbor in neighbors_10k) {
      # Check if this neighbor sees the original cell as its nearest neighbor
      if (i %in% nn_indices_3k[neighbor, ]) {
        mutual_neighbors &amp;lt;- c(mutual_neighbors, neighbor)
      }
    }
    mnn_list[[i]] &amp;lt;- mutual_neighbors
  }
  return(mnn_list)
}

# Find MNNs
mnn_indices &amp;lt;- find_mnn(nn_indices_10k, nn_indices_3k)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Label transfer for cells that have MNNs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Step 3: Label Transfer with MNN
# Assume we have labels for the PBMC10k dataset
pbmc10k_labels &amp;lt;- as.character(pbmc10k$celltype)

# Initialize transferred labels and scores
transferred_labels &amp;lt;- character(length = nrow(canonical_variates_3k))
transfer_scores &amp;lt;- numeric(length = nrow(canonical_variates_3k))

# Transfer labels with error handling
for (i in seq_along(mnn_indices)) {
  if (length(mnn_indices[[i]]) &amp;gt; 0) {
    # Get labels for the MNNs
    labels &amp;lt;- pbmc10k_labels[mnn_indices[[i]]]
    
    # Remove NAs from labels
    labels &amp;lt;- labels[!is.na(labels)]
    
    # Check if we have any valid labels left
    if (length(labels) &amp;gt; 0) {
      # Assign the most common label among the MNNs
      transferred_labels[i] &amp;lt;- names(sort(table(labels), decreasing = TRUE))[1]
      # Calculate transfer score as the proportion of matching labels
      transfer_scores[i] &amp;lt;- max(table(labels)) / length(labels)
    } else {
      # Assign NA or a default value if no valid labels
      transferred_labels[i] &amp;lt;- NA_character_  # Keep it as NA of character type
      transfer_scores[i] &amp;lt;- 0
    }
  } else {
    # For cells without MNN, assign NA or a default label (e.g., &amp;quot;unknown&amp;quot;)
    transferred_labels[i] &amp;lt;- NA_character_
    transfer_scores[i] &amp;lt;- 0
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;step-4-handle-cells-without-mnn&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Step 4: Handle cells without MNN&lt;/h4&gt;
&lt;p&gt;You can assign a default label or propagate labels based on other criteria. For example, using a knn approach or global label distribution. Optionally, you could implement a fallback strategy like the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for (i in seq_along(transferred_labels)) {
  if (is.na(transferred_labels[i])) {
    # Look for the nearest neighbor labels in pbmc10k
    nearest_label_index &amp;lt;- nn_indices_10k[i, 1]  # Get the first neighbor
    transferred_labels[i] &amp;lt;- pbmc10k_labels[nearest_label_index]  # Assign its label
  }
}

# transferred_labels now contains labels transferred from pbmc10k to pbmc3k
# transfer_scores indicates the confidence of the label transfer for each cell

pbmc3k$transferred_labels&amp;lt;- transferred_labels&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;compare-with-seurats-wrapper&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;compare with Seurat’s wrapper&lt;/h3&gt;
&lt;p&gt;the default is &lt;code&gt;pcaprojection&lt;/code&gt; as what we did in my last blog post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Step 1: Find transfer anchors
anchors &amp;lt;- FindTransferAnchors(
  reference = pbmc10k,     # The reference dataset
  query = pbmc3k,          # The query dataset
  dims = 1:100,                # The dimensions to use for anchor finding
  #reduction = &amp;quot;cca&amp;quot; # 
)

# Step 2: Transfer labels
predictions &amp;lt;- TransferData(
  anchors = anchors,           # The anchors identified in the previous step
  refdata = pbmc10k$celltype, # Assuming &amp;#39;label&amp;#39; is the metadata containing the true labels in seurat_10k
  dims = 1:30                  # Dimensions to use for transferring
)


# Step 3: Add predictions to the query dataset
pbmc3k &amp;lt;- AddMetaData(pbmc3k, metadata = predictions)

# predicted.id is from Seurat&amp;#39;s wrapper function, predicted is from our naive implementation
table(pbmc3k$transferred_labels, pbmc3k$predicted.id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                         
#&amp;gt;                          B cell progenitor CD14+ Monocytes CD16+ Monocytes
#&amp;gt;   B cell progenitor                     86               0               0
#&amp;gt;   CD14+ Monocytes                        0             480              15
#&amp;gt;   CD16+ Monocytes                        0               5             131
#&amp;gt;   CD4 Memory                             0               0               0
#&amp;gt;   CD4 Naive                              0               0               0
#&amp;gt;   CD8 effector                           0               0               0
#&amp;gt;   CD8 Naive                              0               0               0
#&amp;gt;   Dendritic cell                         0               3               1
#&amp;gt;   Double negative T cell                 0               0               0
#&amp;gt;   NK cell                                2               0               0
#&amp;gt;   pDC                                    0               2               0
#&amp;gt;   Platelets                              0               3               0
#&amp;gt;   pre-B cell                            15               0               0
#&amp;gt;                         
#&amp;gt;                          CD4 Memory CD4 Naive CD8 effector CD8 Naive
#&amp;gt;   B cell progenitor               2         6            0         1
#&amp;gt;   CD14+ Monocytes                23        20            0         0
#&amp;gt;   CD16+ Monocytes                 0         0            0         0
#&amp;gt;   CD4 Memory                    452       165            5        21
#&amp;gt;   CD4 Naive                       5       334            0        18
#&amp;gt;   CD8 effector                   16         6          163         9
#&amp;gt;   CD8 Naive                       0        34            0        77
#&amp;gt;   Dendritic cell                  0         1            0         1
#&amp;gt;   Double negative T cell         21        13            4         2
#&amp;gt;   NK cell                         1         1           14         0
#&amp;gt;   pDC                             2         1            0         0
#&amp;gt;   Platelets                       0         0            2         0
#&amp;gt;   pre-B cell                      0         0            0         0
#&amp;gt;                         
#&amp;gt;                          Dendritic cell Double negative T cell NK cell pDC
#&amp;gt;   B cell progenitor                   0                      0       0   0
#&amp;gt;   CD14+ Monocytes                     4                      0       1   0
#&amp;gt;   CD16+ Monocytes                     0                      0       0   0
#&amp;gt;   CD4 Memory                          0                      1       2   0
#&amp;gt;   CD4 Naive                           0                      0       0   0
#&amp;gt;   CD8 effector                        0                      2       0   0
#&amp;gt;   CD8 Naive                           0                      0       0   0
#&amp;gt;   Dendritic cell                     27                      0       0   0
#&amp;gt;   Double negative T cell              0                     91       0   0
#&amp;gt;   NK cell                             0                      1     150   0
#&amp;gt;   pDC                                 0                      0       0   4
#&amp;gt;   Platelets                           0                      0       0   0
#&amp;gt;   pre-B cell                          0                      0       0   0
#&amp;gt;                         
#&amp;gt;                          Platelets pre-B cell
#&amp;gt;   B cell progenitor              0         10
#&amp;gt;   CD14+ Monocytes                1          0
#&amp;gt;   CD16+ Monocytes                0          0
#&amp;gt;   CD4 Memory                     0          0
#&amp;gt;   CD4 Naive                      0          0
#&amp;gt;   CD8 effector                   0          0
#&amp;gt;   CD8 Naive                      0          0
#&amp;gt;   Dendritic cell                 0          0
#&amp;gt;   Double negative T cell         0          0
#&amp;gt;   NK cell                        0          1
#&amp;gt;   pDC                            0          0
#&amp;gt;   Platelets                     12          0
#&amp;gt;   pre-B cell                     0        230&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;visualize in a heatmap&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ComplexHeatmap)
table(pbmc3k$transferred_labels, pbmc3k$predicted.id) %&amp;gt;%
        as.matrix() %&amp;gt;%
        scale() %&amp;gt;%
        Heatmap(cluster_rows = FALSE, cluster_columns= FALSE, name= &amp;quot;scaled\ncell number&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-19-how-seurat-cca-label-transfer_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;clustering-and-umap&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;clustering and UMAP&lt;/h3&gt;
&lt;p&gt;With the CCA embeddings, you can do clustering (k-means, hierarchical clustering etc) and UMAP by concatenating the cannoical variates from two datasets together.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load required libraries for clustering and UMAP
library(uwot)  # For UMAP
library(cluster)  # For clustering algorithms (like k-means)

# Combine canonical variates from both datasets 
combined_variates &amp;lt;- rbind(canonical_variates_3k, canonical_variates_10k)
combined_variates&amp;lt;- scale(combined_variates)

# Step 1: Clustering (using k-means as an example)
# Set the number of clusters (k)
k &amp;lt;- 13  # Choose the number of clusters based on your data ( I am cheating as I know 13 celltypes in the dataset)

set.seed(123)
kmeans_result &amp;lt;- kmeans(combined_variates, centers = k)

# Extract cluster labels
cluster_labels &amp;lt;- kmeans_result$cluster

# Step 2: UMAP Calculation
# Compute UMAP on the canonical variates
umap_results &amp;lt;- umap(combined_variates)

# UMAP Results
umap_data &amp;lt;- as.data.frame(umap_results)

# Add cluster labels and data source to UMAP results for visualization
umap_data$Cluster &amp;lt;- factor(cluster_labels)
umap_data$dataset&amp;lt;- c(rep(&amp;quot;3k&amp;quot;, nrow(canonical_variates_3k)),
                      rep(&amp;quot;10k&amp;quot;, nrow(canonical_variates_10k)))
umap_data$celltype&amp;lt;- c(as.character(pbmc3k$transferred_labels),
                       as.character(pbmc10k$celltype))

table(umap_data$Cluster, umap_data$celltype) %&amp;gt;%
        as.matrix() %&amp;gt;%
        scale() %&amp;gt;%
        Heatmap(cluster_rows = FALSE, cluster_columns= FALSE, name= &amp;quot;scaled\ncell number&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-19-how-seurat-cca-label-transfer_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;K-means works reasonably well. It mixes CD4 naive and CD8 naive together; pDC and Dendritic cells together. It split CD14+ monocytes into two different cluster 6 and 11. One can do many times of K-means and use the consensus as the clusters. e.g., &lt;a href=&#34;https://www.nature.com/articles/nmeth.4236&#34;&gt;SC3: consensus clustering of single-cell RNA-seq data&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;datasets-integration&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Datasets integration&lt;/h3&gt;
&lt;p&gt;Plot UMAP&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

ggplot(umap_data, aes(x = V1, y = V2, color = dataset)) +
  geom_point(size = 0.4) +
  labs(title = &amp;quot;UMAP Projection of CCA Canonical Variates&amp;quot;,
       x = &amp;quot;UMAP 1&amp;quot;,
       y = &amp;quot;UMAP 2&amp;quot;) +
  theme_minimal() +
  scale_color_discrete(name = &amp;quot;dataset&amp;quot;) +
        facet_wrap(~dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-19-how-seurat-cca-label-transfer_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see those two datasets are aligned super well!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(umap_data, aes(x = V1, y = V2, color = dataset)) +
  geom_point(size = 0.4) +
  labs(title = &amp;quot;UMAP Projection of CCA Canonical Variates&amp;quot;,
       x = &amp;quot;UMAP 1&amp;quot;,
       y = &amp;quot;UMAP 2&amp;quot;) +
  theme_minimal() +
  scale_color_discrete(name = &amp;quot;dataset&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-19-how-seurat-cca-label-transfer_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s color the cells with celltype:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# use https://oompa.r-forge.r-project.org/packages/Polychrome/polychrome.html for colors
library(Polychrome)

# length(unique(umap_data$celltype)) 
# total 13 distinct cell types

# remove the first white color
colors_to_use&amp;lt;- kelly.colors(n=14)[-1] %&amp;gt;% unname()

ggplot(umap_data, aes(x = V1, y = V2, color = celltype)) +
  geom_point(size = 0.4) +
  labs(title = &amp;quot;UMAP Projection of CCA Canonical Variates&amp;quot;,
       x = &amp;quot;UMAP 1&amp;quot;,
       y = &amp;quot;UMAP 2&amp;quot;) +
  theme_minimal() +
        scale_color_manual(values = colors_to_use) +
        guides(colour = guide_legend(override.aes = list(size=2))) # increase the dot size in the legend&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-19-how-seurat-cca-label-transfer_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-if-we-do-not-do-cca-integration&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What if we do not do CCA integration?&lt;/h3&gt;
&lt;p&gt;What if we do not use the CCA covariates for clustering? We can just concatenate
two seurat object together and go through the routine process:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add a metadata column so you know which dataset the cells are from 
pbmc3k$sample&amp;lt;- &amp;quot;3k&amp;quot;
pbmc10k$sample&amp;lt;- &amp;quot;10k&amp;quot;

# combine two seurat objects together
pbmc&amp;lt;- merge(pbmc3k, pbmc10k)

pbmc&amp;lt;- pbmc %&amp;gt;% 
  NormalizeData(normalization.method = &amp;quot;LogNormalize&amp;quot;, scale.factor = 10000) %&amp;gt;%
  FindVariableFeatures(selection.method = &amp;quot;vst&amp;quot;, nfeatures = 5000) %&amp;gt;%
  ScaleData() %&amp;gt;%
  RunPCA(verbose = FALSE) %&amp;gt;%
  FindNeighbors(dims = 1:30, verbose = FALSE) %&amp;gt;%
  FindClusters(resolution = 0.5, verbose = FALSE) %&amp;gt;%
  RunUMAP(dims = 1:30, verbose = FALSE)

DimPlot(pbmc, label = TRUE, repel = TRUE, group.by= &amp;quot;sample&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-19-how-seurat-cca-label-transfer_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Without using &lt;code&gt;CCA&lt;/code&gt;, you see the cells are separated by samples. The idea of data integration is to make the cells of the same cell type group together even they are
from different datasets while cells of different cell types still separate from each other.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-cca-achieves-in-single-cell-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What CCA Achieves in Single-Cell Data:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Aligning Cell Embeddings: CCA produces canonical variates &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt;, which are lower-dimensional embeddings of the cells from the two datasets. These embeddings are aligned in such a way that the cells from both datasets are maximally correlated in this new space.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Identifying Shared Structure: By finding the common canonical directions, CCA captures the shared structure in gene expression between the two datasets, allowing cells with similar profiles across datasets to be aligned.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;comparison-to-pca&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Comparison to PCA&lt;/h3&gt;
&lt;p&gt;Unlike PCA, which focuses on capturing variance within a &lt;strong&gt;single dataset&lt;/strong&gt;, &lt;code&gt;CCA&lt;/code&gt; focuses on capturing correlation between two datasets. Both involve matrix decomposition, but while &lt;code&gt;PCA&lt;/code&gt; decomposes a single covariance matrix, &lt;code&gt;CCA&lt;/code&gt; involves solving for relationships between the covariance matrices of two datasets.&lt;/p&gt;
&lt;p&gt;To summarize:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PCA: Finds directions of maximum variance within a single dataset.&lt;/li&gt;
&lt;li&gt;CCA: Finds directions of maximum covariance between two datasets.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Happy Learning!&lt;/p&gt;
&lt;p&gt;Tommy aka. Crazyhottommy&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How PCA projection and cell label transfer work in Seurat</title>
      <link>/post/pca-projection/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/pca-projection/</guid>
      <description>&lt;p&gt;&lt;strong&gt;To not miss a post like this, sign up for my &lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/profile&#34;&gt;newsletter&lt;/a&gt; to learn computational
biology and bioinformatics.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;understand-the-example-datasets&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Understand the example datasets&lt;/h3&gt;
&lt;p&gt;We will use PBMC3k and PBMC10k data. We will project the PBMC3k data to the PBMC10k data
and get the labels&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Seurat)
library(Matrix)
library(irlba)  # For PCA
library(RcppAnnoy)  # For fast nearest neighbor search
library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Assuming the PBMC datasets (3k and 10k) are already normalized
# and represented as sparse matrices
# devtools::install_github(&amp;#39;satijalab/seurat-data&amp;#39;)
library(SeuratData)
#AvailableData()
#InstallData(&amp;quot;pbmc3k&amp;quot;)

pbmc3k&amp;lt;-UpdateSeuratObject(pbmc3k)
pbmc3k@meta.data %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                orig.ident nCount_RNA nFeature_RNA seurat_annotations
#&amp;gt; AAACATACAACCAC     pbmc3k       2419          779       Memory CD4 T
#&amp;gt; AAACATTGAGCTAC     pbmc3k       4903         1352                  B
#&amp;gt; AAACATTGATCAGC     pbmc3k       3147         1129       Memory CD4 T
#&amp;gt; AAACCGTGCTTCCG     pbmc3k       2639          960         CD14+ Mono
#&amp;gt; AAACCGTGTATGCG     pbmc3k        980          521                 NK
#&amp;gt; AAACGCACTGGTAC     pbmc3k       2163          781       Memory CD4 T&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# routine processing
pbmc3k&amp;lt;- pbmc3k %&amp;gt;% 
  NormalizeData(normalization.method = &amp;quot;LogNormalize&amp;quot;, scale.factor = 10000) %&amp;gt;%
  FindVariableFeatures(selection.method = &amp;quot;vst&amp;quot;, nfeatures = 3000) %&amp;gt;%
  ScaleData() %&amp;gt;%
  RunPCA(verbose = FALSE) %&amp;gt;%
  FindNeighbors(dims = 1:10, verbose = FALSE) %&amp;gt;%
  FindClusters(resolution = 0.5, verbose = FALSE) %&amp;gt;%
  RunUMAP(dims = 1:10, verbose = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Get an idea of how the pbmc3k data look like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1&amp;lt;- DimPlot(pbmc3k, reduction = &amp;quot;umap&amp;quot;, label = TRUE, group.by = 
                        &amp;quot;RNA_snn_res.0.5&amp;quot;)

p2&amp;lt;- DimPlot(pbmc3k, reduction = &amp;quot;umap&amp;quot;, label = TRUE, group.by = &amp;quot;seurat_annotations&amp;quot;, label.size = 3)

p1 + p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-17-how-seurat-pca-label-transfer_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;How the pbmc10k data look like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# download it here curl -Lo pbmc_10k_v3.rds https://www.dropbox.com/s/3f3p5nxrn5b3y4y/pbmc_10k_v3.rds?dl=1 

pbmc10k&amp;lt;- readRDS(&amp;quot;~/blog_data/pbmc_10k_v3.rds&amp;quot;)
pbmc10k&amp;lt;-UpdateSeuratObject(pbmc10k)
pbmc10k@meta.data %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                        orig.ident nCount_RNA nFeature_RNA    observed simulated
#&amp;gt; rna_AAACCCAAGCGCCCAT-1    10x_RNA       2204         1087 0.035812672 0.4382022
#&amp;gt; rna_AAACCCACAGAGTTGG-1    10x_RNA       5884         1836 0.019227034 0.1017964
#&amp;gt; rna_AAACCCACAGGTATGG-1    10x_RNA       5530         2216 0.005447865 0.1392801
#&amp;gt; rna_AAACCCACATAGTCAC-1    10x_RNA       5106         1615 0.014276003 0.4949495
#&amp;gt; rna_AAACCCACATCCAATG-1    10x_RNA       4572         1800 0.053857351 0.1392801
#&amp;gt; rna_AAACCCAGTGGCTACC-1    10x_RNA       6702         1965 0.056603774 0.3554328
#&amp;gt;                        percent.mito RNA_snn_res.0.4        celltype
#&amp;gt; rna_AAACCCAAGCGCCCAT-1   0.02359347               1      CD4 Memory
#&amp;gt; rna_AAACCCACAGAGTTGG-1   0.10757988               0 CD14+ Monocytes
#&amp;gt; rna_AAACCCACAGGTATGG-1   0.07848101               5         NK cell
#&amp;gt; rna_AAACCCACATAGTCAC-1   0.10830396               3      pre-B cell
#&amp;gt; rna_AAACCCACATCCAATG-1   0.08989501               5         NK cell
#&amp;gt; rna_AAACCCAGTGGCTACC-1   0.06326470               1      CD4 Memory&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DimPlot(pbmc10k, label = TRUE, repel = TRUE) + NoLegend()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-17-how-seurat-pca-label-transfer_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The pbmc3k data and pbmc10k data have different number of gene names, let’s subset
to the common genes.&lt;/p&gt;
&lt;p&gt;the pbmc3k dataset comes with annotations (the seurat_annotations column). In
this experiment, we will pretend we do not have it and use the 10k pbmc data to
transfer the labels. Also the 10kpbmc cell labels are a little more granular.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbmc3k_genes &amp;lt;- rownames(pbmc3k)
pbmc10k_genes &amp;lt;- rownames(pbmc10k)

# Find common genes
common_genes &amp;lt;- intersect(pbmc3k_genes, pbmc10k_genes)


pbmc3k &amp;lt;- subset(pbmc3k, features = common_genes)
pbmc10k &amp;lt;- subset(pbmc10k, features = common_genes)

all.equal(rownames(pbmc3k), rownames(pbmc10k))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;understand-pcasvd&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Understand PCA/SVD&lt;/h3&gt;
&lt;p&gt;For Singular Value Decomposition (SVD), the decomposition of an
&lt;span class=&#34;math inline&#34;&gt;\(𝑋\)&lt;/span&gt; matrix (with dimensions &lt;span class=&#34;math inline&#34;&gt;\(n\times p\)&lt;/span&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the number of cells/samples and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the number of genes/features) is as follows:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(X = U D V^T\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Components of SVD:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(n \times n\)&lt;/span&gt; orthogonal matrix. It contains the left singular vectors (associated with the rows of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; i.e., cells/samples).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(p \times p\)&lt;/span&gt; orthogonal matrix. It contains the right singular vectors (associated with the columns of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; i.e., genes/features).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(n \times p\)&lt;/span&gt; diagonal matrix (with non-negative real numbers on the diagonal).
The diagonal elements are the singular values of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; which indicate the variance captured by each component.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Principal Components (PCs):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The principal components (PCs) are given by:
&lt;span class=&#34;math inline&#34;&gt;\(Z = UD\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This matrix has the dimensions &lt;span class=&#34;math inline&#34;&gt;\(n\times r\)&lt;/span&gt; (where &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is the rank of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;)&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Z\)&lt;/span&gt; contains the projection of your data onto the principal component space.&lt;/p&gt;
&lt;p&gt;SVD is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(X = U D V^T\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We &lt;span class=&#34;math inline&#34;&gt;\(\times V\)&lt;/span&gt; on both sides of the &lt;code&gt;SVD&lt;/code&gt; equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(XV = U DV^TV\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Since the &lt;code&gt;V&lt;/code&gt; matrix is orthonormal, &lt;span class=&#34;math inline&#34;&gt;\(V \times V^T = I\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(I\)&lt;/span&gt; is the identity matrix.
The equation becomes:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(XV = UD\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So, alternatively, you can express the PCs as:
&lt;span class=&#34;math inline&#34;&gt;\(Z = XV\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In single-cell RNAseq analysis, the &lt;span class=&#34;math inline&#34;&gt;\(Z\)&lt;/span&gt; matrix is used to construct the k-nearest neighbor graph and clusters are detected using Louvain method in the graph. One can use any other clustering algorithms to cluster the cells (e.g., k-means, hierarchical clustering) in this PC space.&lt;/p&gt;
&lt;p&gt;I really wish I learned linear algebra better during college:)
Note, you can take &lt;a href=&#34;https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/&#34;&gt;MIT1806&lt;/a&gt;, which is a great course for linear algebra.&lt;/p&gt;
&lt;p&gt;Let’s calculate the PCA from scratch with &lt;code&gt;irlba&lt;/code&gt; for big matrix. use built-in &lt;code&gt;svd&lt;/code&gt; if the matrix is small.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install.packages(&amp;quot;irlba&amp;quot;)
library(irlba)
# use the scaled matrix 
pbmc10k_scaled &amp;lt;- pbmc10k@assays$RNA@scale.data

dim(pbmc10k_scaled)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 2068 9432&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Perform PCA using irlba (for large matrices). We transpose it first to gene x sample
pca_10k &amp;lt;- irlba(t(pbmc10k_scaled), nv = 100)  # Keep 100 PCs. The orginal seurat object kept 100 PCs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;read my previous blog post on some details of PCA steps within Seurat
&lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/permute-test-for-pca-components/&#34; class=&#34;uri&#34;&gt;https://divingintogeneticsandgenomics.com/post/permute-test-for-pca-components/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;By default, &lt;code&gt;RunPCA&lt;/code&gt; computes the PCA on the cell (n) x gene (p) matrix. One thing to note is that in linear algebra, a matrix is coded as n (rows are observations) X p (columns are features). That’s why by default, the gene x cell original matrix is transposed first to cell x gene: &lt;code&gt;irlba(A = t(x = data.use), nv = pcs.compute, ...)&lt;/code&gt;. After &lt;code&gt;irlba&lt;/code&gt;, the &lt;code&gt;v&lt;/code&gt; matrix is the gene loadings, the &lt;code&gt;u&lt;/code&gt; matrix is the cell embeddings.&lt;/p&gt;
&lt;p&gt;This is the source code of &lt;code&gt;RunPCA&lt;/code&gt; from &lt;code&gt;Seurat&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pcs.compute &amp;lt;- min(pcs.compute, nrow(x = data.use)-1)
pca.results &amp;lt;- irlba(A = t(x = data.use), nv = pcs.compute, ...)

gene.loadings &amp;lt;- pca.results$v

sdev &amp;lt;- pca.results$d/sqrt(max(1, ncol(data.use) - 1))

if(weight.by.var){
      cell.embeddings &amp;lt;- pca.results$u %*% diag(pca.results$d)
    } else {
      cell.embeddings &amp;lt;- pca.results$u
    }

rownames(x = gene.loadings) &amp;lt;- rownames(x = data.use)
colnames(x = gene.loadings) &amp;lt;- paste0(reduction.key, 1:pcs.compute)
rownames(x = cell.embeddings) &amp;lt;- colnames(x = data.use)
colnames(x = cell.embeddings) &amp;lt;- colnames(x = gene.loadings)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note, the diagonal matrix &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; in &lt;code&gt;svd&lt;/code&gt;/&lt;code&gt;irlba&lt;/code&gt; output in &lt;code&gt;R&lt;/code&gt; is the &lt;code&gt;d&lt;/code&gt; vector for the diagonal values, and you convert it to a matrix by &lt;code&gt;diag(d)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the gene loadings (V matrix). 
gene_loadings_10k &amp;lt;- pca_10k$v  # Gene loadings (features/genes in rows, PCs in columns)
dim(gene_loadings_10k)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 2068  100&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rownames(gene_loadings_10k) &amp;lt;- rownames(pbmc10k_scaled)
colnames(gene_loadings_10k) &amp;lt;- paste0(&amp;quot;PC&amp;quot;, 1:100)
# 2068 most variable genes (after subsetting the common genes with the pbmc3k data)
# ideally, we should re-run FindVariableFeatures, but I am skipping it
VariableFeatures(pbmc10k) %&amp;gt;% length()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 2068&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get PCA embeddings/cell embeddings (U matrix * D matrix) 
cell_embeddings_10k &amp;lt;- pca_10k$u %*% diag(pca_10k$d)  # Cell embeddings (10k cells in rows)
dim(cell_embeddings_10k)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 9432  100&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rownames(cell_embeddings_10k) &amp;lt;- colnames(pbmc10k_scaled)
colnames(cell_embeddings_10k) &amp;lt;- colnames(gene_loadings_10k)

cell_embeddings_10k[1:5, 1:10]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                               PC1        PC2       PC3         PC4       PC5
#&amp;gt; rna_AAACCCAAGCGCCCAT-1  10.403049   5.696715 -3.163544 -0.09967979  1.671379
#&amp;gt; rna_AAACCCACAGAGTTGG-1 -16.407637   1.541569 -4.664094 -1.19047314 -7.783903
#&amp;gt; rna_AAACCCACAGGTATGG-1   8.260527  14.882676 20.279862 -3.38568692 -3.978372
#&amp;gt; rna_AAACCCACATAGTCAC-1   9.943605 -17.397959  3.370954 -0.37872376 -2.409626
#&amp;gt; rna_AAACCCACATCCAATG-1  10.418157  10.678506 13.450984 -2.11710310 -2.893075
#&amp;gt;                                PC6        PC7         PC8       PC9       PC10
#&amp;gt; rna_AAACCCAAGCGCCCAT-1  1.58299300  6.2184955  0.42955410  6.163026 -1.1548215
#&amp;gt; rna_AAACCCACAGAGTTGG-1 -0.03877799 -4.9201975  5.97044789  2.240565 -1.5349458
#&amp;gt; rna_AAACCCACAGGTATGG-1 -2.54951081 -5.5834799 -5.08844441  1.729374 -2.7080737
#&amp;gt; rna_AAACCCACATAGTCAC-1 -2.79861360 -0.4920498  1.06599051 -1.454068  2.1049640
#&amp;gt; rna_AAACCCACATCCAATG-1 -2.34159998 -0.5451218 -0.09535381 -1.472860 -0.9710287&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;center the 3k pbmc data with the 10k gene meas and scale:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbmc3k_normalized &amp;lt;- pbmc3k@assays$RNA$data

# Center the 3k PBMC dataset based on 10k dataset&amp;#39;s gene means
pbmc3k_scaled &amp;lt;- scale(t(pbmc3k_normalized), center = rowMeans(pbmc10k@assays$RNA$data), scale = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Centering the transposed 3k PBMC dataset based on the 10k dataset’s gene means is an important step in the process of projecting one dataset onto another, particularly in single-cell RNA-seq analysis for label transfer. Here are the main reasons why this step is necessary:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Aligning Data Distributions: Centering the 3k dataset using the 10k dataset’s means ensures both datasets are aligned, reducing biases from differences in gene expression profiles.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ensuring Consistency: If the datasets come from different conditions, centering standardizes them, making them more comparable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Variance Representation: PCA is sensitive to the data’s mean; centering the 3k dataset with the 10k’s means ensures the variance is accurately captured by the principal components.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Improving Projection Accuracy: Proper centering improves projection accuracy and enhances the label transfer process by focusing on biological variation instead of technical noise.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(pbmc3k_scaled)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]  2700 11774&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# subset the same genes for the scaled 
pbmc3k_scaled&amp;lt;- pbmc3k_scaled[, rownames(pbmc10k_scaled)]

dim(pbmc3k_scaled)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 2700 2068&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;project-the-3k-cells-onto-the-pca-space-of-10k-dataset&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Project the 3k cells onto the PCA space of 10K dataset&lt;/h3&gt;
&lt;p&gt;Now, we are using the &lt;span class=&#34;math inline&#34;&gt;\(U = XV\)&lt;/span&gt; formula. The expression matrix is the pbmc3k
scaled matrix and the &lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; matrix is from the 10k pbmc data&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
cell_embeddings_3k &amp;lt;- as.matrix(pbmc3k_scaled) %*% gene_loadings_10k

cell_embeddings_3k[1:5, 1:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                      PC1         PC2        PC3        PC4       PC5
#&amp;gt; AAACATACAACCAC 14.059153   3.5956611 -2.5969722 -0.9823900  1.446572
#&amp;gt; AAACATTGAGCTAC 10.120213 -10.7275385  3.5977444 -0.4405952  0.890632
#&amp;gt; AAACATTGATCAGC 12.226727   4.5484269 -3.9300445 -0.3233310  2.735518
#&amp;gt; AAACCGTGCTTCCG -2.538137   0.2757831  0.3029575  0.1371588  7.311531
#&amp;gt; AAACCGTGTATGCG 14.332570   6.5377602  9.7189625 -3.3478680 -2.428808&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can plot the 3K pmbc cells in the 10k pmbc PCA space:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(rownames(cell_embeddings_3k), rownames(pbmc3k@meta.data))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cbind(cell_embeddings_3k,pbmc3k@meta.data) %&amp;gt;%
        ggplot(aes(x=PC1, y=PC2)) +
        geom_point(aes(color = seurat_annotations)) +
        theme_classic(base_size = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-17-how-seurat-pca-label-transfer_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# PCA space based on pbmc3k its own 
DimPlot(pbmc3k, reduction = &amp;quot;pca&amp;quot;, group.by = &amp;quot;seurat_annotations&amp;quot;, 
        label = TRUE) +
        NoLegend()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-17-how-seurat-pca-label-transfer_files/figure-html/unnamed-chunk-13-2.png&#34; width=&#34;672&#34; /&gt;
We see the cells roughly split into three major “islands”: B cells, myeloid cells (CD14/CD16+ monocytes) and the T cell/NK cells.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;identification-of-the-k-nearest-neighbors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;identification of the k nearest neighbors&lt;/h3&gt;
&lt;p&gt;Now that the 3k pbmc cell ebmeddings are projected to the 10k pbmc PCA space. We can find the k nearest neighbors in the 10k dataset to every cell in the 3k dataset.&lt;/p&gt;
&lt;p&gt;We are using &lt;code&gt;AnnoyAngular&lt;/code&gt; which calculates the cosine distance in the PCA space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Use the Annoy algorithm to find nearest neighbors between 3k and 10k datasets
n_neighbors &amp;lt;- 30  # Number of nearest neighbors to find k =30

# Create Annoy index for 10k PBMC dataset
annoy_index &amp;lt;- new(AnnoyAngular, ncol(cell_embeddings_10k)) ##use cosine distance Angular
for (i in 1:nrow(cell_embeddings_10k)) {
  annoy_index$addItem(i - 1, cell_embeddings_10k[i, ])
}
annoy_index$build(10)  # Build the index with 10 trees

# Find nearest neighbors for each cell in 3k dataset
nn_indices &amp;lt;- t(sapply(1:nrow(cell_embeddings_3k), function(i) {
  annoy_index$getNNsByVector(cell_embeddings_3k[i, ], n_neighbors)
}))

# nn_indices gives you the indices of nearest neighbors in the 10k PBMC dataset
# the rows are cells from 3k dataset, columns are the 30 nearest cells in the 10k dataset
dim(nn_indices)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 2700   30&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(nn_indices)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]
#&amp;gt; [1,] 8624 4993  275 8358 6192 3536 2828  457 7173   555  9058  5383  6643  6775
#&amp;gt; [2,] 8528  100 8576 6437 1351 4501 1822 4127 1407  3173  5457  5817  4931    46
#&amp;gt; [3,] 7950  754 5057  696 4787 3587 1578 3015   58  8249  2685  1371  8246  5740
#&amp;gt; [4,]  108 8617 4995 9206 8431 6035 6989  426 7892  3620  1215  6495  3897  6036
#&amp;gt; [5,]  452 8114 3868 5414 7884 1579 7633 4572 5017  3612  9159  8211  5712  1922
#&amp;gt; [6,] 4219 1815 6417 7895 8122 2080 6141 1256 3354  6037  6523  7299  7950  8519
#&amp;gt;      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]
#&amp;gt; [1,]  3558  8707  3529  1275  5868  4073  3811  1393  3855  5616  2381  7941
#&amp;gt; [2,]  6365  7079  7457  7123  8021  2107  2588  6516  7167  8056  5376  6102
#&amp;gt; [3,]   887  5788  5601  7588  1478  8934  6248  2030  7882  1239  2405  4230
#&amp;gt; [4,]  9132  3516  8077  9192  3507  5605  8443  6134  4658  7512  6104  1225
#&amp;gt; [5,]  2253  2091  1261  7797  4482  8450  7986  8537  8812  4113  1024  6570
#&amp;gt; [6,]  4808   949  8615  9422   696  5938  8860  8239  1319  2800  5870  4782
#&amp;gt;      [,27] [,28] [,29] [,30]
#&amp;gt; [1,]  3688  2263  9398  7010
#&amp;gt; [2,]  7311  8774   973  1743
#&amp;gt; [3,]  8239  1484  4816  4560
#&amp;gt; [4,]  1241  6221  3313  4065
#&amp;gt; [5,]  8183  9221  3822  5012
#&amp;gt; [6,]  3566  6276  3166  1578&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;label-transfer-based-on-the-nearest-neighbors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Label transfer based on the nearest neighbors&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;labels_10k&amp;lt;- as.character(pbmc10k$celltype)
# Transfer labels based on majority vote from nearest neighbors
transfer_labels &amp;lt;- apply(nn_indices, 1, function(neighbors) {
  # Get labels for the nearest neighbors
  neighbor_labels &amp;lt;- labels_10k[neighbors + 1]  # Add 1 for R&amp;#39;s 1-based index
  
  # Return the most common label (majority vote)
  most_common_label &amp;lt;- names(sort(table(neighbor_labels), decreasing = TRUE))[1]
  return(most_common_label)
})

# Now, transfer_labels contains the predicted labels for the 3k PBMC dataset
head(transfer_labels)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;CD8 Naive&amp;quot;         &amp;quot;B cell progenitor&amp;quot; &amp;quot;CD4 Memory&amp;quot;       
#&amp;gt; [4] &amp;quot;CD16+ Monocytes&amp;quot;   &amp;quot;NK cell&amp;quot;           &amp;quot;CD4 Memory&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbmc3k$predicted&amp;lt;- transfer_labels

DimPlot(pbmc3k, reduction = &amp;quot;umap&amp;quot;, group.by = &amp;quot;predicted&amp;quot;, label = TRUE, repel=TRUE) +
        NoLegend()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-17-how-seurat-pca-label-transfer_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;compare-with-seurats-wrapper&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;compare with Seurat’s wrapper&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Step 1: Find transfer anchors
anchors &amp;lt;- FindTransferAnchors(
  reference = pbmc10k,     # The reference dataset
  query = pbmc3k,          # The query dataset
  dims = 1:100,            # The dimensions to use for anchor finding
  reduction = &amp;quot;pcaproject&amp;quot; # this is the default
)

# Step 2: Transfer labels
predictions &amp;lt;- TransferData(
  anchors = anchors,           # The anchors identified in the previous step
  refdata = pbmc10k$celltype, # Assuming &amp;#39;label&amp;#39; is the metadata containing the true labels in seurat_10k
  dims = 1:30                  # Dimensions to use for transferring
)

# Step 3: Add predictions to the query dataset
pbmc3k &amp;lt;- AddMetaData(pbmc3k, metadata = predictions)

# predicted.id is from Seurat&amp;#39;s wrapper function, predicted is from our naive implementation
table(pbmc3k$predicted, pbmc3k$predicted.id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                         
#&amp;gt;                          B cell progenitor CD14+ Monocytes CD16+ Monocytes
#&amp;gt;   B cell progenitor                     85               1               0
#&amp;gt;   CD14+ Monocytes                        0             266               0
#&amp;gt;   CD16+ Monocytes                        0              77             135
#&amp;gt;   CD4 Memory                             0               4               4
#&amp;gt;   CD4 Naive                              0             129               8
#&amp;gt;   CD8 effector                           0               1               0
#&amp;gt;   CD8 Naive                              0               2               2
#&amp;gt;   Dendritic cell                         0              10               0
#&amp;gt;   Double negative T cell                 0               0               0
#&amp;gt;   NK cell                                0               0               0
#&amp;gt;   pDC                                    0               0               0
#&amp;gt;   Platelets                              0               1               0
#&amp;gt;   pre-B cell                             9               2               0
#&amp;gt;                         
#&amp;gt;                          CD4 Memory CD4 Naive CD8 effector CD8 Naive
#&amp;gt;   B cell progenitor               0         0            0         0
#&amp;gt;   CD14+ Monocytes                 0         0            0         0
#&amp;gt;   CD16+ Monocytes                 0         0            0         0
#&amp;gt;   CD4 Memory                    417         6           27         0
#&amp;gt;   CD4 Naive                     120       523           13        19
#&amp;gt;   CD8 effector                    1         0          124         0
#&amp;gt;   CD8 Naive                      21         3           10       120
#&amp;gt;   Dendritic cell                  0         0            0         0
#&amp;gt;   Double negative T cell          0         0            0         0
#&amp;gt;   NK cell                         0         0            4         0
#&amp;gt;   pDC                             0         0            0         0
#&amp;gt;   Platelets                       0         0            0         0
#&amp;gt;   pre-B cell                      0         0            1         0
#&amp;gt;                         
#&amp;gt;                          Dendritic cell Double negative T cell NK cell pDC
#&amp;gt;   B cell progenitor                   3                      0       2   0
#&amp;gt;   CD14+ Monocytes                     0                      0       0   0
#&amp;gt;   CD16+ Monocytes                     0                      0       0   0
#&amp;gt;   CD4 Memory                          2                     27       2   0
#&amp;gt;   CD4 Naive                           1                      9       0   0
#&amp;gt;   CD8 effector                        0                      1      10   0
#&amp;gt;   CD8 Naive                           0                      2       0   0
#&amp;gt;   Dendritic cell                     24                      0       0   0
#&amp;gt;   Double negative T cell              0                     62       0   0
#&amp;gt;   NK cell                             0                      0     140   0
#&amp;gt;   pDC                                 1                      0       0   4
#&amp;gt;   Platelets                           0                      0       0   0
#&amp;gt;   pre-B cell                          1                      0       0   0
#&amp;gt;                         
#&amp;gt;                          Platelets pre-B cell
#&amp;gt;   B cell progenitor              0          3
#&amp;gt;   CD14+ Monocytes                0          0
#&amp;gt;   CD16+ Monocytes                0          0
#&amp;gt;   CD4 Memory                     1          0
#&amp;gt;   CD4 Naive                      3          8
#&amp;gt;   CD8 effector                   0          0
#&amp;gt;   CD8 Naive                      1          0
#&amp;gt;   Dendritic cell                 0          0
#&amp;gt;   Double negative T cell         0          0
#&amp;gt;   NK cell                        0          0
#&amp;gt;   pDC                            0          0
#&amp;gt;   Platelets                      8          0
#&amp;gt;   pre-B cell                     0        240&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;visualize in a heatmap&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ComplexHeatmap)
table(pbmc3k$predicted, pbmc3k$predicted.id) %&amp;gt;%
        as.matrix() %&amp;gt;%
        scale() %&amp;gt;%
        Heatmap(cluster_rows = FALSE, cluster_columns= FALSE, name= &amp;quot;scaled\ncell number&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-17-how-seurat-pca-label-transfer_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our native implementation of the k nearest neighbor label transferring is working decently well:)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mutual-nearest-neighbors-mnn&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mutual nearest neighbors (MNN)&lt;/h2&gt;
&lt;p&gt;In Seurat, the mutual nearest neighbors (MNN) method is a key part of anchor identification during label transfer. Here’s a breakdown of what MNN does, how it differs from the PCA projection with k-nearest neighbors (kNN), and how labels are transferred for cells that are not mutual nearest neighbors.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is Mutual Nearest Neighbors (MNN) in Seurat?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mutual nearest neighbors (MNN) is used to match cells from two datasets (query and reference) based on their proximity in the shared feature space (e.g., PCA space). In this context:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Mutual Nearest Neighbors: For a cell in dataset A, find its nearest neighbors in dataset B, and for a cell in dataset B, find its nearest neighbors in dataset A. If two cells are nearest neighbors of each other, they are considered mutual nearest neighbors (MNNs).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Anchor Identification: MNNs serve as anchors or points of correspondence between the two datasets. These anchors represent pairs of cells from the two datasets that have similar profiles, and they help align the datasets for further downstream tasks such as label transfer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How is MNN Different from Your PCA Projection with kNN?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Mutual Nearest Neighbors (MNN):&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MNN requires that the nearest neighbor relationship is mutual: a cell in the query dataset must be a nearest neighbor of a cell in the reference dataset and vice versa.
MNN is designed to be more robust when integrating datasets, as it ensures bidirectional similarity between cells in the query and reference datasets.
It captures correspondence between cells that truly resemble each other in both datasets, which is particularly important when datasets have batch effects or other technical differences.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;k-Nearest Neighbors (kNN) in PCA Projection:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In PCA projection with k-nearest neighbors, you project the query dataset into the reference dataset’s PCA space and then find the nearest neighbors in that space.
The nearest neighbor relationship is one-sided: for each cell in the query dataset, you only find its nearest neighbors in the reference dataset.&lt;/p&gt;
&lt;p&gt;This approach does not check if the reference dataset’s cells also treat the query dataset’s cells as nearest neighbors, which can introduce errors if the datasets are not perfectly aligned or suffer from batch effects.&lt;/p&gt;
&lt;p&gt;Now, let’s find the nearest neighbors for each dataset separately:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(RcppAnnoy)

# Number of nearest neighbors to find
n_neighbors &amp;lt;- 30

# Build an annoy index for the 10k dataset
#annoy_index_10k &amp;lt;- new(AnnoyEuclidean, ncol(cell_embeddings_10k))
annoy_index_10k &amp;lt;- new(AnnoyAngular, ncol(cell_embeddings_10k)) #use cosine distance instead

# Add each cell&amp;#39;s PCA embeddings to the index
for (i in 1:nrow(cell_embeddings_10k)) {
  annoy_index_10k$addItem(i - 1, cell_embeddings_10k[i, ])  # 0-based index for Annoy
}

# Build the index for fast nearest neighbor search
annoy_index_10k$build(10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Find nearest neighbors in 10k for each cell in 3k&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_10k_for_3k &amp;lt;- t(sapply(1:nrow(cell_embeddings_3k), function(i) {
  annoy_index_10k$getNNsByVector(cell_embeddings_3k[i, ], n_neighbors)
}))

# Adjust for R&amp;#39;s 1-based indexing
nn_10k_for_3k &amp;lt;- nn_10k_for_3k + 1  # convert to 1-based indexing for R

head(nn_10k_for_3k)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]
#&amp;gt; [1,] 8625 4994  276 8359 6193 3537 2829  458 7174   556  9059  5384  6644  6776
#&amp;gt; [2,] 8529  101 8577 6438 1352 4502 1823 4128 1408  3174  5458  5818  4932    47
#&amp;gt; [3,] 7951  755 5058  697 4788 3588 1579 3016   59  8250  2686  1372  8247  5741
#&amp;gt; [4,]  109 8618 4996 9207 8432 6036 6990  427 7893  3621  1216  6496  3898  6037
#&amp;gt; [5,]  453 8115 3869 5415 7885 1580 7634 4573 5018  3613  9160  8212  5713  1923
#&amp;gt; [6,] 4220 1816 6418 7896 8123 2081 6142 1257 3355  6038  6524  7300  7951  8520
#&amp;gt;      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]
#&amp;gt; [1,]  3559  8708  3530  1276  5869  4074  3812  1394  3856  5617  2382  7942
#&amp;gt; [2,]  6366  7080  7458  7124  8022  2108  2589  6517  7168  8057  5377  6103
#&amp;gt; [3,]   888  5789  5602  7589  1479  8935  6249  2031  7883  1240  2406  4231
#&amp;gt; [4,]  9133  3517  8078  9193  3508  5606  8444  6135  4659  7513  6105  1226
#&amp;gt; [5,]  2254  2092  1262  7798  4483  8451  7987  8538  8813  4114  1025  6571
#&amp;gt; [6,]  4809   950  8616  9423   697  5939  8861  8240  1320  2801  5871  4783
#&amp;gt;      [,27] [,28] [,29] [,30]
#&amp;gt; [1,]  3689  2264  9399  7011
#&amp;gt; [2,]  7312  8775   974  1744
#&amp;gt; [3,]  8240  1485  4817  4561
#&amp;gt; [4,]  1242  6222  3314  4066
#&amp;gt; [5,]  8184  9222  3823  5013
#&amp;gt; [6,]  3567  6277  3167  1579&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similarly, build an index for the 3k dataset&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# annoy_index_3k &amp;lt;- new(AnnoyEuclidean, ncol(cell_embeddings_3k))
annoy_index_3k &amp;lt;- new(AnnoyAngular, ncol(cell_embeddings_3k)) 

for (i in 1:nrow(cell_embeddings_3k)) {
  annoy_index_3k$addItem(i - 1, cell_embeddings_3k[i, ])  # 0-based index for Annoy
}

annoy_index_3k$build(10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Find nearest neighbors in 3k for each cell in 10k&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_3k_for_10k &amp;lt;- t(sapply(1:nrow(cell_embeddings_10k), function(i) {
  annoy_index_3k$getNNsByVector(cell_embeddings_10k[i, ], n_neighbors)
}))

# Adjust for R&amp;#39;s 1-based indexing
nn_3k_for_10k &amp;lt;- nn_3k_for_10k + 1  # convert to 1-based indexing for R&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A key thing here is that &lt;code&gt;RcppAnnoy&lt;/code&gt; in &lt;code&gt;C&lt;/code&gt; is 0 based, and R is 1 based.
We need to add 1 to the index. Otherwise, I will get non-sense results!&lt;/p&gt;
&lt;div id=&#34;identify-mutual-nearest-neighbors-mnn&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Identify Mutual Nearest Neighbors (MNN)&lt;/h3&gt;
&lt;p&gt;Now identify Mutual Nearest Neighbors and include the transfer score:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;labels_10k &amp;lt;- as.character(labels_10k)

# Create empty vectors to store the scores and labels
pbmc3k_transferred_labels &amp;lt;- rep(NA, nrow(cell_embeddings_3k))
pbmc3k_transfer_scores &amp;lt;- rep(0, nrow(cell_embeddings_3k))

# Loop through each cell in the 3k dataset to find the mutual nearest neighbors
for (i in 1:nrow(cell_embeddings_3k)) {
  # Get nearest neighbors of the i-th 3k cell in 10k
  nn_in_10k &amp;lt;- nn_10k_for_3k[i, ]
  
  # Initialize count for mutual nearest neighbors
  mutual_count &amp;lt;- 0
  
  # Check mutual nearest neighbors
  for (nn in nn_in_10k) {
    # Check if i-th 3k cell is a nearest neighbor for the nn-th 10k cell
    if (i %in% nn_3k_for_10k[nn, ]) {  # Correct 1-based indexing
      mutual_count &amp;lt;- mutual_count + 1
      
      # Transfer the label from the 10k cell to the 3k cell
      pbmc3k_transferred_labels[i] &amp;lt;- labels_10k[nn]
    }
  }
  
  # Calculate the transfer score (mutual neighbor count / total neighbors)
  pbmc3k_transfer_scores[i] &amp;lt;- mutual_count / n_neighbors
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;handling-cells-without-mnn&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Handling Cells Without MNN:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Label Transfer for Non-Mutual Nearest Neighbors
Seurat handles cells that are not mutual nearest neighbors (i.e., cells that do not have a direct anchor) in the following ways:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Weighting Anchors:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Seurat uses a weighted transfer system. Even if a query cell does not have a direct MNN, the label transfer process still considers the relationship between that query cell and the nearest anchors (the mutual nearest neighbors).&lt;/p&gt;
&lt;p&gt;For cells that are not mutual nearest neighbors, their labels are predicted based on the similarity (distance) to the identified anchors. The influence of each anchor is weighted according to its distance from the query cell.
Extrapolation for Non-MNN Cells:&lt;/p&gt;
&lt;p&gt;For cells in the query dataset that don’t have mutual nearest neighbors, the labels can still be inferred based on their position relative to the MNN cells.&lt;/p&gt;
&lt;p&gt;Seurat’s &lt;code&gt;TransferData&lt;/code&gt; function takes into account the proximity of these non-MNN cells to the anchor cells and extrapolates the labels based on the information from the anchor set. The cells closest to the MNN cells will receive a higher weight when transferring labels.
Prediction Confidence:&lt;/p&gt;
&lt;p&gt;Seurat also provides prediction scores that indicate the confidence of the label transfer for each cell. Cells that do not have strong mutual nearest neighbors may receive lower confidence scores.&lt;/p&gt;
&lt;p&gt;For cells without MNN, we can still assign labels based on the nearest neighbor from pbmc10k, but their transfer score will be lower (or zero). Our implementation just use the nearest neighbor in the 10k even they are not mutually nearest to simplify the demonstration.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fill in missing labels for cells without MNN based on nearest neighbor in 10k
for (i in 1:length(pbmc3k_transferred_labels)) {
  if (is.na(pbmc3k_transferred_labels[i])) {
    # Assign the label of the nearest 10k cell
    nearest_10k_cell &amp;lt;- nn_10k_for_3k[i, 1]  # First nearest neighbor
    pbmc3k_transferred_labels[i] &amp;lt;- labels_10k[nearest_10k_cell]
    
    # Assign a lower score for non-mutual neighbors
    pbmc3k_transfer_scores[i] &amp;lt;- 0.01  # assign a small score like 0.01 for non-mutual
  }
}

head(pbmc3k_transferred_labels)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;CD4 Memory&amp;quot;        &amp;quot;B cell progenitor&amp;quot; &amp;quot;CD4 Memory&amp;quot;       
#&amp;gt; [4] &amp;quot;CD16+ Monocytes&amp;quot;   &amp;quot;NK cell&amp;quot;           &amp;quot;CD4 Memory&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(pbmc3k_transfer_scores)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 0.1000000 0.3666667 0.4000000 0.0100000 0.1000000 0.4333333&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see how it looks like&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Add predictions to the query dataset
pbmc3k$pbmc3k_transferred_labels&amp;lt;- pbmc3k_transferred_labels

# predicted.id is from Seurat&amp;#39;s wrapper function, pbmc3k_transferred_labels is from our naive MNN implementation

table(pbmc3k$pbmc3k_transferred_labels, pbmc3k$predicted.id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                         
#&amp;gt;                          B cell progenitor CD14+ Monocytes CD16+ Monocytes
#&amp;gt;   B cell progenitor                     85               1               0
#&amp;gt;   CD14+ Monocytes                        0             296               0
#&amp;gt;   CD16+ Monocytes                        0              54             135
#&amp;gt;   CD4 Memory                             0              27              10
#&amp;gt;   CD4 Naive                              0              98               3
#&amp;gt;   CD8 effector                           0               1               0
#&amp;gt;   CD8 Naive                              0               4               1
#&amp;gt;   Dendritic cell                         0               5               0
#&amp;gt;   Double negative T cell                 0               0               0
#&amp;gt;   NK cell                                1               0               0
#&amp;gt;   pDC                                    0               0               0
#&amp;gt;   Platelets                              0               3               0
#&amp;gt;   pre-B cell                             8               4               0
#&amp;gt;                         
#&amp;gt;                          CD4 Memory CD4 Naive CD8 effector CD8 Naive
#&amp;gt;   B cell progenitor               0         1            0         0
#&amp;gt;   CD14+ Monocytes                 0         0            0         0
#&amp;gt;   CD16+ Monocytes                 0         0            0         0
#&amp;gt;   CD4 Memory                    507        92           29         9
#&amp;gt;   CD4 Naive                      41       431            3        12
#&amp;gt;   CD8 effector                    2         0          141         0
#&amp;gt;   CD8 Naive                       8         8            2       118
#&amp;gt;   Dendritic cell                  0         0            0         0
#&amp;gt;   Double negative T cell          0         0            2         0
#&amp;gt;   NK cell                         0         0            1         0
#&amp;gt;   pDC                             0         0            0         0
#&amp;gt;   Platelets                       0         0            0         0
#&amp;gt;   pre-B cell                      1         0            1         0
#&amp;gt;                         
#&amp;gt;                          Dendritic cell Double negative T cell NK cell pDC
#&amp;gt;   B cell progenitor                   1                      0       2   0
#&amp;gt;   CD14+ Monocytes                     0                      0       0   0
#&amp;gt;   CD16+ Monocytes                     0                      0       0   0
#&amp;gt;   CD4 Memory                          2                     32       3   0
#&amp;gt;   CD4 Naive                           1                      3       0   0
#&amp;gt;   CD8 effector                        0                      9      28   0
#&amp;gt;   CD8 Naive                           0                      2       0   0
#&amp;gt;   Dendritic cell                     24                      0       0   0
#&amp;gt;   Double negative T cell              0                     55       0   0
#&amp;gt;   NK cell                             0                      0     121   0
#&amp;gt;   pDC                                 2                      0       0   4
#&amp;gt;   Platelets                           0                      0       0   0
#&amp;gt;   pre-B cell                          2                      0       0   0
#&amp;gt;                         
#&amp;gt;                          Platelets pre-B cell
#&amp;gt;   B cell progenitor              0         15
#&amp;gt;   CD14+ Monocytes                0          0
#&amp;gt;   CD16+ Monocytes                0          0
#&amp;gt;   CD4 Memory                     4          0
#&amp;gt;   CD4 Naive                      0          1
#&amp;gt;   CD8 effector                   0          0
#&amp;gt;   CD8 Naive                      0          0
#&amp;gt;   Dendritic cell                 0          0
#&amp;gt;   Double negative T cell         0          0
#&amp;gt;   NK cell                        0          0
#&amp;gt;   pDC                            1          0
#&amp;gt;   Platelets                      8          0
#&amp;gt;   pre-B cell                     0        235&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Visualize in a heatmap&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(pbmc3k$pbmc3k_transferred_labels, pbmc3k$predicted.id) %&amp;gt;%
        as.matrix() %&amp;gt;%
        scale() %&amp;gt;%
        Heatmap(cluster_rows = FALSE, cluster_columns= FALSE, name= &amp;quot;scaled\ncell number&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-10-17-how-seurat-pca-label-transfer_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our native implementation of MNN is not exactly the same as Seurat. Seurat’s MNN implementation includes additional optimization like PC scaling and anchor filtering, but it is very good to see we get reasonable results!&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;Seurat&lt;/code&gt;(Tim Stuart et al 2019), the other way is to use Canonical Correlation Analysis (CCA) and we will leave it to a future post!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/CCA.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;final-note&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Final Note&lt;/h3&gt;
&lt;p&gt;I asked ChatGPT for help a lot, and it gave me a good starting point for the code. I had
to adapt the code when I had the errors. Anyway, it shows how powerful &lt;code&gt;chatGPT&lt;/code&gt; is and
you can use it as you study companion. Embrace AI or it will replace people who do not use it :)&lt;/p&gt;
&lt;p&gt;Happy Learning!&lt;/p&gt;
&lt;p&gt;Tommy&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Single-cell analysis best practices and challenges</title>
      <link>/talk/2024-fog-singlecell/</link>
      <pubDate>Wed, 25 Sep 2024 11:00:00 +0000</pubDate>
      
      <guid>/talk/2024-fog-singlecell/</guid>
      <description>&lt;p&gt;The Single Cell Track begins with sessions on &amp;lsquo;Improving Your Understanding of Disease Complexity&amp;rsquo; with Saurabh Vishnu Laddha and a panel on &amp;lsquo;Navigating the Crossroads of Single Cell Genomics and Human Genetics&amp;rsquo; with Joseph Powell, Marisol Alvarez-Martinez, PhD, Fan Zhang, PhD and Giorgio Gaglia&lt;/p&gt;

&lt;p&gt;Occurring in parallel on the Spatial Omics Track, we have two sessions on multimodal spatial methods, including proteomics and transcriptomics and mass spec imaging, featuring Tullia Bruno and Elizabeth Neumann&lt;/p&gt;

&lt;p&gt;Afterwards, on the Single Cell Track, we have session on mastering sample preparation for single cell, led by Ashleigh Lister and Kristin Beaumont, covering all manner of problems related to single cell, nuclei and tough tissues.&lt;/p&gt;

&lt;p&gt;The Spatial Omics Track then features two sessions on &amp;lsquo;Defining Cellular Populations, Dynamics and Interactions&amp;rsquo; with Miao-Ping Chien and Gregory Schwartz. Learn about new methods for cell-cell communication and linking genotype to phenotype.&lt;/p&gt;

&lt;p&gt;Finally, the Single Cell Track closes with sessions on data analysis, with revolutionary sessions on AI with Yann Abraham and Jun Ding, finishing with the Big Challenge Session on data analysis led by 🎯 &lt;strong&gt;Ming &amp;ldquo;Tommy&amp;rdquo; Tang&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/fog.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>You need to master it if you deal with genomics data</title>
      <link>/post/genomic-interval/</link>
      <pubDate>Sat, 21 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/genomic-interval/</guid>
      <description>&lt;p&gt;&lt;strong&gt;To not miss a post like this, sign up for my &lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/profile&#34;&gt;newsletter&lt;/a&gt; to learn computational
biology and bioinformatics.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;motivation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Motivation&lt;/h3&gt;
&lt;p&gt;What’s the most common problem you need to solve when dealing with genomics data?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For me, it is Genomic Intervals!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The genomics data usually represents linearly: chromosome name, start and end.&lt;/p&gt;
&lt;p&gt;We use it to define a region in the genome ( A peak from ChIP-seq data);
the location of a gene, a DNA methylation site ( a single point), a mutation call
(a single point), and a duplication region in cancer etc.&lt;/p&gt;
&lt;p&gt;When I first started to learn programming 12 years ago in a wet lab, my task was
to find where a set of peaks (from ChIP-seq) bind to genes. To solve this, we have
two files (dummy example below):&lt;/p&gt;
&lt;p&gt;a peak file with chr, start, end for each row&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chr1 200 300 peak1
chr2 400 500 peak2
chr3 456 888 peak3
.....&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A gene file also has chr, start, end, and name for each row denoting the gene’s transcription start sites (TSS) + 50 bp upstream and downstream:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chr1 250 350 gene1
chr2 600 700 gene2
chr3 700 800 gene3
....&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The task is “easy”, find the overlaps of those two files (in fact, you can eyeball
this example, peak1 binds to gene1, peak3 binds to gene3)!&lt;/p&gt;
&lt;p&gt;As a beginner, I did not know much, so I read in both files with Python, loop over
the lines and compare.&lt;/p&gt;
&lt;p&gt;For two regions to overlap, chr should be the same and there could be the following
4 conditions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
                 start1 ------------------end1
           start2----------------end2



                start1 ------------------end1
                           start2----------------end2



              start1 ---------------------end1
                     start2---------end2



                 start1 ---------------end1
              start2---------------------------end2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These are a lot of conditions to compare! Instead, we can find the conditions that the two regions do not overlap:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                     start1 ------------------end1
          start2----------------end2


            start 1 ------------------end1
                                           start2----------------end2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The comparison will be: if &lt;strong&gt;NOT&lt;/strong&gt; ((start2 &amp;gt; end1) &lt;strong&gt;or&lt;/strong&gt; (start1 &amp;gt; end2)): then two regions overlap!
My brute force method works! and I felt accomplished as a beginner.&lt;/p&gt;
&lt;p&gt;As I become a little more experienced, I get to know the &lt;a href=&#34;https://en.wikipedia.org/wiki/Interval_tree&#34;&gt;interval tree&lt;/a&gt; data structure
which makes those types of comparisons much faster and efficient.&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;2010&lt;/strong&gt;, &lt;a href=&#34;https://bedtools.readthedocs.io/en/latest/index.html&#34;&gt;bedtools&lt;/a&gt; was published! and in a single command (&lt;code&gt;bedtools intersect&lt;/code&gt;) you
can accomplish what I did with my Python script.&lt;/p&gt;
&lt;p&gt;Remember, I wrote my script in &lt;strong&gt;2012&lt;/strong&gt;, two years after bedtools was published.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The problem was I did not know this tool even existed!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As a beginner, ignorance of what’s out there is the price to pay. (wink, follow me on X &lt;a href=&#34;https://x.com/tangming2005&#34; class=&#34;uri&#34;&gt;https://x.com/tangming2005&lt;/a&gt;, I tweet tools and papers)&lt;/p&gt;
&lt;p&gt;My story was not alone. Last Thursday, I had the pleasure and honor to have dinner with &lt;a href=&#34;https://genetics.wustl.edu/people/ting-wang-phdthe-sanford-and-karen-loewentheil-distinguished-professor-of-medicine-and-head-department-of-genetics/&#34;&gt;Dr. Ting Wang&lt;/a&gt;.
We invited him to give a talk at our company.&lt;/p&gt;
&lt;p&gt;He told me that in the early days, he wrote a Perl script to do the intersection of
genomic regions and found TP53 binds to Transposable elements(TE). see his paper &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/18003932/&#34; class=&#34;uri&#34;&gt;https://pubmed.ncbi.nlm.nih.gov/18003932/&lt;/a&gt; &lt;strong&gt;in 2007&lt;/strong&gt;. His lab has published 3 papers on
Nature Genetics on TE. e.g., &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/36973455/&#34;&gt;Pan-cancer analysis identifies tumor-specific antigens derived from transposable elements&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Of course, Ting was a formally trained PhD in bioinformatics and I am sure his Perl
script is much better than my crappy one.&lt;/p&gt;
&lt;p&gt;But this tells you how common this type of analysis is, and &lt;code&gt;bedtools&lt;/code&gt; comes to the rescue in 2010.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bonus:&lt;/strong&gt; watch &lt;a href=&#34;https://www.youtube.com/watch?v=UHnRjGcMp8M&amp;amp;&#34;&gt;this video&lt;/a&gt; on how I use conda to install bedtools.&lt;/p&gt;
&lt;p&gt;Later, I started to learn more about the Bioconductor ecosystem and learned the
&lt;code&gt;GenomicRanges&lt;/code&gt; package which is the foundation of dealing with genomic intervals
in &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can work with bedtools on command line. But if you want to work within R,
let’s use &lt;code&gt;GenomicRanges&lt;/code&gt;. Before that, we need to know &lt;code&gt;IRanges&lt;/code&gt; upon which &lt;code&gt;GenomicRanges&lt;/code&gt; is built.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction-to-iranges&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction to IRanges&lt;/h3&gt;
&lt;p&gt;In Biconductor, the &lt;a href=&#34;https://bioconductor.org/packages/release/bioc/html/IRanges.html&#34;&gt;&lt;code&gt;IRanges&lt;/code&gt;&lt;/a&gt; implements
the Interval data structure.&lt;/p&gt;
&lt;p&gt;Let’s take a look at some examples&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(IRanges)
ir &amp;lt;- IRanges(c(1, 8, 14, 15, 19), 
              width=c(12, 6, 6, 15, 6))

ir2 &amp;lt;- IRanges(c(5, 9, 12, 25, 50), 
              width=c(3, 6, 6, 15, 6))

ir &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; IRanges object with 5 ranges and 0 metadata columns:
#&amp;gt;           start       end     width
#&amp;gt;       &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt;
#&amp;gt;   [1]         1        12        12
#&amp;gt;   [2]         8        13         6
#&amp;gt;   [3]        14        19         6
#&amp;gt;   [4]        15        29        15
#&amp;gt;   [5]        19        24         6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ir2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; IRanges object with 5 ranges and 0 metadata columns:
#&amp;gt;           start       end     width
#&amp;gt;       &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt;
#&amp;gt;   [1]         5         7         3
#&amp;gt;   [2]         9        14         6
#&amp;gt;   [3]        12        17         6
#&amp;gt;   [4]        25        39        15
#&amp;gt;   [5]        50        55         6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An IRanges object has start, end and width.&lt;/p&gt;
&lt;p&gt;Let’s visualize them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges &amp;lt;- function(x, xlim=x, main=deparse(substitute(x)),
                        col=&amp;quot;black&amp;quot;, sep=0.5, ...) {
         height &amp;lt;- 1
         if (is(xlim, &amp;quot;IntegerRanges&amp;quot;))
                 xlim &amp;lt;- c(min(start(xlim)), max(end(xlim)))
         bins &amp;lt;- disjointBins(IRanges(start(x), end(x) + 1))
        plot.new()
        plot.window(xlim, c(0, max(bins)*(height + sep)))
        ybottom &amp;lt;- bins * (sep + height) - height
        rect(start(x)-0.5, ybottom, end(x)+0.5, ybottom + height, col=col, ...)
        title(main)
        axis(1)
 }

plotRanges(ir)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;some useful functions from the package. Check the visualization to understand the
output of each function.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;intersect&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;intersect(ir, ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; IRanges object with 3 ranges and 0 metadata columns:
#&amp;gt;           start       end     width
#&amp;gt;       &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt;
#&amp;gt;   [1]         5         7         3
#&amp;gt;   [2]         9        17         9
#&amp;gt;   [3]        25        29         5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(intersect(ir, ir2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;reduce&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reduce(ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; IRanges object with 4 ranges and 0 metadata columns:
#&amp;gt;           start       end     width
#&amp;gt;       &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt;
#&amp;gt;   [1]         5         7         3
#&amp;gt;   [2]         9        17         9
#&amp;gt;   [3]        25        39        15
#&amp;gt;   [4]        50        55         6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(reduce(ir2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;union&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;union(ir, ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; IRanges object with 2 ranges and 0 metadata columns:
#&amp;gt;           start       end     width
#&amp;gt;       &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt;
#&amp;gt;   [1]         1        39        39
#&amp;gt;   [2]        50        55         6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(union(ir, ir2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setdiff(ir, ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; IRanges object with 3 ranges and 0 metadata columns:
#&amp;gt;           start       end     width
#&amp;gt;       &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt;
#&amp;gt;   [1]         1         4         4
#&amp;gt;   [2]         8         8         1
#&amp;gt;   [3]        18        24         7&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(setdiff(ir, ir2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;flank&lt;/code&gt; generates flanking ranges for each range in x. If start is TRUE for a given range, the flanking occurs at the start, otherwise the end. The widths of the flanks are given by the width parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flank(ir, width = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; IRanges object with 5 ranges and 0 metadata columns:
#&amp;gt;           start       end     width
#&amp;gt;       &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt;
#&amp;gt;   [1]        -1         0         2
#&amp;gt;   [2]         6         7         2
#&amp;gt;   [3]        12        13         2
#&amp;gt;   [4]        13        14         2
#&amp;gt;   [5]        17        18         2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(flank(ir, width=2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;shift&lt;/code&gt; shifts all the ranges in x by the amount specified by the shift argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;shift(ir2, shift=2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; IRanges object with 5 ranges and 0 metadata columns:
#&amp;gt;           start       end     width
#&amp;gt;       &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt;
#&amp;gt;   [1]         7         9         3
#&amp;gt;   [2]        11        16         6
#&amp;gt;   [3]        14        19         6
#&amp;gt;   [4]        27        41        15
#&amp;gt;   [5]        52        57         6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(shift(ir2, shift=2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;resize&lt;/code&gt; resizes the ranges to the specified width where either the start, end, or center is used as an anchor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;resize(ir, width = 2, fix=&amp;quot;start&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; IRanges object with 5 ranges and 0 metadata columns:
#&amp;gt;           start       end     width
#&amp;gt;       &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt;
#&amp;gt;   [1]         1         2         2
#&amp;gt;   [2]         8         9         2
#&amp;gt;   [3]        14        15         2
#&amp;gt;   [4]        15        16         2
#&amp;gt;   [5]        19        20         2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(resize(ir, width = 2, fix=&amp;quot;start&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;precede(x, subject, select=c(&#34;first&#34;, &#34;all&#34;))&lt;/code&gt;: For each range in x, precede returns the index of the interval in subject that is directly preceded by the query range. &lt;strong&gt;Overlapping ranges&lt;/strong&gt; are excluded. NA is returned when there are no qualifying ranges in subject.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;precede(ir, ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 4 4 4 5 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;follow(x, subject, select=c(&#34;last&#34;, &#34;all&#34;))&lt;/code&gt;: The opposite of precede, this function returns the index of the range in subject that a query range in x directly follows. Overlapping ranges are excluded. NA is returned when there are no qualifying ranges in subject&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;follow(ir, ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] NA  1  1  2  3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;gaps&lt;/code&gt; and &lt;code&gt;disjoin&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gaps(ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; IRanges object with 3 ranges and 0 metadata columns:
#&amp;gt;           start       end     width
#&amp;gt;       &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt;
#&amp;gt;   [1]         8         8         1
#&amp;gt;   [2]        18        24         7
#&amp;gt;   [3]        40        49        10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(gaps(ir2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-13-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;disjoin(ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; IRanges object with 6 ranges and 0 metadata columns:
#&amp;gt;           start       end     width
#&amp;gt;       &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt;
#&amp;gt;   [1]         5         7         3
#&amp;gt;   [2]         9        11         3
#&amp;gt;   [3]        12        14         3
#&amp;gt;   [4]        15        17         3
#&amp;gt;   [5]        25        39        15
#&amp;gt;   [6]        50        55         6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotRanges(disjoin(ir2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-09-21-genomic-intervals_files/figure-html/unnamed-chunk-13-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The most common operation is to find the overlaps.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;overlap&amp;lt;- findOverlaps(ir, ir2)
overlap&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Hits object with 9 hits and 0 metadata columns:
#&amp;gt;       queryHits subjectHits
#&amp;gt;       &amp;lt;integer&amp;gt;   &amp;lt;integer&amp;gt;
#&amp;gt;   [1]         1           1
#&amp;gt;   [2]         1           2
#&amp;gt;   [3]         1           3
#&amp;gt;   [4]         2           2
#&amp;gt;   [5]         2           3
#&amp;gt;   [6]         3           2
#&amp;gt;   [7]         3           3
#&amp;gt;   [8]         4           3
#&amp;gt;   [9]         4           4
#&amp;gt;   -------
#&amp;gt;   queryLength: 5 / subjectLength: 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;overlap&lt;/code&gt; is a Hits object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;queryHits(overlap)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 1 1 1 2 2 3 3 4 4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;subjectHits(overlap)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 1 2 3 2 3 2 3 3 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It returns the indices of the query hits and the subject hits.&lt;/p&gt;
&lt;p&gt;You can turn it to a matrix:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.matrix(overlap)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;       queryHits subjectHits
#&amp;gt;  [1,]         1           1
#&amp;gt;  [2,]         1           2
#&amp;gt;  [3,]         1           3
#&amp;gt;  [4,]         2           2
#&amp;gt;  [5,]         2           3
#&amp;gt;  [6,]         3           2
#&amp;gt;  [7,]         3           3
#&amp;gt;  [8,]         4           3
#&amp;gt;  [9,]         4           4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;distance&lt;/code&gt; returns the pair-wise distance of two GenomicRanges.
The distance method is symmetric; y cannot be missing. If x and y are not the same length, the shortest will be recycled to match the length of the longest. The select argument is not available for distance because comparisons are made in a pair-wise fashion. The return value is the length of the longest of x and y.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;distance(ir, ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]  0  0  0  0 25&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;nearest&lt;/code&gt; performs conventional nearest neighbor finding. Returns an integer vector
containing the index of the nearest neighbor range in subject for each range in query:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nearest(ir, ir2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 1 1 2 2 4&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction-to-genomicranges&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction to GenomicRanges&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;GenomicRanges&lt;/code&gt; is a natural extension of the &lt;code&gt;IRanges&lt;/code&gt;, adding chromosome name
and the strand information:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#if (!require(&amp;quot;BiocManager&amp;quot;, quietly = TRUE))
#    install.packages(&amp;quot;BiocManager&amp;quot;)
# BiocManager::install(&amp;quot;GenomicRanges&amp;quot;)

library(GenomicRanges)

x &amp;lt;- GRanges(&amp;quot;chr1&amp;quot;, IRanges(c(2, 9) , c(7, 19)), strand=c(&amp;quot;+&amp;quot;, &amp;quot;-&amp;quot;))
y &amp;lt;- GRanges(&amp;quot;chr1&amp;quot;, IRanges(5, 10), strand=&amp;quot;-&amp;quot;) 

union(x, y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 2 ranges and 0 metadata columns:
#&amp;gt;       seqnames    ranges strand
#&amp;gt;          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;
#&amp;gt;   [1]     chr1       2-7      +
#&amp;gt;   [2]     chr1      5-19      -
#&amp;gt;   -------
#&amp;gt;   seqinfo: 1 sequence from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;union(x, y, ignore.strand=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 1 range and 0 metadata columns:
#&amp;gt;       seqnames    ranges strand
#&amp;gt;          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;
#&amp;gt;   [1]     chr1      2-19      *
#&amp;gt;   -------
#&amp;gt;   seqinfo: 1 sequence from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;intersect(x, y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 1 range and 0 metadata columns:
#&amp;gt;       seqnames    ranges strand
#&amp;gt;          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;
#&amp;gt;   [1]     chr1      9-10      -
#&amp;gt;   -------
#&amp;gt;   seqinfo: 1 sequence from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;intersect(x, y, ignore.strand=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 2 ranges and 0 metadata columns:
#&amp;gt;       seqnames    ranges strand
#&amp;gt;          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;
#&amp;gt;   [1]     chr1       5-7      *
#&amp;gt;   [2]     chr1      9-10      *
#&amp;gt;   -------
#&amp;gt;   seqinfo: 1 sequence from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setdiff(x, y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 2 ranges and 0 metadata columns:
#&amp;gt;       seqnames    ranges strand
#&amp;gt;          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;
#&amp;gt;   [1]     chr1       2-7      +
#&amp;gt;   [2]     chr1     11-19      -
#&amp;gt;   -------
#&amp;gt;   seqinfo: 1 sequence from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setdiff(x, y, ignore.strand=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 2 ranges and 0 metadata columns:
#&amp;gt;       seqnames    ranges strand
#&amp;gt;          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;
#&amp;gt;   [1]     chr1       2-4      *
#&amp;gt;   [2]     chr1     11-19      *
#&amp;gt;   -------
#&amp;gt;   seqinfo: 1 sequence from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Other functions behavior similarily with the ones in &lt;code&gt;IRanges&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flank(x, width = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 2 ranges and 0 metadata columns:
#&amp;gt;       seqnames    ranges strand
#&amp;gt;          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;
#&amp;gt;   [1]     chr1       0-1      +
#&amp;gt;   [2]     chr1     20-21      -
#&amp;gt;   -------
#&amp;gt;   seqinfo: 1 sequence from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;promoters(x, upstream = 2, downstream = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 2 ranges and 0 metadata columns:
#&amp;gt;       seqnames    ranges strand
#&amp;gt;          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;
#&amp;gt;   [1]     chr1       0-3      +
#&amp;gt;   [2]     chr1     18-21      -
#&amp;gt;   -------
#&amp;gt;   seqinfo: 1 sequence from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that it takes account of the strand information. When the strand is &lt;code&gt;-&lt;/code&gt;.
the promoter returns the range around the &lt;code&gt;end&lt;/code&gt; position.&lt;/p&gt;
&lt;p&gt;You can use &lt;code&gt;resize&lt;/code&gt; to return the transcription start site:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;resize(x, width=1, fix = &amp;quot;start&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 2 ranges and 0 metadata columns:
#&amp;gt;       seqnames    ranges strand
#&amp;gt;          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;
#&amp;gt;   [1]     chr1         2      +
#&amp;gt;   [2]     chr1        19      -
#&amp;gt;   -------
#&amp;gt;   seqinfo: 1 sequence from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;findOverlaps(x, y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Hits object with 1 hit and 0 metadata columns:
#&amp;gt;       queryHits subjectHits
#&amp;gt;       &amp;lt;integer&amp;gt;   &amp;lt;integer&amp;gt;
#&amp;gt;   [1]         2           1
#&amp;gt;   -------
#&amp;gt;   queryLength: 2 / subjectLength: 1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;a-real-world-example&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A real-world example&lt;/h3&gt;
&lt;p&gt;Let’s see how can we use it for a real-world bioinformatics problem.&lt;/p&gt;
&lt;p&gt;Go to &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE120885&#34;&gt;GSE120885&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;Download HIF1a ChIP-seq peaks at &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3417778&#34; class=&#34;uri&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3417778&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Download HIF2a ChIP-seq peaks at &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3417780&#34; class=&#34;uri&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3417780&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You should have two files downloaded&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# HIF1a
GSM3417778_6h_0.5__PM14_1_peaks.bed.gz 

# HIF2a
GSM3417780_6h_0.5__PM9_1_peaks.bed.gz&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;HIF1α (Hypoxia-Inducible Factor 1α) and HIF2α (Hypoxia-Inducible Factor 2α) are transcription factors that help cells respond to low oxygen (hypoxia). HIF1α regulates genes involved in oxygen transport and metabolism, while HIF2α plays a role in more specific processes like stem cell function and vascular development. Both proteins are crucial in cancer biology, as they enable tumors to adapt to low oxygen conditions, promoting growth and survival under stress.&lt;/p&gt;
&lt;p&gt;Let’s ask simple questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How many HIF1a peaks overlap with HIF2a peaks?&lt;/li&gt;
&lt;li&gt;How many HIF1a peaks located at the promoter regions? (Note the peaks coordinates are hg19 version)&lt;/li&gt;
&lt;li&gt;How to get the nearest genes of the HIF1a peaks?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can use &lt;code&gt;rtracklayer&lt;/code&gt; to load the bed files.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# BiocManager::install(&amp;quot;rtracklayer&amp;quot;)
library(rtracklayer)
HIF1_peaks&amp;lt;- import(&amp;quot;~/blog_data/GSM3417778_6h_0.5__PM14_1_peaks.bed.gz&amp;quot;)
HIF2_peaks&amp;lt;- import(&amp;quot;~/blog_data/GSM3417780_6h_0.5__PM9_1_peaks.bed.gz&amp;quot;)

HIF1_peaks&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 1496 ranges and 2 metadata columns:
#&amp;gt;          seqnames              ranges strand |           name     score
#&amp;gt;             &amp;lt;Rle&amp;gt;           &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; |    &amp;lt;character&amp;gt; &amp;lt;numeric&amp;gt;
#&amp;gt;      [1]     chr1       763060-763168      * |    MACS_peak_1     60.05
#&amp;gt;      [2]     chr1       954905-955303      * |    MACS_peak_2    106.52
#&amp;gt;      [3]     chr1     5439920-5440090      * |    MACS_peak_3     51.16
#&amp;gt;      [4]     chr1     5765488-5765761      * |    MACS_peak_4     57.23
#&amp;gt;      [5]     chr1     5882033-5882303      * |    MACS_peak_5     50.23
#&amp;gt;      ...      ...                 ...    ... .            ...       ...
#&amp;gt;   [1492]     chrX   80823360-80823533      * | MACS_peak_1492     59.37
#&amp;gt;   [1493]     chrX 133683313-133683581      * | MACS_peak_1493    119.01
#&amp;gt;   [1494]     chrX 151143115-151143368      * | MACS_peak_1494     93.84
#&amp;gt;   [1495]     chrX 152582879-152583036      * | MACS_peak_1495     53.76
#&amp;gt;   [1496]     chrX 153606352-153606601      * | MACS_peak_1496     68.16
#&amp;gt;   -------
#&amp;gt;   seqinfo: 29 sequences from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;HIF2_peaks&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 1417 ranges and 2 metadata columns:
#&amp;gt;          seqnames              ranges strand |           name     score
#&amp;gt;             &amp;lt;Rle&amp;gt;           &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; |    &amp;lt;character&amp;gt; &amp;lt;numeric&amp;gt;
#&amp;gt;      [1]     chr1     2383154-2383508      * |    MACS_peak_1     82.11
#&amp;gt;      [2]     chr1     2566751-2567041      * |    MACS_peak_2     51.35
#&amp;gt;      [3]     chr1     3459508-3460142      * |    MACS_peak_3     96.47
#&amp;gt;      [4]     chr1     3464750-3465045      * |    MACS_peak_4     51.45
#&amp;gt;      [5]     chr1     4318344-4318487      * |    MACS_peak_5     61.02
#&amp;gt;      ...      ...                 ...    ... .            ...       ...
#&amp;gt;   [1413]     chrX 102862582-102862698      * | MACS_peak_1413     53.25
#&amp;gt;   [1414]     chrX 116435651-116435799      * | MACS_peak_1414     50.49
#&amp;gt;   [1415]     chrX 127756374-127756490      * | MACS_peak_1415     54.87
#&amp;gt;   [1416]     chrX 130129816-130129963      * | MACS_peak_1416     50.70
#&amp;gt;   [1417]     chrX 142617589-142617695      * | MACS_peak_1417     50.34
#&amp;gt;   -------
#&amp;gt;   seqinfo: 26 sequences from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How many peaks HIF1a overlaps with HIF2a?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(HIF1_peaks)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 1496&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(HIF2_peaks)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 1417&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;subsetByOverlaps(HIF1_peaks, HIF2_peaks)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 93 ranges and 2 metadata columns:
#&amp;gt;              seqnames              ranges strand |           name     score
#&amp;gt;                 &amp;lt;Rle&amp;gt;           &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; |    &amp;lt;character&amp;gt; &amp;lt;numeric&amp;gt;
#&amp;gt;    [1]           chr1     8938337-8939542      * |    MACS_peak_9   1224.68
#&amp;gt;    [2]           chr1   21564937-21565326      * |   MACS_peak_23     90.64
#&amp;gt;    [3]           chr1   23503867-23504391      * |   MACS_peak_24     58.14
#&amp;gt;    [4]           chr1   65614184-65614750      * |   MACS_peak_45    369.22
#&amp;gt;    [5]           chr1 142535453-142535612      * |   MACS_peak_58     66.92
#&amp;gt;    ...            ...                 ...    ... .            ...       ...
#&amp;gt;   [89]           chr8 134387536-134388301      * | MACS_peak_1411    421.12
#&amp;gt;   [90]           chr9   93956056-93956397      * | MACS_peak_1448     57.95
#&amp;gt;   [91]           chr9 121093933-121094280      * | MACS_peak_1468    135.11
#&amp;gt;   [92]           chr9 136202761-136203184      * | MACS_peak_1483     54.57
#&amp;gt;   [93] chrUn_gl000220       118399-126340      * | MACS_peak_1487    101.57
#&amp;gt;   -------
#&amp;gt;   seqinfo: 29 sequences from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;93 HIF1a peaks overlap with HIF2a peaks&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;subsetByOverlaps(HIF2_peaks, HIF1_peaks)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 94 ranges and 2 metadata columns:
#&amp;gt;              seqnames              ranges strand |           name     score
#&amp;gt;                 &amp;lt;Rle&amp;gt;           &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; |    &amp;lt;character&amp;gt; &amp;lt;numeric&amp;gt;
#&amp;gt;    [1]           chr1     8938913-8939522      * |   MACS_peak_11    251.69
#&amp;gt;    [2]           chr1   21564813-21565350      * |   MACS_peak_33    389.00
#&amp;gt;    [3]           chr1   23503900-23504222      * |   MACS_peak_36     52.22
#&amp;gt;    [4]           chr1   65614200-65614665      * |   MACS_peak_69    143.21
#&amp;gt;    [5]           chr1 142535444-142535599      * |   MACS_peak_93     68.69
#&amp;gt;    ...            ...                 ...    ... .            ...       ...
#&amp;gt;   [90]           chr8 134387445-134388247      * | MACS_peak_1329    224.87
#&amp;gt;   [91]           chr9   93955941-93956494      * | MACS_peak_1369    363.15
#&amp;gt;   [92]           chr9 121094013-121094130      * | MACS_peak_1391     63.00
#&amp;gt;   [93]           chr9 136203030-136203291      * | MACS_peak_1402     51.10
#&amp;gt;   [94] chrUn_gl000220       118416-125420      * | MACS_peak_1410    212.47
#&amp;gt;   -------
#&amp;gt;   seqinfo: 26 sequences from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;94 HIF2a peaks overlap with HIF1a peaks.&lt;/p&gt;
&lt;p&gt;There must be 2 HIF2a peaks overlap with the same HIF1a peak.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# BiocManager::install(&amp;quot;TxDb.Hsapiens.UCSC.hg19.knownGene&amp;quot;)
library(TxDb.Hsapiens.UCSC.hg19.knownGene)
library(org.Hs.eg.db)
library(AnnotationDbi)


library(dplyr)
txdb&amp;lt;- TxDb.Hsapiens.UCSC.hg19.knownGene

## get the promoters
hg19_genes&amp;lt;- genes(txdb)

gene_symbols &amp;lt;- AnnotationDbi::select(org.Hs.eg.db, 
                                      keys = hg19_genes$gene_id, 
                                      column = &amp;quot;SYMBOL&amp;quot;, 
                                      keytype = &amp;quot;ENTREZID&amp;quot;, 
                                      multiVals = &amp;quot;first&amp;quot;)

head(gene_symbols)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;    ENTREZID  SYMBOL
#&amp;gt; 1         1    A1BG
#&amp;gt; 2        10    NAT2
#&amp;gt; 3       100     ADA
#&amp;gt; 4      1000    CDH2
#&amp;gt; 5     10000    AKT3
#&amp;gt; 6 100008586 GAGE12F&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# double check the id order is the same
all.equal(gene_symbols$ENTREZID, hg19_genes$gene_id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add the gene symbol to it
hg19_genes$symbol&amp;lt;- gene_symbols$SYMBOL

hg19_promoters&amp;lt;- promoters(hg19_genes, upstream = 2000, downstream = 2000)

hg19_promoters&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 23056 ranges and 2 metadata columns:
#&amp;gt;         seqnames              ranges strand |     gene_id      symbol
#&amp;gt;            &amp;lt;Rle&amp;gt;           &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; | &amp;lt;character&amp;gt; &amp;lt;character&amp;gt;
#&amp;gt;       1    chr19   58872215-58876214      - |           1        A1BG
#&amp;gt;      10     chr8   18246755-18250754      + |          10        NAT2
#&amp;gt;     100    chr20   43278377-43282376      - |         100         ADA
#&amp;gt;    1000    chr18   25755446-25759445      - |        1000        CDH2
#&amp;gt;   10000     chr1 244004887-244008886      - |       10000        AKT3
#&amp;gt;     ...      ...                 ...    ... .         ...         ...
#&amp;gt;    9991     chr9 115093945-115097944      - |        9991       PTBP3
#&amp;gt;    9992    chr21   35734323-35738322      + |        9992       KCNE2
#&amp;gt;    9993    chr22   19107968-19111967      - |        9993       DGCR2
#&amp;gt;    9994     chr6   90537619-90541618      + |        9994    CASP8AP2
#&amp;gt;    9997    chr22   50962906-50966905      - |        9997        SCO2
#&amp;gt;   -------
#&amp;gt;   seqinfo: 93 sequences (1 circular) from hg19 genome&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How many HIF1a peaks overlap with promoters?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;subsetByOverlaps(HIF1_peaks, hg19_promoters)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 275 ranges and 2 metadata columns:
#&amp;gt;         seqnames              ranges strand |           name     score
#&amp;gt;            &amp;lt;Rle&amp;gt;           &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; |    &amp;lt;character&amp;gt; &amp;lt;numeric&amp;gt;
#&amp;gt;     [1]     chr1       763060-763168      * |    MACS_peak_1     60.05
#&amp;gt;     [2]     chr1       954905-955303      * |    MACS_peak_2    106.52
#&amp;gt;     [3]     chr1     8938337-8939542      * |    MACS_peak_9   1224.68
#&amp;gt;     [4]     chr1   12289915-12290246      * |   MACS_peak_13     70.79
#&amp;gt;     [5]     chr1   14924055-14924254      * |   MACS_peak_17     55.58
#&amp;gt;     ...      ...                 ...    ... .            ...       ...
#&amp;gt;   [271]     chrX   49042798-49043142      * | MACS_peak_1490     66.54
#&amp;gt;   [272]     chrX   77359244-77359848      * | MACS_peak_1491    577.87
#&amp;gt;   [273]     chrX 133683313-133683581      * | MACS_peak_1493    119.01
#&amp;gt;   [274]     chrX 151143115-151143368      * | MACS_peak_1494     93.84
#&amp;gt;   [275]     chrX 153606352-153606601      * | MACS_peak_1496     68.16
#&amp;gt;   -------
#&amp;gt;   seqinfo: 29 sequences from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;275 peaks are at the promoter region.&lt;/p&gt;
&lt;p&gt;what genes are nearby?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nearby_gene_index&amp;lt;- nearest(HIF1_peaks, hg19_promoters)

# there is NAs in the index. 
table(is.na(nearby_gene_index))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 
#&amp;gt; FALSE  TRUE 
#&amp;gt;  1494     2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;HIF1_peaks&amp;lt;- HIF1_peaks[!is.na(nearby_gene_index)]

# remove the NAs
nearby_gene_index&amp;lt;- nearby_gene_index[!is.na(nearby_gene_index)]

# the nearest genes 
hg19_promoters[nearby_gene_index]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; GRanges object with 1494 ranges and 2 metadata columns:
#&amp;gt;             seqnames              ranges strand |     gene_id      symbol
#&amp;gt;                &amp;lt;Rle&amp;gt;           &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; | &amp;lt;character&amp;gt; &amp;lt;character&amp;gt;
#&amp;gt;       79854     chr1       760903-764902      - |       79854   LINC00115
#&amp;gt;      375790     chr1       953503-957502      + |      375790        AGRN
#&amp;gt;   100616489     chr1     5622131-5626130      + |   100616489        &amp;lt;NA&amp;gt;
#&amp;gt;   100616489     chr1     5622131-5626130      + |   100616489        &amp;lt;NA&amp;gt;
#&amp;gt;   100616421     chr1     5920802-5924801      - |   100616421     MIR4689
#&amp;gt;         ...      ...                 ...    ... .         ...         ...
#&amp;gt;       79366     chrX   80455442-80459441      - |       79366       HMGN5
#&amp;gt;   100506757     chrX 133682054-133686053      + |   100506757   LINC00629
#&amp;gt;        2564     chrX 151141152-151145151      - |        2564       GABRE
#&amp;gt;       10838     chrX 152597613-152601612      + |       10838      ZNF275
#&amp;gt;        2010     chrX 153605597-153609596      + |        2010         EMD
#&amp;gt;   -------
#&amp;gt;   seqinfo: 93 sequences (1 circular) from hg19 genome&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# distance between the peak and the TSS of the nearest gene
distance_to_peaks&amp;lt;- distance(HIF1_peaks, 
                    resize(hg19_genes, width =1, fix=&amp;quot;start&amp;quot;)[nearby_gene_index])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;combine the peaks and the gene information&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;peak_df&amp;lt;- as.data.frame(HIF1_peaks) 

peak_df$gene_id&amp;lt;- hg19_promoters[nearby_gene_index]$gene_id

peak_df$symbol&amp;lt;- hg19_promoters[nearby_gene_index]$symbol

peak_df$distance&amp;lt;- distance_to_peaks

head(peak_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;   seqnames   start     end width strand        name  score   gene_id    symbol
#&amp;gt; 1     chr1  763060  763168   109      * MACS_peak_1  60.05     79854 LINC00115
#&amp;gt; 2     chr1  954905  955303   399      * MACS_peak_2 106.52    375790      AGRN
#&amp;gt; 3     chr1 5439920 5440090   171      * MACS_peak_3  51.16 100616489      &amp;lt;NA&amp;gt;
#&amp;gt; 4     chr1 5765488 5765761   274      * MACS_peak_4  57.23 100616489      &amp;lt;NA&amp;gt;
#&amp;gt; 5     chr1 5882033 5882303   271      * MACS_peak_5  50.23 100616421   MIR4689
#&amp;gt; 6     chr1 6824756 6824931   176      * MACS_peak_6  57.10     23261    CAMTA1
#&amp;gt;   distance
#&amp;gt; 1      157
#&amp;gt; 2      199
#&amp;gt; 3   184040
#&amp;gt; 4   141356
#&amp;gt; 5    40497
#&amp;gt; 6    20452&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hoary! We annotated the peaks with the closest genes from scratch!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;final-note&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Final note&lt;/h3&gt;
&lt;p&gt;You should use well-tested packages such as &lt;a href=&#34;https://bioconductor.org/packages/release/bioc/html/ChIPseeker.html&#34;&gt;&lt;code&gt;ChIPseeker&lt;/code&gt;&lt;/a&gt; to do such analysis, but
understanding the basics and the low-level functions is super useful!&lt;/p&gt;
&lt;p&gt;Happy Learning!&lt;/p&gt;
&lt;p&gt;Tommy&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;To not miss a post like this, sign up for my &lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/profile&#34;&gt;newsletter&lt;/a&gt; to learn computational
biology and bioinformatics.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>From Cell Line to Command Line: my unexpected career in Bioinformatics</title>
      <link>/talk/2024-ufgi_talk/</link>
      <pubDate>Thu, 05 Sep 2024 11:00:00 +0000</pubDate>
      
      <guid>/talk/2024-ufgi_talk/</guid>
      <description>&lt;p&gt;I was invited to give a talk to the University Florida Genetics Institute (UFGI)
&lt;a href=&#34;http://ufgi.ufl.edu/&#34; target=&#34;_blank&#34;&gt;graduate program&lt;/a&gt;. I graduated from there! Go, Gators!&lt;/p&gt;

&lt;p&gt;read my story here &lt;a href=&#34;https://divingintogeneticsandgenomics.com/publication/2023-10-04-nature-career/&#34; target=&#34;_blank&#34;&gt;https://divingintogeneticsandgenomics.com/publication/2023-10-04-nature-career/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Guess which one is me?!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/UFGI.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hands-on E-workshop Molecular Informatics - Transforming Biotechnology Research with Computational Analysis</title>
      <link>/talk/2024-pakistan_talk/</link>
      <pubDate>Tue, 03 Sep 2024 06:00:00 +0000</pubDate>
      
      <guid>/talk/2024-pakistan_talk/</guid>
      <description>&lt;p&gt;I gave a workshop on RNA-seq analysis in the Hands-on E-workshop &amp;ldquo;Molecular Informatics - Transforming Biotechnology Research with Computational Analysis&amp;rdquo; for the INTERNATIONAL ISLAMIC UNIVERSITY, ISLAMABAD, PAKISTAN.&lt;/p&gt;

&lt;p&gt;Github repo is here &lt;a href=&#34;https://github.com/crazyhottommy/bulk-RNAseq-workshop&#34; target=&#34;_blank&#34;&gt;https://github.com/crazyhottommy/bulk-RNAseq-workshop&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/pakistan_workshop.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;/img/Thankyou.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A docker image to keep this site alive</title>
      <link>/post/docker-mac-m3/</link>
      <pubDate>Mon, 26 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/docker-mac-m3/</guid>
      <description>&lt;p&gt;&lt;strong&gt;To not miss a post like this, sign up for my &lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/profile&#34;&gt;newsletter&lt;/a&gt; to learn computational
biology and bioinformatics.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I have been writing blog posts for over 10 years. I was using &lt;a href=&#34;https://crazyhottommy.blogspot.com/&#34;&gt;blogspot&lt;/a&gt; and in 2018,
I switched to &lt;code&gt;blogdown&lt;/code&gt; and I love it.&lt;/p&gt;
&lt;p&gt;My blogdown website &lt;code&gt;divingintogeneticsandgenomics.com&lt;/code&gt; was using &lt;code&gt;Hugo v0.42&lt;/code&gt; and &lt;code&gt;blogdown v1.0&lt;/code&gt;. It has been many years and now I have a macbook pro with an M3 chip. I could not install the old versions of the R packages to serve the site.&lt;/p&gt;
&lt;p&gt;Docker comes to rescue!&lt;/p&gt;
&lt;p&gt;I have several old blog posts for docker. Read them here if you are interested:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/run-rstudio-server-with-singularity-on-hpc/&#34;&gt;Run Rstudio server with singularity on HPC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/how-to-run-dockerized-rstudio-server-on-google-cloud/&#34;&gt;How to run dockerized Rstudio server on google cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/develop-bioconductor-packages-with-docker-container/&#34;&gt;Develop Bioconductor packages with docker container&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With the help of ChatGPT, I successfully made a docker image to serve my blogdown site! Hopefully, it can run another 10 years.&lt;/p&gt;
&lt;div id=&#34;step-1-download-docker&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 1: download docker&lt;/h3&gt;
&lt;p&gt;go to &lt;a href=&#34;https://www.docker.com/products/docker-desktop/&#34; class=&#34;uri&#34;&gt;https://www.docker.com/products/docker-desktop/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;to install docker.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-build-a-docker-image&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 2 build a docker image&lt;/h3&gt;
&lt;p&gt;build a docker image from scratch with the help of chatGPT. Below is the docker file:&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;# Use the Rocker RStudio image
FROM rocker/rstudio:4


# Install system dependencies, including fontconfig and freetype
RUN apt-get update &amp;amp;&amp;amp; apt-get install -y \
    tzdata \
    libcurl4-openssl-dev \
    libssl-dev \
    libxml2-dev \
    libsqlite3-0 \
    libclang-dev \
    psmisc \
    sudo \
    wget \
    zlib1g-dev \
    libgit2-dev \
    libfontconfig1-dev \
    libfreetype6-dev \
    pkg-config \
    libharfbuzz-dev \
    libfribidi-dev \
    libpng-dev \
    libjpeg-dev \
    libtiff5-dev \
    &amp;amp;&amp;amp; apt-get clean \
    &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*

RUN apt-get update &amp;amp;&amp;amp; apt-get install -y libbz2-dev

# Set the timezone to avoid interactive mode
ENV DEBIAN_FRONTEND=noninteractive

# Set the timezone to Boston (EST)
RUN echo &amp;quot;America/New_York&amp;quot; &amp;gt; /etc/timezone &amp;amp;&amp;amp; \
    ln -snf /usr/share/zoneinfo/America/New_York /etc/localtime &amp;amp;&amp;amp; \
    dpkg-reconfigure -f noninteractive tzdata


# Install Hugo (ARM64)
RUN wget https://github.com/gohugoio/hugo/releases/download/v0.42/hugo_0.42_Linux-ARM64.tar.gz &amp;amp;&amp;amp; \
    tar -xvzf hugo_0.42_Linux-ARM64.tar.gz hugo &amp;amp;&amp;amp; \
    mv hugo /usr/local/bin/ &amp;amp;&amp;amp; \
    rm hugo_0.42_Linux-ARM64.tar.gz

#make a directory to be mounted to the host machine for installing R packages
RUN mkdir /usr/local/lib/R/host-site-library

RUN echo &amp;#39;.libPaths(c(&amp;quot;/usr/local/lib/R/host-site-library&amp;quot;, .libPaths()))&amp;#39; &amp;gt; /home/rstudio/.Rprofile

# Install blogdown package
RUN R -e &amp;quot;install.packages(&amp;#39;blogdown&amp;#39;, version = &amp;#39;1.0&amp;#39;, repos=&amp;#39;http://cran.rstudio.com/&amp;#39;)&amp;quot; 
RUN R -e &amp;quot;install.packages(&amp;#39;devtools&amp;#39;)&amp;quot;
RUN R -e &amp;quot;install.packages(&amp;#39;tidyverse&amp;#39;)&amp;quot;



# Expose ports for RStudio Server and Hugo
EXPOSE 8787 1313&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;build the image&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;docker build -t my-rstudio-blogdown .&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;use the pre-built rstudio image which contains rstudio server to avoid install it from scratch.&lt;/p&gt;
&lt;p&gt;I tried to install Rstudio server inside the docker image and it gave me errors. common problem is the rstudio server deb file url is not correct.&lt;/p&gt;
&lt;p&gt;Make sure it is ARM architechture compatible since I am using a macbook pro with M3 chip.&lt;/p&gt;
&lt;p&gt;common errors are missing libraries during &lt;code&gt;apt-get install&lt;/code&gt; for &lt;code&gt;devtools&lt;/code&gt;. Even it did not error out during the image building process, the &lt;code&gt;devtools&lt;/code&gt; does not work inside the Rstudio.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;library(devtools)&lt;/code&gt; shows the package is not installed.&lt;/p&gt;
&lt;p&gt;so I installed manually inside Rstudio:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;install.packges(&#34;devtools&#34;)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and get error messages for missing libraries. I then gave the error messages to ChatGPT, and it added the libraires:&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;     zlib1g-dev \
    libgit2-dev \
    libfontconfig1-dev \
    libfreetype6-dev \
    pkg-config \
    libharfbuzz-dev \
    libfribidi-dev \
    libpng-dev \
    libjpeg-dev \
    libtiff5-dev \&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I then iterate several times until I have devtools installed correctly during the image building process.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;run-the-docker-container&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;run the docker container&lt;/h3&gt;
&lt;p&gt;In your host machine, &lt;code&gt;mkdir ~/R/host-site-library&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -d -p 8787:8787 -p 8080:8080 \
    -v ~/githup_repo/DivingIntoGeneticsAndGenomics:/home/rstudio/my_blog \
    -v ~/R/host-site-library:/usr/local/lib/R/host-site-library \
    -e USER=rstudio \
    -e PASSWORD=test \
    --name my-rstudio-hugo-container my-rstudio-blogdown&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;-v ~/R/host-site-library:/usr/local/lib/R/host-site-library&lt;/code&gt; will mount the
&lt;code&gt;~/R/host-site-library&lt;/code&gt; folder to the &lt;code&gt;/usr/local/lib/R/host-site-library&lt;/code&gt; inside
the container. All your newly installed R packages will be stored there so you
do not need to re-install them.&lt;/p&gt;
&lt;p&gt;Go to &lt;code&gt;localhost:8787&lt;/code&gt; to log in the Rstudio server. User name: rstudio, password: test.&lt;/p&gt;
&lt;p&gt;Within Rstudio, you need to specify the port (which we mapped to local 8080) and the host. If you do not specify the host to be &lt;code&gt;0.0.0.0&lt;/code&gt;, you can not access the website either.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blogdown::serve_site(port = 8080, host = &amp;#39;0.0.0.0&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, go to your web browser and type &lt;code&gt;localhost:8080&lt;/code&gt; you should see the blogdown website!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-glitch&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;additional glitch&lt;/h3&gt;
&lt;p&gt;My blog uses hugo0.42, and blogdown1.0 can render the website, but the Rstudio add-in for creating a new post does not work.&lt;/p&gt;
&lt;p&gt;Manually create a post inside the &lt;code&gt;content/post&lt;/code&gt; folder using file name format “2024-08-11-my-test.Rmd” and use the yaml header with a format below:&lt;/p&gt;
&lt;pre class=&#34;yaml&#34;&gt;&lt;code&gt;
---
title: &amp;quot;Your Post Title&amp;quot;
author: &amp;quot;Your Name&amp;quot;
date: &amp;quot;2024-08-11&amp;quot;
output:
  blogdown::html_page:
    self_contained: false
tags: [&amp;quot;tag1&amp;quot;, &amp;quot;tag2&amp;quot;]
categories: [&amp;quot;category1&amp;quot;]
---&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;push-the-docker-image-to-dockerhub&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;push the docker image to dockerhub&lt;/h3&gt;
&lt;p&gt;I pushed the container to dockerhub so I can pull it on another macbook pro.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;docker login

docker tag my-rstudio-blogdown crazyhottommy/my-rstudio-blogdown:latest

docker push crazyhottommy/my-rstudio-blogdown:latest
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;final-tips&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Final tips:&lt;/h3&gt;
&lt;p&gt;remove all containers and images&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;docker rm -vf $(docker ps -aq)
docker rmi -f $(docker images -aq)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can git clone the docker file at &lt;a href=&#34;https://github.com/crazyhottommy/blogdown1.0_hug0.4_docker&#34; class=&#34;uri&#34;&gt;https://github.com/crazyhottommy/blogdown1.0_hug0.4_docker&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Happy Learning!&lt;/p&gt;
&lt;p&gt;Tommy&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Most Common Mistake In Bioinformatics, one-off error</title>
      <link>/post/most-common-mistake-for-bioinformatics/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/most-common-mistake-for-bioinformatics/</guid>
      <description>&lt;p&gt;&lt;strong&gt;To not miss a post like this, sign up for my &lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/profile&#34;&gt;newsletter&lt;/a&gt; to learn computational
biology and bioinformatics.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In my &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/stupid-mistakes-for-bioinformatics/&#34;&gt;last blog post&lt;/a&gt;, I talked about some common bioinformatics mistakes.&lt;/p&gt;
&lt;p&gt;Today, we are going to talk about THE MOST common bioinformatics mistake people make. And I think it deserves a separate post about it. Even some experienced programmers get it wrong and the mistake prevails in many bioinformatics software:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The one-off mistake!!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;What is that?&lt;/p&gt;
&lt;p&gt;Genomics files such as &lt;code&gt;bed&lt;/code&gt;, &lt;code&gt;vcf&lt;/code&gt;, &lt;code&gt;gtf&lt;/code&gt; etc come with a coordinate system. To describe a region a position in a genome, you specify something like chr3, 4-7. This means the region is on chromosome 3 and from base 4 to 7. But there are more nuances here..&lt;/p&gt;
&lt;p&gt;There are the 0-based and 1-based coordinates systems in genomics:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/coordinates_system.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The 0-based starts with 0 and the 1-based begins with 1. Why it matters?&lt;/p&gt;
&lt;p&gt;Different file formats (THE bioiFORMATics problem!!) use different systems:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/file_formats.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So if you are not careful, you will make one-off mistakes.&lt;/p&gt;
&lt;p&gt;I highly recommend you to read this old post on biostars: &lt;a href=&#34;https://www.biostars.org/p/84686/&#34; class=&#34;uri&#34;&gt;https://www.biostars.org/p/84686/&lt;/a&gt;​&lt;/p&gt;
&lt;p&gt;To make things worse :) you know R is 1-based and Python is 0-based!!&lt;/p&gt;
&lt;p&gt;If you use different languages to analyze the data, you must also be careful.&lt;/p&gt;
&lt;p&gt;some files such as bed file is 0 based. Two genomic regions:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;chr1 0 1000

chr1 1000 2000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;when you import that bed file into R using rtracklayer::import(), it will become&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;chr1 1 1000

chr1 1001 2000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function converts it to 1 based internally (R is 1 based unlike Python).&lt;/p&gt;
&lt;p&gt;When you read the bed file with read.table and use &lt;code&gt;GenomicRanges::makeGRangesFromDataFrame()&lt;/code&gt; to convert it to a GRanges object, do not forget to add 1 to the start before doing it.&lt;/p&gt;
&lt;p&gt;Similarly, when you write a GRanges object to disk using &lt;code&gt;rtracklayer::export&lt;/code&gt;, you do not need to worry, R will convert it back to 0 based in the file. However, if you make a dataframe out of the GRanges object, and write that dataframe to file, remember to do start -1 before doing it.&lt;/p&gt;
&lt;p&gt;I hope you learned something new!&lt;/p&gt;
&lt;p&gt;Further reading: UCSC coordinate counting system &lt;a href=&#34;https://genome-blog.gi.ucsc.edu/blog/2016/12/12/the-ucsc-genome-browser-coordinate-counting-systems/&#34; class=&#34;uri&#34;&gt;https://genome-blog.gi.ucsc.edu/blog/2016/12/12/the-ucsc-genome-browser-coordinate-counting-systems/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Happy Learning!&lt;/p&gt;
&lt;p&gt;Tommy&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Most Common Stupid Mistakes In Bioinformatics</title>
      <link>/post/stupid-mistakes-for-bioinformatics/</link>
      <pubDate>Tue, 13 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/stupid-mistakes-for-bioinformatics/</guid>
      <description>&lt;link href=&#34;/rmarkdown-libs/vembedr/css/vembedr.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;p&gt;&lt;strong&gt;To not miss a post like this, sign up for my &lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/profile&#34;&gt;newsletter&lt;/a&gt; to learn computational
biology and bioinformatics.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This post is inspired by this &lt;a href=&#34;https://www.biostars.org/p/7126/&#34;&gt;popular thread&lt;/a&gt; in &lt;a href=&#34;https://www.biostars.org/&#34; class=&#34;uri&#34;&gt;https://www.biostars.org/&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;common-mistakes-in-general&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Common mistakes in general&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Off-by-One Errors:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Mistakes occur when switching between different indexing systems. For example, BED files are 0-based while GFF/GTF files are 1-based, leading to potential misinterpretations of genomic coordinates.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is one of the most common mistakes! I highly recommend you to read this &lt;a href=&#34;https://www.biostars.org/p/84686/&#34;&gt;Tutorial:Cheat Sheet For One-Based Vs Zero-Based Coordinate Systems&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Switching Between Programming Languages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Indexing errors happen when a developer switches between languages with different base indexes. Python and most modern languages use 0-based indexing, whereas R and Lua are 1-based.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See an example here: &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/three-gotchas-when-using-r-for-genomic-data-analysis/&#34;&gt;Three gotchas when using R for Genomic data analysis&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Incorrect Chromosome Sorting:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Assuming alphabetical order instead of natural sort leads to chr10 being listed before chr2. Consider implementing natural sorting to avoid this issue.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you do want to have natural sort
see &lt;a href=&#34;https://gist.github.com/crazyhottommy/e778ceb39cebfa20739a&#34; class=&#34;uri&#34;&gt;https://gist.github.com/crazyhottommy/e778ceb39cebfa20739a&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Regex Errors:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Errors arise from constructing regular expressions incorrectly, leading to failure in pattern matching, which can result in missed or incorrect data extraction.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Incorrect File Parsing:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complex file formats like BLAST or GenBank require precise parsing rules. Errors can occur if the format specifications are misunderstood or files are parsed incorrectly. &lt;strong&gt;Do not reinvent the wheel!&lt;/strong&gt;, I have seen people write their own fastq parsers. Use a well-tested library.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Strand Orientation and Sequence Reversal:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Not accounting for the strand direction can result in incorrect data interpretation, such as failing to reverse complement sequences when required.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Loop and File End Errors:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When looping through files, especially if the last line lacks an end-of-line character, logic errors can lead to missing data processing.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Operating System Line Breaks:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Line break conventions vary across operating systems. Failing to handle these differences can cause issues reading or writing files across different platforms. &lt;a href=&#34;https://dos2unix.sourceforge.io/&#34;&gt;&lt;code&gt;dos2unix&lt;/code&gt;&lt;/a&gt; is your friend. I have been bitten by it many times!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Selecting Incorrect Genomic Assemblies:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mistakenly using the wrong assembly, annotation, or release version can lead to inaccurate analysis results. e.g., Double check if the genome build is hg19 or hg38 for human genome. If you aligned your fastq reads to hg19 genome and visualize in hg38 genome build UCSC genome browser or IGV, you should ask yourself why all the coverage is not in the exons!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Managing Multiple File Versions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using outdated or incorrect file versions without clear version tracking may lead to inconsistent data analysis outcomes. This is one of the core problems of reproducible computing. Always version control your files! (using &lt;a href=&#34;https://git-lfs.com/&#34;&gt;git lfs&lt;/a&gt;?)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Handling Nested Genome Annotations:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complex annotations, such as nested genes, need careful handling to avoid missing or double-counting features. Some different genes may have overlapping exons or introns.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Randomization and Statistical Tests:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Not properly randomizing data or misusing statistical tests can lead to biased results and incorrect conclusions.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Poor Documentation Practices:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Failing to fully document methods and procedures makes it difficult to review and correct errors, and hinders reproducibility and collaboration.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;some-command-line-mistake-examples&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Some command line mistake examples&lt;/h3&gt;
&lt;p&gt;Here are some of the common mistakes when using command line tools for bioinformatics tasks.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-rm-in-the-wrong-directory&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using &lt;code&gt;rm *&lt;/code&gt; in the wrong directory&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Running &lt;code&gt;rm *&lt;/code&gt; without checking the directory.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Delete files in a specific subdirectory.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;rm *&lt;/code&gt; (in the wrong directory).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Navigate to the correct directory first:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;cd target_directory
rm *&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;mistaking-for&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Mistaking &lt;code&gt;&amp;gt;&lt;/code&gt; for &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Using &lt;code&gt;&amp;gt;&lt;/code&gt; instead of &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; to append to a file. &lt;code&gt;&amp;gt;&lt;/code&gt; will overwrite the file.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Append to a file.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;command &amp;gt; file&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Use &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; for appending:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;command &amp;gt;&amp;gt; file&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;misspelling-file-extensions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Misspelling file extensions&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Incorrect file extension.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Delete &lt;code&gt;.fastq&lt;/code&gt; files.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;rm *.fasq&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Verify the extension:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;rm *.fastq&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;path-misconfiguration&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Path misconfiguration&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Executing a command in a misconfigured environment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Use a tool installed in a different path.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;myfancytool&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Update your $PATH variable or use absolute path:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;/usr/local/bin/myfancytool&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Watch my chatomics video to understand the PATH
variable:&lt;/p&gt;
&lt;div class=&#34;vembedr&#34;&gt;
&lt;div&gt;
&lt;iframe src=&#34;https://www.youtube.com/embed/nveykWjrFM0&#34; width=&#34;533&#34; height=&#34;300&#34; frameborder=&#34;0&#34; allowfullscreen=&#34;&#34; data-external=&#34;1&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;incorrect-use-of-file-wildcard&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Incorrect use of file wildcard&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Incorrect wildcard usage.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Delete only &lt;code&gt;.txt&lt;/code&gt; files.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;rm *txt&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Correct the wildcard pattern:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;rm *.txt&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;remove-fasta-with-unintentional-spaces&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;remove fasta with unintentional spaces&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Accidental space.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; remove all fasta file.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;rm -rf * .fasta&lt;/code&gt; removes all files!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Ensure no space before .fasta:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;`rm -rf *.fasta&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;forgetting--r-with-rm&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Forgetting &lt;code&gt;-r&lt;/code&gt; with &lt;code&gt;rm&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Forgetting recursive flag for directories.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Delete a directory.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;rm directory&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Use &lt;code&gt;-r&lt;/code&gt; for directories:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;rm -r directory&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;not-escaping-special-characters&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Not escaping special characters&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Forgetting to escape special characters.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Search for &lt;code&gt;*&lt;/code&gt; in files.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;grep * file&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Escape the character:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;grep \* file&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;overwriting-important-files&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Overwriting important files&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Overwriting important data files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Save output to a temporary file.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;command &amp;gt; important_file&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Use a temporary filename:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;command &amp;gt; tempfile&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;using-cat-for-large-files&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using &lt;code&gt;cat&lt;/code&gt; for large files&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Using &lt;code&gt;cat&lt;/code&gt; for very large files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Preview content of a large file.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;cat largefile&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Use &lt;code&gt;less&lt;/code&gt; or &lt;code&gt;head&lt;/code&gt;/&lt;code&gt;tail&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;less largefile&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tip: I usually use &lt;code&gt;less -S largefile&lt;/code&gt; so the line will not be wrapped if it is too long.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;incorrect-find-syntax&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Incorrect &lt;code&gt;find&lt;/code&gt; syntax&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Incorrect parameters with &lt;code&gt;find&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Find &lt;code&gt;.txt&lt;/code&gt; files.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;find . -name *txt&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Use quotes properly:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;find . -name &amp;quot;*.txt&amp;quot;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;misunderstanding-chmod&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Misunderstanding &lt;code&gt;chmod&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Incorrectly setting file permissions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Make a file executable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;chmod 777 file&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Use appropriate permissions:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;chmod +x file&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;if you only want the owner to have executable permission&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;chomod u+x file&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each digit is for: user, group and other.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;chmod 754 myfile&lt;/code&gt;: this means the user has read, write and execute permssion; member in the same group has read and execute permission but no write permission; other people in the world only has read permission.&lt;/p&gt;
&lt;p&gt;4 stands for “read”,&lt;br /&gt;
2 stands for “write”,&lt;br /&gt;
1 stands for “execute”, and.
0 stands for “no permission.”&lt;/p&gt;
&lt;p&gt;So 7 is the combination of permissions 4+2+1 (read, write, and execute), 5 is 4+0+1 (read, no write, and execute), and 4 is 4+0+0 (read, no write, and no execute).&lt;/p&gt;
&lt;p&gt;It is sometimes hard to remember. one can use the letter:The letters u, g, and o stand for “user”, “group”, and “other”; “r”, “w”, and “x” stand for “read”, “write”, and “execute”, respectively.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;chmod u+x myfile&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;chmod g+r myfile&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;grep-without-quote&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;grep “&amp;gt;” without quote&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; not using quote for &lt;code&gt;&amp;gt;&lt;/code&gt; sign.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; search “&amp;gt;” in a fasta file.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;grep &amp;gt; some.fasta&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Use quote for the &amp;gt; sign:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;grep &amp;#39;&amp;gt;&amp;#39; some.fasta&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;forgetting-about-hidden-files&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Forgetting about hidden files&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Not considering hidden files when deleting.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Delete all files in a directory.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;rm *&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Include hidden files:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;rm * .*&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;hidden files starts with &lt;code&gt;.&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;incorrect-argument-order-in-tar&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Incorrect argument order in &lt;code&gt;tar&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Wrong argument order in &lt;code&gt;tar&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Extract a tarball.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;tar -xvf file.tar.gz -C directory&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Correct argument order:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;tar -xvzf file.tar.gz -C directory&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I have to google every time for different compressed files. Use this one below instead:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;#!/bin/bash
# function Extract for common file formats

function extract {
 if [ -z &amp;quot;$1&amp;quot; ]; then
    # display usage if no parameters given
    echo &amp;quot;Usage: extract &amp;lt;path/file_name&amp;gt;.&amp;lt;zip|rar|bz2|gz|tar|tbz2|tgz|Z|7z|xz|ex|tar.bz2|tar.gz|tar.xz&amp;gt;&amp;quot;
 else
    if [ -f &amp;quot;$1&amp;quot; ] ; then
        NAME=${1%.*}
        #mkdir $NAME &amp;amp;&amp;amp; cd $NAME
        case &amp;quot;$1&amp;quot; in
          *.tar.bz2)   tar xvjf ./&amp;quot;$1&amp;quot;    ;;
          *.tar.gz)    tar xvzf ./&amp;quot;$1&amp;quot;    ;;
          *.tar.xz)    tar xvJf ./&amp;quot;$1&amp;quot;    ;;
          *.lzma)      unlzma ./&amp;quot;$1&amp;quot;      ;;
          *.bz2)       bunzip2 ./&amp;quot;$1&amp;quot;     ;;
          *.rar)       unrar x -ad ./&amp;quot;$1&amp;quot; ;;
          *.gz)        gunzip ./&amp;quot;$1&amp;quot;      ;;
          *.tar)       tar xvf ./&amp;quot;$1&amp;quot;     ;;
          *.tbz2)      tar xvjf ./&amp;quot;$1&amp;quot;    ;;
          *.tgz)       tar xvzf ./&amp;quot;$1&amp;quot;    ;;
          *.zip)       unzip ./&amp;quot;$1&amp;quot;       ;;
          *.Z)         uncompress ./&amp;quot;$1&amp;quot;  ;;
          *.7z)        7z x ./&amp;quot;$1&amp;quot;        ;;
          *.xz)        unxz ./&amp;quot;$1&amp;quot;        ;;
          *.exe)       cabextract ./&amp;quot;$1&amp;quot;  ;;
          *)           echo &amp;quot;extract: &amp;#39;$1&amp;#39; - unknown archive method&amp;quot; ;;
        esac
    else
        echo &amp;quot;&amp;#39;$1&amp;#39; - file does not exist&amp;quot;
    fi
fi
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Save it as &lt;code&gt;extract&lt;/code&gt; in the &lt;code&gt;/local/usr/bin&lt;/code&gt; and &lt;code&gt;chomod u+x extract&lt;/code&gt;.
you can then use it to extract any files without remembering the syntax.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;misuse-of-cut-without-delimiter&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Misuse of &lt;code&gt;cut&lt;/code&gt; without delimiter&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Using &lt;code&gt;cut&lt;/code&gt; without specifying delimiter.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Extract a column from a CSV.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;cut -f2 file.csv&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Specify the delimiter:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;cut -d, -f2 file.csv&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;default is tab as the delimiter.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;overwriting-.bashrc&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Overwriting &lt;code&gt;.bashrc&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Using &lt;code&gt;&amp;gt;&lt;/code&gt; to update &lt;code&gt;.bashrc&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Append to &lt;code&gt;.bashrc&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;echo &#34;export PATH=$PATH:/new/path&#34; &amp;gt; ~/.bashrc&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Use &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; for appending:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;echo &amp;quot;export PATH=$PATH:/new/path&amp;quot; &amp;gt;&amp;gt; ~/.bashrc&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;misinterpreting-awk-syntax&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Misinterpreting &lt;code&gt;awk&lt;/code&gt; syntax&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Incorrect &lt;code&gt;awk&lt;/code&gt; syntax.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Print the second column of a file.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;awk {print $2} file&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Use quoted expressions:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;awk &amp;#39;{print $2}&amp;#39; file&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;forgetting--p-with-mkdir&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Forgetting &lt;code&gt;-p&lt;/code&gt; with &lt;code&gt;mkdir&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Not using &lt;code&gt;-p&lt;/code&gt; with &lt;code&gt;mkdir&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Create nested directories.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;mkdir /path/to/new/directory&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Use &lt;code&gt;-p&lt;/code&gt; to create intermediate directories:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;mkdir -p /path/to/new/directory&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the intermediate folders (to, new) does not exist, &lt;code&gt;mkdir&lt;/code&gt; will error out.
use &lt;code&gt;mkdir -p&lt;/code&gt; instead.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;incorrect-use-of-pipe&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Incorrect use of &lt;code&gt;|&lt;/code&gt; (pipe)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mistake:&lt;/strong&gt; Misplaced pipe operator.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What you meant to do:&lt;/strong&gt; Chain commands with a pipe.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actual Command:&lt;/strong&gt; &lt;code&gt;command1 | command2 | &amp;gt; outputfile&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Correction:&lt;/strong&gt; Remove redundant &lt;code&gt;|&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;command1 | command2 &amp;gt; outputfile&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fun fact: &lt;code&gt;|&amp;gt;&lt;/code&gt; is the built-in pipe in &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What’s your mistakes? Leave a comment!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
