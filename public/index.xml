<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DNA confesses Data speak on DNA confesses Data speak</title>
    <link>/</link>
    <description>Recent content in DNA confesses Data speak on DNA confesses Data speak</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Ming &#39;Tommy&#39; Tang</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Ten single-cell data benchmarking papers</title>
      <link>/post/ten-single-cell-data-benchmarking-papers/</link>
      <pubDate>Thu, 13 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/ten-single-cell-data-benchmarking-papers/</guid>
      <description>&lt;p&gt;I tweeted it at &lt;a href=&#34;https://twitter.com/tangming2005/status/1679120948140572672&#34; target=&#34;_blank&#34;&gt;https://twitter.com/tangming2005/status/1679120948140572672&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I got asked to put all my posts in a central place and I think it is a good idea.
&lt;img src=&#34;/img/request_post.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41467-023-37126-3&#34; target=&#34;_blank&#34;&gt;Benchmarking integration of single-cell differential expression&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41592-021-01336-8&#34; target=&#34;_blank&#34;&gt;Benchmarking atlas-level data integration in single-cell genomics&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://academic.oup.com/bib/article/22/4/bbaa222/5916940?login=false&#34; target=&#34;_blank&#34;&gt;A review of computational strategies for denoising and imputation of single-cell transcriptomic data&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41592-022-01480-9&#34; target=&#34;_blank&#34;&gt;Benchmarking spatial and single-cell transcriptomics integration methods for transcript distribution prediction and cell type deconvolution&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41467-022-30755-0&#34; target=&#34;_blank&#34;&gt;Comparison of methods and resources for cell-cell communication inference from single-cell RNA-Seq data&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2022.09.22.508982v2&#34; target=&#34;_blank&#34;&gt;Meta-analysis of (single-cell method) benchmarks reveals the need for extensibility and interoperability&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/33338399/&#34; target=&#34;_blank&#34;&gt;Benchmarking Computational Doublet-Detection Methods for Single-Cell RNA Sequencing Data&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://genomebiology.biomedcentral.com/articles/10.1186/s13059-023-02978-x&#34; target=&#34;_blank&#34;&gt;The effect of background noise and its removal on the analysis of single-cell expression data&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41592-023-01814-1&#34; target=&#34;_blank&#34;&gt;Comparison of transformations for single-cell RNA-seq data&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41592-019-0690-6&#34; target=&#34;_blank&#34;&gt;Benchmarking algorithms for gene regulatory network inference from single-cell transcriptomic data&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Patient Participation: The Unsung Hero of Drug Development</title>
      <link>/talk/2023-patient-drug-discovery-pod/</link>
      <pubDate>Fri, 07 Jul 2023 12:00:00 -0400</pubDate>
      
      <guid>/talk/2023-patient-drug-discovery-pod/</guid>
      <description>&lt;p&gt;Drumroll, please! ü•Å We&amp;rsquo;re ecstatic to unveil our newest episode of Decoding Life: Conversations with a Computational Biologist - &amp;ldquo;Patient Participation: The Unsung Hero of Drug Development&amp;rdquo;! Packed with valuable insights, we dive headfirst into the transformative role patients play in drug development.&lt;/p&gt;

&lt;p&gt;Thrilled to have üéØ Ming &amp;ldquo;Tommy&amp;rdquo; Tang, Director of Computational Biology at Immunitas Therapeutics, as our guest. Together, we navigate the inspiring landscape of how patient contributions are revolutionizing drug discovery and the development of biological products.&lt;/p&gt;

&lt;p&gt;From the surge of patient-centered approaches to the careful navigation of ethical considerations, Tommy masterfully illustrates the vibrant mosaic that is drug development.&lt;/p&gt;

&lt;p&gt;Eager to tap into the untapped potential of patient participation? Grab your headphones, hit play, and let&amp;rsquo;s stir up a dynamic dialogue! Because the future of drug discovery is a journey we&amp;rsquo;re all embarking on together.&lt;/p&gt;

&lt;p&gt;This episode is ready for your ears on your favorite streaming platforms:&lt;/p&gt;

&lt;p&gt;üéµ Spotify: &lt;a href=&#34;https://open.spotify.com/episode/1vQdgYdTNbO1OXg8WhLBmO&#34; target=&#34;_blank&#34;&gt;https://open.spotify.com/episode/1vQdgYdTNbO1OXg8WhLBmO&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;üéµ Deezer: &lt;a href=&#34;https://www.deezer.com/us/show/6045527&#34; target=&#34;_blank&#34;&gt;https://www.deezer.com/us/show/6045527&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;üéµ Amazon Music: &lt;a href=&#34;https://lnkd.in/e25ksqes&#34; target=&#34;_blank&#34;&gt;https://lnkd.in/e25ksqes&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;üéµ Podcast Index: &lt;a href=&#34;https://podcastindex.org/podcast/6363721&#34; target=&#34;_blank&#34;&gt;https://podcastindex.org/podcast/6363721&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Has AI changed the course of Drug Development?</title>
      <link>/post/has-ai-changed-the-course-of-drug-development/</link>
      <pubDate>Thu, 15 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/has-ai-changed-the-course-of-drug-development/</guid>
      <description>

&lt;h3 id=&#34;what-s-the-drug-development-process&#34;&gt;What‚Äôs the drug development process?&lt;/h3&gt;

&lt;p&gt;Has AI changed the course of Drug Development? To answer this question, we need first to understand the drug development process.&lt;/p&gt;

&lt;p&gt;The whole process includes the &lt;a href=&#34;https://ncats.nih.gov/translation/maps&#34; target=&#34;_blank&#34;&gt;following&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;target identification&lt;/li&gt;
&lt;li&gt;target pharmacology and biomarker development&lt;/li&gt;
&lt;li&gt;lead identification, lead optimization&lt;/li&gt;
&lt;li&gt;Clinical research &amp;amp; development&lt;/li&gt;
&lt;li&gt;regulatory review of IND (investigational new drug) and later phase clinical trials&lt;/li&gt;
&lt;li&gt;post-marketing knowledge&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/img/drug_small.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Biologics/antibodies drug development follows a similar path (you can find the map in the same &lt;a href=&#34;https://ncats.nih.gov/translation/maps&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;). As you can see, new target identification is only a tiny component of the complicated drug development process.&lt;/p&gt;

&lt;h3 id=&#34;what-is-ai&#34;&gt;What is AI?&lt;/h3&gt;

&lt;p&gt;AI stands for artificial intelligence. It refers to the development of computer systems or machines that can perform tasks that typically require human intelligence. AI systems are designed to simulate human intelligence and are capable of learning, reasoning, problem-solving, and making decisions.&lt;/p&gt;

&lt;p&gt;The definition is broad. I prefer the term machine learning (ML) in the context of bioinformatics which includes: supervised and unsupervised machine learning approaches. This &lt;a href=&#34;https://www.mdpi.com/1422-0067/22/6/2903&#34; target=&#34;_blank&#34;&gt;review&lt;/a&gt; has a good summary:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/AI_bio.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Most AI/ML is applied to drug discovery, or the first step of the drug development process.  For small molecules, One can screen virtual libraries of large numbers of existing compounds that can inhibit or activate a new target. It can narrow down the list and then validate in experimental assays.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.recursion.com/&#34; target=&#34;_blank&#34;&gt;Recursion&lt;/a&gt; uses an array of robots to treat millions of cell samples with drugs and genetic perturbations, stain them, and image them. It then applies machine learning algorithms to search for informative relationships between the perturbations and the morphological features of the cells.&lt;/p&gt;

&lt;p&gt;Most of the AI companies are vague on their ML approaches in their websites.&lt;/p&gt;

&lt;p&gt;My favorite supervised machine learning technique is linear regression (logistic regression for classification) and random forest. They usually perform well when the data size is moderate. In addition, they are simple, easy to interpret compared with deep learning models in which multiple layers are wrapped in a black box. Image analysis and protein structure prediction may be the fields in that deep learning is better than conventional machine learning approaches.&lt;/p&gt;

&lt;p&gt;By analyzing single-cell RNAseq, single-cell TCRseq and spatial transcriptome data, our company &lt;a href=&#34;https://www.immunitastx.com/&#34; target=&#34;_blank&#34;&gt;Immunitas&lt;/a&gt; uses conventional machine-learning algorithms (e.g., linear regression and random forest) to identify new targets for immunotherapy. Our approaches do give sensible targets.&lt;/p&gt;

&lt;p&gt;In my experience,  most of the time, you do not need deep learning; you do not even need machine learning. A simple correlation analysis answers the question in hand.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/ML_meme.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;we-are-not-there-yet&#34;&gt;We are not there yet&lt;/h3&gt;

&lt;p&gt;With the recent development of the large language mode(LMM), the hype of how AI can transform drug development has reached its peak.&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s the reality?&lt;/p&gt;

&lt;p&gt;AlphaFold2 (AF2) from DeepMind has very high accuracy in predicting protein structures. All the structures can be accessed at &lt;a href=&#34;https://alphafold.ebi.ac.uk/&#34; target=&#34;_blank&#34;&gt;https://alphafold.ebi.ac.uk/&lt;/a&gt;. Can you do antibody discovery with AlphaFold2? In this &lt;a href=&#34;https://www.naturalantibody.com/use-case/deepmind-alphafold-for-antibody-discovery-whats-the-status/&#34; target=&#34;_blank&#34;&gt;post&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Experimental conclusion: We performed a very easy experiment to check if there‚Äôs ‚Äúa free lunch‚Äù for antibody discovery employing AlphaFold2. Unfortunately, according to our results, this is not the case‚Äù&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;At Immunitas, &lt;a href=&#34;https://twitter.com/Matthew_N_B&#34; target=&#34;_blank&#34;&gt;Matt Bernstein&lt;/a&gt; in our group used AlphaFold-multimer for a ligand deorphaning project, and the identified candidates are not validated by the experiment so far.&lt;/p&gt;

&lt;p&gt;Derek Lowe &lt;a href=&#34;https://www.chemistryworld.com/opinion/why-alphafold-wont-revolutionise-drug-discovery/4016051.article&#34; target=&#34;_blank&#34;&gt;wrote&lt;/a&gt;,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;It is very, very rare for knowledge of a protein‚Äôs structure to be any sort of rate-limiting step in a drug discovery project&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;His comment makes sense as you can see how complicated the whole drug process is from the map in the beginning. Clinical trials usually are the bottlenecks.&lt;/p&gt;

&lt;p&gt;AI-designed compounds are still in their early stage. For example, an AI-discovered drug VRG50635 from &lt;a href=&#34;https://www.vergegenomics.com/&#34; target=&#34;_blank&#34;&gt;Verge genomics&lt;/a&gt; entered clinical trials. It is announced that the Phase 1 clinical trial data is positive this week. Phase I trial is mainly for safety. Whether it will reach clinical end point in later phases is still yet to see.&lt;/p&gt;

&lt;p&gt;Another AI-leading company, &lt;a href=&#34;https://www.benevolent.com/&#34; target=&#34;_blank&#34;&gt;BenevolentAI&lt;/a&gt;, recently underwent¬†&lt;a href=&#34;https://endpts.com/benevolentai-lays-off-around-180-staffers-cuts-pipeline-programs-in-reorg/&#34; target=&#34;_blank&#34;&gt;layoffs and restructuring&lt;/a&gt;¬†because of their atopic dermatitis program failure in the Phase 2a clinical trial.&lt;/p&gt;

&lt;p&gt;Derek Lowe wrote,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;There are no existing AI/ML systems that mitigate clinical failure risks due to target choice or toxicology.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Generative AI is being used to design new proteins/antibodies. E.g., &lt;a href=&#34;https://twitter.com/abscibio&#34; target=&#34;_blank&#34;&gt;@abscibio&lt;/a&gt; claims they can de novo design antibodies from scratch, &lt;a href=&#34;https://twitter.com/SurgeBiswas/status/1613232556673224705&#34; target=&#34;_blank&#34;&gt;but people disagree&lt;/a&gt;. That being said, the field is advancing quickly; &lt;a href=&#34;https://github.com/crazyhottommy/Machine_learning_drug_discovery#proteinantibody-design&#34; target=&#34;_blank&#34;&gt;see my notes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;See a full list of &lt;a href=&#34;https://www.nature.com/articles/s41591-023-02361-0&#34; target=&#34;_blank&#34;&gt;AI-enabled drugs in clinical trials&lt;/a&gt;.
&lt;img src=&#34;/img/AI_drugs.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;it-all-gets-down-to-data&#34;&gt;It all gets down to data.&lt;/h3&gt;

&lt;p&gt;Small molecules are attractive for AI approaches in part owing to the availability of appropriate data to learn from, enabling good predictions about new molecules. Small molecules are well described by their chemical structure, which can be rendered quickly in a format that computers can use.&lt;/p&gt;

&lt;p&gt;In order for AI to work, it has to have enough data to train on. But the problem is that we do not have enough high-quality data. Last month, I was in the &lt;a href=&#34;https://www.hub-xchange.com/xchanges/&#34; target=&#34;_blank&#34;&gt;HubX-Exchange meeting&lt;/a&gt;: AI for drug discovery. In the roundtable on data quality which I facilitated, the Chemical informaticians complained about lacking quality data. Genomics data have the same problem. Data silos is another big &lt;a href=&#34;https://timmermanreport.com/2023/06/pharma-rd-execs-offer-extravagant-expectations-for-ai-but-few-proof-points/&#34; target=&#34;_blank&#34;&gt;problem in pharma&lt;/a&gt;. Even failed clinical trial data can be valuable but often they are not accessible.&lt;/p&gt;

&lt;p&gt;As Jacob mentions in this &lt;a href=&#34;https://www.digitalisventures.com/blog/engineering-biology-how-to-build-data-centric-biotech&#34; target=&#34;_blank&#34;&gt;blog post&lt;/a&gt;, the main barrier now is data.&lt;/p&gt;

&lt;p&gt;There are two strategies for solving this problem in drug development:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Better tools and systems for data collection and management (so one can &lt;a href=&#34;https://www.go-fair.org/fair-principles/&#34; target=&#34;_blank&#34;&gt;FAIR&lt;/a&gt; the data)&lt;/li&gt;
&lt;li&gt;Building around novel high throughput biology (so one can generate a lot of data)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I want to add one more:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Avoid data silos (so data can be shared and reused)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With enough data, AI could play an important role for drug development. However, we need to be reminded that it is just a tool, like any experimental assay. It is a small piece of the whole puzzle. We still need to perform experiments to validate the AI-discovered/designed drugs and ultimately test them in human patients. &lt;strong&gt;With enough high quality data&lt;/strong&gt;, AI also can help design better clinical trials and recruit the right patients.&lt;/p&gt;

&lt;p&gt;Understanding the biology is as important. Bioinformaticians should work closely with biology experts. The domain knowledge is critical in selecting a good target from the top list generated by AI.  Even one day, the knowledge graph and LMM are so good, human expertise is still un-replaceable.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;AI has not revolutionized drug development yet,&lt;/strong&gt; but it may first disrupt the early detection of cancer&lt;/p&gt;

&lt;p&gt;Two companies, &lt;a href=&#34;https://www.enidnews.com/region/grail-and-university-of-oxford-to-present-results-from-first-prospective-study-of-multi-cancer/article_de08bd8d-9dec-5d8f-b8e8-99a5a938ef52.html&#34; target=&#34;_blank&#34;&gt;GRAIL&lt;/a&gt; and &lt;a href=&#34;https://www.exai.bio/news/exai-bio-to-present-new-non-small-cell-lung-cancer-early-detection-data-at-the-american-association-for-cancer-research-aacr-2023-annual-meeting&#34; target=&#34;_blank&#34;&gt;EXAI&lt;/a&gt;, announced their liquid biopsy&amp;rsquo;s high accuracy and specificity for early cancer detection.&lt;/p&gt;

&lt;p&gt;This speaks for the success of using AI algorithms for the diagnosis.&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Tapping into the drug discovery potential of AI &lt;a href=&#34;https://www.nature.com/articles/d43747-021-00045-7&#34; target=&#34;_blank&#34;&gt;https://www.nature.com/articles/d43747-021-00045-7&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.fda.gov/media/167973/download&#34; target=&#34;_blank&#34;&gt;https://www.fda.gov/media/167973/download&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.fiercebiotech.com/biotech/benevolentai-makes-deep-cuts-after-midphase-flop-laying-180-and-shrinking-lab-footprint&#34; target=&#34;_blank&#34;&gt;https://www.fiercebiotech.com/biotech/benevolentai-makes-deep-cuts-after-midphase-flop-laying-180-and-shrinking-lab-footprint&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Artificial intelligence in drug discovery and development &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7577280/&#34; target=&#34;_blank&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7577280/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://decodingbio.substack.com/p/biobyte-032-ai-and-the-overlooked&#34; target=&#34;_blank&#34;&gt;https://decodingbio.substack.com/p/biobyte-032-ai-and-the-overlooked&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AI-designed drugs &lt;a href=&#34;https://www.nature.com/articles/s41591-023-02361-0&#34; target=&#34;_blank&#34;&gt;https://www.nature.com/articles/s41591-023-02361-0&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.science.org/content/blog-post/has-ai-discovered-drug-now-guess&#34; target=&#34;_blank&#34;&gt;https://www.science.org/content/blog-post/has-ai-discovered-drug-now-guess&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.digitalisventures.com/blog/engineering-biology-how-to-build-data-centric-biotech&#34; target=&#34;_blank&#34;&gt;https://www.digitalisventures.com/blog/engineering-biology-how-to-build-data-centric-biotech&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Chris Dawn‚Äôs post  &lt;a href=&#34;https://dwan.org/index.php/2023/06/12/a-tale-of-three-conferences/&#34; target=&#34;_blank&#34;&gt;https://dwan.org/index.php/2023/06/12/a-tale-of-three-conferences/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AI for R&amp;amp;D  &lt;a href=&#34;https://timmermanreport.com/2023/06/pharma-rd-execs-offer-extravagant-expectations-for-ai-but-few-proof-points/&#34; target=&#34;_blank&#34;&gt;https://timmermanreport.com/2023/06/pharma-rd-execs-offer-extravagant-expectations-for-ai-but-few-proof-points/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Single-cell analysis: best practices and unsolved problems</title>
      <link>/talk/2023-poland/</link>
      <pubDate>Fri, 09 Jun 2023 03:15:00 -0400</pubDate>
      
      <guid>/talk/2023-poland/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;/img/poland_talk.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to add boxplots or density plots side-by-side a scatterplot: a single cell case study</title>
      <link>/post/how-to-add-boxplots-or-density-plots-side-by-side-a-scatterplot-a-single-cell-case-study/</link>
      <pubDate>Thu, 08 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-add-boxplots-or-density-plots-side-by-side-a-scatterplot-a-single-cell-case-study/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduce-ggside-using-single-cell-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;introduce ggside using single cell data&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&#34;https://cran.r-project.org/web/packages/ggside/vignettes/ggside_basic_usage.html&#34;&gt;ggside&lt;/a&gt; R package provides a new way to visualize data by combining the flexibility of ggplot2 with the power of side-by-side plots.&lt;/p&gt;
&lt;p&gt;We will use a single cell dataset to demonstrate its usage.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ggside&lt;/code&gt; allows users to create side-by-side plots of multiple variables, such as gene expression, cell type, and experimental conditions. This can be helpful for identifying patterns and trends in scRNA-seq data that would be difficult to see in individual plots. Additionally, &lt;code&gt;ggside&lt;/code&gt; provides a number of features that make it easy to customize the appearance of side-by-side plots, such as changing the color scheme, adding labels, and adjusting the layout.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;load-libraries&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Load libraries&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.packages(&amp;quot;ggside&amp;quot;)
library(ggside)
library(Seurat)
library(dplyr)
library(SeuratData)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;load the 3k pbmc dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;pbmc3k&amp;quot;)

pbmc3k&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; An object of class Seurat 
#&amp;gt; 13714 features across 2700 samples within 1 assay 
#&amp;gt; Active assay: RNA (13714 features, 0 variable features)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2700 immune cells from blood.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;routine-processing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;routine processing&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbmc3k&amp;lt;- pbmc3k %&amp;gt;% 
  NormalizeData(normalization.method = &amp;quot;LogNormalize&amp;quot;, scale.factor = 10000) %&amp;gt;%
  FindVariableFeatures(selection.method = &amp;quot;vst&amp;quot;, nfeatures = 2000) %&amp;gt;%
  ScaleData() %&amp;gt;%
  RunPCA(verbose = FALSE) %&amp;gt;%
  FindNeighbors(dims = 1:10, verbose = FALSE) %&amp;gt;%
  FindClusters(resolution = 0.5, verbose = FALSE) %&amp;gt;%
  RunUMAP(dims = 1:10, verbose = FALSE)

Idents(pbmc3k)&amp;lt;- pbmc3k$seurat_annotations

DimPlot(pbmc3k, label = TRUE, repel=TRUE) + NoLegend()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-06-08-how-to-add-boxplots-or-density-plots-side-by-side-a-scatterplot-a-single-cell-case-study_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;some helper functions to extract the gene expression values from the seurat object&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;matrix_to_expression_df&amp;lt;- function(x, obj){
        df&amp;lt;- x %&amp;gt;%
                as.matrix() %&amp;gt;% 
                as.data.frame() %&amp;gt;%
                tibble::rownames_to_column(var= &amp;quot;gene&amp;quot;) %&amp;gt;%
                tidyr::pivot_longer(cols = -1, names_to = &amp;quot;cell&amp;quot;, values_to = &amp;quot;expression&amp;quot;) %&amp;gt;%
                tidyr::pivot_wider(names_from = &amp;quot;gene&amp;quot;, values_from = expression) %&amp;gt;%
                left_join(obj@meta.data %&amp;gt;% 
                                  tibble::rownames_to_column(var = &amp;quot;cell&amp;quot;))
        return(df)
}


get_expression_data&amp;lt;- function(obj, assay = &amp;quot;RNA&amp;quot;, slot = &amp;quot;data&amp;quot;, 
                               genes = NULL, cells = NULL){
        if (is.null(genes) &amp;amp; !is.null(cells)){
                df&amp;lt;- GetAssayData(obj, assay = assay, slot = slot)[, cells, drop = FALSE] %&amp;gt;%
                        matrix_to_expression_df(obj = obj)
        } else if (!is.null(genes) &amp;amp; is.null(cells)){
                df &amp;lt;- GetAssayData(obj, assay = assay, slot = slot)[genes, , drop = FALSE] %&amp;gt;%
                        matrix_to_expression_df(obj = obj)
        } else if (is.null(genes &amp;amp; is.null(cells))){
                df &amp;lt;- GetAssayData(obj, assay = assay, slot = slot)[, , drop = FALSE] %&amp;gt;%
                        matrix_to_expression_df(obj = obj)
        } else {
                df&amp;lt;- GetAssayData(obj, assay = assay, slot = slot)[genes, cells, drop = FALSE] %&amp;gt;%
                        matrix_to_expression_df(obj = obj)
        }
        return(df)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test the function&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df&amp;lt;- get_expression_data(obj = pbmc3k, genes = c(&amp;quot;CD14&amp;quot;, &amp;quot;FCGR3A&amp;quot;))

head(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 6 √ó 9
#&amp;gt;   cell           CD14 FCGR3A orig.ident nCount_RNA nFeature_RNA seurat_annotati‚Ä¶
#&amp;gt;   &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;           &amp;lt;dbl&amp;gt;        &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;           
#&amp;gt; 1 AAACATACAACC‚Ä¶     0   0    pbmc3k           2419          779 Memory CD4 T    
#&amp;gt; 2 AAACATTGAGCT‚Ä¶     0   0    pbmc3k           4903         1352 B               
#&amp;gt; 3 AAACATTGATCA‚Ä¶     0   0    pbmc3k           3147         1129 Memory CD4 T    
#&amp;gt; 4 AAACCGTGCTTC‚Ä¶     0   1.57 pbmc3k           2639          960 CD14+ Mono      
#&amp;gt; 5 AAACCGTGTATG‚Ä¶     0   0    pbmc3k            980          521 NK              
#&amp;gt; 6 AAACGCACTGGT‚Ä¶     0   0    pbmc3k           2163          781 Memory CD4 T    
#&amp;gt; # ‚Ä¶ with 2 more variables: RNA_snn_res.0.5 &amp;lt;fct&amp;gt;, seurat_clusters &amp;lt;fct&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let‚Äôs only focus on the monocytes and use CD14 and CD16/FCGR3A as an example.&lt;/p&gt;
&lt;p&gt;A plain scatter plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df %&amp;gt;%
  filter(seurat_annotations %in% c(&amp;quot;CD14+ Mono&amp;quot;, &amp;quot;FCGR3A+ Mono&amp;quot;)) %&amp;gt;%
  ggplot(aes(x= CD14, y = FCGR3A)) +
  geom_point(aes(color = seurat_annotations))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-06-08-how-to-add-boxplots-or-density-plots-side-by-side-a-scatterplot-a-single-cell-case-study_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;576&#34; /&gt;
CD14+ monocytes are mostly CD14+CD16- and CD16+ monocytes are mostly CD16+CD14-
which makes sense.There are also some intermedidate cells that are CD14+CD16+ in the middle.&lt;/p&gt;
&lt;p&gt;a scatter plot adding two boxplots:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df %&amp;gt;%
  filter(seurat_annotations %in% c(&amp;quot;CD14+ Mono&amp;quot;, &amp;quot;FCGR3A+ Mono&amp;quot;)) %&amp;gt;%
  ggplot(aes(x= CD14, y = FCGR3A)) +
  geom_point(aes(color = seurat_annotations)) +
  geom_xsideboxplot(aes(y = seurat_annotations, color = seurat_annotations), 
                    orientation = &amp;quot;y&amp;quot;) +
  geom_ysideboxplot(aes(x = seurat_annotations, color = seurat_annotations), 
                    orientation = &amp;quot;x&amp;quot;)+
  scale_xsidey_discrete() +
  scale_ysidex_discrete()+
  theme(ggside.panel.scale.x = 0.2,
       ggside.panel.scale.y = 0.3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-06-08-how-to-add-boxplots-or-density-plots-side-by-side-a-scatterplot-a-single-cell-case-study_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;a scatterplot adding one boxplot and one density plot&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df %&amp;gt;%
  filter(seurat_annotations %in% c(&amp;quot;CD14+ Mono&amp;quot;, &amp;quot;FCGR3A+ Mono&amp;quot;)) %&amp;gt;%
  ggplot(aes(x= CD14, y = FCGR3A)) +
  geom_point(aes(color = seurat_annotations)) +
  geom_xsideboxplot(aes(y = seurat_annotations, color = seurat_annotations), 
                    orientation = &amp;quot;y&amp;quot;) +
  geom_ysidedensity(aes(x = after_stat(density), color = seurat_annotations, fill = seurat_annotations), 
                    position = &amp;quot;stack&amp;quot;, alpha = 0.4) +
  scale_xsidey_discrete() +
  scale_ysidex_continuous(guide = guide_axis(angle = 90), minor_breaks = NULL) +
  theme(ggside.panel.scale.x = 0.2,
       ggside.panel.scale.y = 0.4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-06-08-how-to-add-boxplots-or-density-plots-side-by-side-a-scatterplot-a-single-cell-case-study_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;alternative-way-use-patchwork&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;alternative way: use patchwork&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://patchwork.data-imaginist.com/&#34; class=&#34;uri&#34;&gt;https://patchwork.data-imaginist.com/&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(patchwork)

p1&amp;lt;- df %&amp;gt;%
  filter(seurat_annotations %in% c(&amp;quot;CD14+ Mono&amp;quot;, &amp;quot;FCGR3A+ Mono&amp;quot;)) %&amp;gt;%
  ggplot(aes(x= seurat_annotations, y = CD14)) +
  geom_boxplot(aes(color = seurat_annotations)) + 
  xlab(&amp;quot;&amp;quot;) +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    #legend.position = &amp;quot;none&amp;quot;, legend.text = element_blank()
  )+
  coord_flip()

p2&amp;lt;- df %&amp;gt;%
  filter(seurat_annotations %in% c(&amp;quot;CD14+ Mono&amp;quot;, &amp;quot;FCGR3A+ Mono&amp;quot;)) %&amp;gt;%
  ggplot(aes(x= CD14, y = FCGR3A)) +
  geom_point(aes(color = seurat_annotations)) +
  theme(legend.position = &amp;quot;none&amp;quot;, legend.text = element_blank()) 

p3&amp;lt;- df %&amp;gt;%
  filter(seurat_annotations %in% c(&amp;quot;CD14+ Mono&amp;quot;, &amp;quot;FCGR3A+ Mono&amp;quot;)) %&amp;gt;%
  ggplot(aes(x= seurat_annotations, y = FCGR3A)) +
  geom_boxplot(aes(color = seurat_annotations)) +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  ylab(&amp;quot;&amp;quot;) +
  xlab(&amp;quot;&amp;quot;) +
  theme(
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  ) 

p1 + plot_spacer() + p2 + p3 +
   plot_layout(widths = c(4, 2), heights = c(1, 5),
               guides = &amp;#39;collect&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-06-08-how-to-add-boxplots-or-density-plots-side-by-side-a-scatterplot-a-single-cell-case-study_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I hope you enjoyed this post! More later. Happy Learning!&lt;/p&gt;
&lt;p&gt;I made a video for this in my &lt;strong&gt;chatomics youtube channel&lt;/strong&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=v4oBKNnGvtU&#34;&gt;check it out&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Unlock the Power of Genomics Data Analysis: Watershed&#39;s Seamless Cloud Computing Solution</title>
      <link>/post/unlock-the-power-of-genomics-data-analysis-watershed-s-seamless-cloud-computing-solution/</link>
      <pubDate>Wed, 07 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/unlock-the-power-of-genomics-data-analysis-watershed-s-seamless-cloud-computing-solution/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Disclaimer: This post is sponsored by &lt;a href=&#34;https://www.watershed.ai/&#34; target=&#34;_blank&#34;&gt;Watershed Omics Bench platform&lt;/a&gt;. I have personally tested the platform.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;As an experienced bioinformatician who understands the needs of biotech startups, I know the challenges that arise when analyzing genomics data. The first solution that comes to mind is cloud computing. Unsurprisingly, AWS and Google Cloud Platform (GCP) are commonly used options. Cloud computing avoids large upfront costs and can scale more effectively compared to building an on-premise solution. Setting up an on-premise solution is cumbersome, requiring meticulous organization and robust security measures.&lt;/p&gt;

&lt;p&gt;However, setting up an AWS/GCP account for your company can be time-consuming and daunting, especially for those new to the process. It requires setting up the organization, billing account, security measures, and functioning as an administrator. The initial setup may involve multiple meetings with customer support teams. This administrative burden can be overwhelming, hindering the swift start of your analysis.&lt;/p&gt;

&lt;p&gt;Once you&amp;rsquo;ve successfully set up your cloud computing account, you can spin up a virtual machine and delve into real bioinformatics work. However, there are additional challenges to navigate, such as selecting the appropriate machine types, determining optimal memory usage, configuring external disk mounting, and fine-tuning security settings. These decisions can be perplexing, particularly for those without extensive cloud computing expertise.&lt;/p&gt;

&lt;p&gt;Take RNA-seq as an example. Running a bulk RNA-seq analysis on the cloud requires understanding and implementing workflows such as Snakemake or Nextflow. Installing the required tools can be a challenge too. Moreover, the workflow itself can be inefficient, generating large intermediate files and requiring careful management of disk space. I&amp;rsquo;ve found myself contending with the need to expand disk size. After overcoming these obstacles, you can obtain the count matrix and proceed to downstream differential expression analysis.¬† Tools like DESeq2, EdgeR, or Limma in R are commonly used, each with its own learning curve.&lt;/p&gt;

&lt;p&gt;In stark contrast, the &lt;a href=&#34;https://www.watershed.ai/&#34; target=&#34;_blank&#34;&gt;Watershed Omics Bench platform&lt;/a&gt; addresses these pain points and provides an intuitive and efficient solution. With Watershed, you can bid farewell to the worries of configuring CPU numbers and security settings. The platform seamlessly handles these aspects, saving you valuable time and effort. The pre-written workflows (&lt;strong&gt;bulk/single-cell RNA, WGS, ATACseq, ChIPseq, and many more&lt;/strong&gt;) are designed to work out of the box, eliminating the need for extensive setup or workflow language comprehension. Simply load your fastq files into the system, click run, and obtain the count matrix effortlessly. Importantly, the system tracks how each file is generated, associating timestamps, commands used, and configurations as metadata. This makes the analysis highly reproducible.&lt;/p&gt;

&lt;p&gt;Additionally, &lt;strong&gt;Watershed offers real-time monitoring of your analysis job through a user-friendly interface.&lt;/strong&gt; This feature allows you to track the progress of your analysis, empowering you with up-to-date information and enabling informed decision-making. The platform is scalable to your needs. It allows easy parallel processing by adjusting the number of CPUs through dragging a slider. Say goodbye to the complexities of setting up Kubernetes clusters‚ÄîWatershed handles it seamlessly.&lt;/p&gt;

&lt;p&gt;Furthermore, Watershed streamlines downstream analysis by offering pre-configured DESeq2 or EdgeR modules, so you can rest assured that you are using industry best practices. These steps simplify group comparison selection. The generated figures, such as interactive volcano plots and heatmaps, facilitate data exploration. &lt;strong&gt;Bioinformaticians can configure any settings at each step and even hide the underlying code in the notebook, exposing only GUI widgets to wet biologists. The GUI widgets enable them to explore the data themselves.&lt;/strong&gt; This feature saves time in communication and expedites analysis turnover.&lt;/p&gt;

&lt;p&gt;In summary, the Watershed platform is an elegant solution when it comes to analyzing genomics data. It addresses the pain points associated with cloud computing by simplifying the setup process, providing a user-friendly interface with real-time monitoring, ensuring scalability, and streamlining downstream analysis.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.watershed.ai/&#34; target=&#34;_blank&#34;&gt;Watershed&lt;/a&gt; enables biotech startup hires to efficiently analyze their data, collaborate effectively, and accelerate research advancements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to do neighborhood/cellular niches analysis with spatial transcriptome data </title>
      <link>/post/how-to-do-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data/</link>
      <pubDate>Fri, 14 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-do-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;sign-up-for-my-newsletter-to-not-miss-a-post-like-this&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sign up for my newsletter to not miss a post like this&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/newsletter&#34; class=&#34;uri&#34;&gt;https://divingintogeneticsandgenomics.ck.page/newsletter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In a &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/how-to-construct-a-spatial-object-in-seurat/&#34;&gt;previous blog post&lt;/a&gt;, I showed you how to make a Seurat spatial object from
&lt;a href=&#34;https://vizgen.com/&#34;&gt;Vizgen&lt;/a&gt; spatial transcriptome data. In this post, I am going to show you how to
identify clusters of neighborhood or cellular niches where specific cell types tend
to co-localize.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;read-in-the-data-and-pre-process&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;read in the data and pre-process&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Seurat)
library(here)
library(ggplot2)
library(dplyr)

# the LoadVizgen function requires the raw segmentation files which is too big. We will only use the x,y coordinates 
# vizgen.obj &amp;lt;- LoadVizgen(data.dir = here(&amp;quot;data&amp;quot;))

vizgen.input &amp;lt;- ReadVizgen(data.dir = &amp;quot;~/blog_data/spatial_data&amp;quot;, type = &amp;quot;centroids&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For most of the analysis, we will only need the x,y coordinates (the center of the cell). You can also read in
the raw segmentation file( which gives you more detailed cell shape information), or set &lt;code&gt;type = &#34;box&#34;&lt;/code&gt; to get the
rectangular information of a cell (xmin, xmax, ymin and ymax).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;vizgen.input&lt;/code&gt; is a list containing the count matrix and the spatial centrioids.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vizgen.input$centroids %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           x        y cell
#&amp;gt; 1 10145.793 5611.687 7650
#&amp;gt; 2  9975.309 5626.726 7654
#&amp;gt; 3 10129.183 5630.601 7655
#&amp;gt; 4 10112.692 5635.038 7656
#&amp;gt; 5 10151.574 5634.673 7657
#&amp;gt; 6 10099.624 5636.831 7658&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## This gives you the image 
ggplot(vizgen.input$centroids, aes(x= x, y = y))+
        geom_point(size = 0.1, color = &amp;quot;grey&amp;quot;) +
        theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-04-14-how-to-do-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Create a seurat object. The documentation for making a spatial object is sparse.
I went to the &lt;a href=&#34;https://github.com/satijalab/seurat/blob/763259d05991d40721dee99c9919ec6d4491d15e/R/convenience.R#L139&#34;&gt;source code&lt;/a&gt;
of &lt;code&gt;LoadVizgen&lt;/code&gt; and came up with the code below.&lt;/p&gt;
&lt;p&gt;You can read the code from the same link and see how other types of spatial data (10x Xenium, nanostring) are read into Seurat.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## remove the Blank-* control probes
blank_index&amp;lt;- which(stringr::str_detect(rownames(vizgen.input$transcripts), &amp;quot;^Blank&amp;quot;))

transcripts&amp;lt;-vizgen.input$transcripts[-blank_index, ]

dim(vizgen.input$transcripts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]   550 71381&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(transcripts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]   500 71381&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are 50 such probes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-seurat-spatial-object&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;create a Seurat spatial object&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vizgen.obj&amp;lt;- CreateSeuratObject(counts = transcripts, assay = &amp;quot;Vizgen&amp;quot;)

cents &amp;lt;- CreateCentroids(vizgen.input$centroids)
segmentations.data &amp;lt;- list(
    &amp;quot;centroids&amp;quot; = cents,
    &amp;quot;segmentation&amp;quot; = NULL
  )

coords &amp;lt;- CreateFOV(
    coords = segmentations.data,
    type = c(&amp;quot;segmentation&amp;quot;, &amp;quot;centroids&amp;quot;),
    molecules = NULL,
    assay = &amp;quot;Vizgen&amp;quot;
  )
 
vizgen.obj[[&amp;quot;p2s2&amp;quot;]] &amp;lt;- coords
 
GetTissueCoordinates(vizgen.obj[[&amp;quot;p2s2&amp;quot;]][[&amp;quot;centroids&amp;quot;]]) %&amp;gt;%
        head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           x        y cell
#&amp;gt; 1 10145.793 5611.687 7650
#&amp;gt; 2  9975.309 5626.726 7654
#&amp;gt; 3 10129.183 5630.601 7655
#&amp;gt; 4 10112.692 5635.038 7656
#&amp;gt; 5 10151.574 5634.673 7657
#&amp;gt; 6 10099.624 5636.831 7658&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ImageDimPlot(vizgen.obj, fov = &amp;quot;p2s2&amp;quot;, cols = &amp;quot;polychrome&amp;quot;, axes = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-04-14-how-to-do-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;standard-processing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;standard processing&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vizgen.obj &amp;lt;- NormalizeData(vizgen.obj, normalization.method = &amp;quot;LogNormalize&amp;quot;, scale.factor = 10000) %&amp;gt;%
  ScaleData() 
vizgen.obj &amp;lt;- RunPCA(vizgen.obj, npcs = 30, features = rownames(vizgen.obj))
vizgen.obj &amp;lt;- RunUMAP(vizgen.obj, dims = 1:30)
vizgen.obj &amp;lt;- FindNeighbors(vizgen.obj, reduction = &amp;quot;pca&amp;quot;, dims = 1:30)
vizgen.obj &amp;lt;- FindClusters(vizgen.obj, resolution = 0.3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck
#&amp;gt; 
#&amp;gt; Number of nodes: 71381
#&amp;gt; Number of edges: 2100209
#&amp;gt; 
#&amp;gt; Running Louvain algorithm...
#&amp;gt; Maximum modularity in 10 random starts: 0.9109
#&amp;gt; Number of communities: 14
#&amp;gt; Elapsed time: 29 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;umap-by-cluster&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;UMAP by cluster&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DimPlot(vizgen.obj, reduction = &amp;quot;umap&amp;quot;, label = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-04-14-how-to-do-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;image-plot-by-cluster&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Image plot by cluster&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ImageDimPlot(vizgen.obj, fov = &amp;quot;p2s2&amp;quot;, cols = &amp;quot;polychrome&amp;quot;, axes = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-04-14-how-to-do-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-find-the-spatially-close-by-cells.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;How to find the spatially close-by cells.&lt;/h3&gt;
&lt;p&gt;One common task with spatial data is to count how many
cells for a certain cell type is around a cell within a radius.&lt;/p&gt;
&lt;p&gt;The brute force way is to calculate the pairwise distances between all cells and use
a distance cutoff to filter the cells.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;distances&amp;lt;- dist(mat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, this matrix has 71k rows/cells and calculating the pair-wise distance takes a long time
and memory.&lt;/p&gt;
&lt;p&gt;One can use the nearest neighbor algorithm implemented in &lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html&#34; class=&#34;uri&#34;&gt;https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can read more on &lt;code&gt;kd-tree&lt;/code&gt; to find the nearest neighbors efficiently.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;:
For beginners, not knowing how to search and find the right tool is a roadblock.
This is how I asked ChatGPT:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;find an R package implement the k-d tree to find the nearest neighbor as in the python function &lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html&#34; class=&#34;uri&#34;&gt;https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;and it gave me the &lt;code&gt;FNN&lt;/code&gt; package, but it did not receive radius as an argument.&lt;/p&gt;
&lt;p&gt;I asked again:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;that‚Äôs good, can you find an R package also take the argument of radius to find the nearest neighbors within the area of the radius&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I then landed with &lt;code&gt;dbscan&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vizgen.input$centroids %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           x        y cell
#&amp;gt; 1 10145.793 5611.687 7650
#&amp;gt; 2  9975.309 5626.726 7654
#&amp;gt; 3 10129.183 5630.601 7655
#&amp;gt; 4 10112.692 5635.038 7656
#&amp;gt; 5 10151.574 5634.673 7657
#&amp;gt; 6 10099.624 5636.831 7658&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat&amp;lt;- vizgen.input$centroids[,1:2] 
mat&amp;lt;- as.matrix(mat)
rownames(mat)&amp;lt;- vizgen.input$centroids$cell&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Reorder the cells in the coordinates matrix as the same order as in the Seurat object.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This is important&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Cells(vizgen.obj) %&amp;gt;% head&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;0&amp;quot; &amp;quot;1&amp;quot; &amp;quot;2&amp;quot; &amp;quot;3&amp;quot; &amp;quot;4&amp;quot; &amp;quot;5&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# reorder the matrix rows
mat&amp;lt;- mat[Cells(vizgen.obj), ]
head(mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;          x        y
#&amp;gt; 0 10557.32 5766.281
#&amp;gt; 1 10389.43 5770.098
#&amp;gt; 2 10368.95 5772.362
#&amp;gt; 3 10409.22 5774.434
#&amp;gt; 4 10375.96 5776.037
#&amp;gt; 5 10384.77 5775.849&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In &lt;a href=&#34;https://www.nature.com/articles/s41587-022-01467-z&#34;&gt;Modeling intercellular communication in tissues using spatial graphs of cells&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Linear NCEMs were most predictive on an intermediate length scale of 69‚Äâ¬µm across the six datasets (Fig. 1c), showing that cell‚Äìcell dependencies appear on length scales characteristic of molecular mechanisms of cell communication&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let‚Äôs find the nearest cells within a radius of 50 ¬µm. This arbitrary. You can use 100 ¬µm too.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dbscan)
eps &amp;lt;- 50
nn &amp;lt;- frNN(x= mat, eps = eps)
# Indices of the nearest neighbors within radius eps
#nn$id

# Distances to the nearest neighbors within radius eps
#nn$dist

## random pick one cell, the output is the index of all the nearest cells within 50um
nn$id[&amp;#39;7722&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; $`7722`
#&amp;gt; [1] 27821  7725 27720 27820 27724  7721&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat&amp;lt;- mat[nn$id$`7722`, ]
# those cells&amp;#39; positions
dat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;              x        y
#&amp;gt; 27820 10287.40 5993.892
#&amp;gt; 7724  10256.69 6008.903
#&amp;gt; 27719 10297.86 5992.073
#&amp;gt; 27819 10296.64 5983.385
#&amp;gt; 27723 10310.45 6018.985
#&amp;gt; 7720  10303.98 5965.522&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat[&amp;#39;7722&amp;#39;,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;         x         y 
#&amp;gt; 10273.341  6000.784&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Seeing is believing. Let‚Äôs see if those cells are within the 50um radius or not:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vizgen.input$centroids %&amp;gt;%
        filter(cell %in% rownames(dat))%&amp;gt;%
        ggplot(aes(x=x, y = y)) +
        geom_point() +
        ggforce::geom_circle(aes(x0 = 10273.34 , y0 = 6000.784, r = 50)) +
        geom_point(data = as.data.frame(mat[&amp;#39;7722&amp;#39;, , drop=FALSE]), aes(x=x, y=y), color = &amp;quot;red&amp;quot;, size = 3) +
        coord_fixed()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-04-14-how-to-do-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yes, they are!&lt;/p&gt;
&lt;p&gt;Note, the cells are roughly 10um in width, and we are using the centriod. You can adjust the &lt;code&gt;eps&lt;/code&gt; accordingly if you want
to be really accurate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;neigborhood-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;neigborhood analysis&lt;/h3&gt;
&lt;p&gt;Now, for each cell in the data, we need to count the number of cells of each cluster (0-11) within 50 um radius.&lt;/p&gt;
&lt;p&gt;Create the neighborhood count matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(colnames(vizgen.obj), names(nn$id))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# this takes me 7mins, can figure a better way to do it
x&amp;lt;- purrr::map(nn$id, ~vizgen.obj$seurat_clusters[.x] %&amp;gt;% table())

nn_matrix&amp;lt;- do.call(rbind,x)

head(nn_matrix)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;   0 1 2 3 4 5 6 7 8 9 10 11
#&amp;gt; 0 0 0 0 0 0 0 0 0 0 0  0  0
#&amp;gt; 1 4 0 3 7 0 0 0 0 1 2  0  0
#&amp;gt; 2 3 0 3 6 0 0 0 0 1 4  0  0
#&amp;gt; 3 5 0 1 7 0 0 0 0 0 2  0  0
#&amp;gt; 4 3 0 3 7 0 0 0 0 1 4  0  0
#&amp;gt; 5 4 0 3 7 0 0 0 0 1 4  0  0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;nn_matrix&lt;/code&gt;: the columns are cell clusters 0-11 identified by gene expression;
the rows are cells.&lt;/p&gt;
&lt;p&gt;Create a Seurat object and do a regular single-cell count matrix analysis, but now
we only have 12 features (clusters) instead of 20,000 genes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_obj&amp;lt;- CreateSeuratObject(counts = t(nn_matrix),  min.features = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The normalization can be tricky, let‚Äôs try pearson residual normalization implemented
in &lt;code&gt;SCTransform&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can try log normalization too, but it will give you a lot of small clusters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_obj&amp;lt;- SCTransform(nn_obj, vst.flavor = &amp;quot;v2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%
#&amp;gt; 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%
#&amp;gt; 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_obj &amp;lt;- RunPCA(nn_obj, npcs = 30, features = rownames(nn_obj))
ElbowPlot(nn_obj)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-04-14-how-to-do-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_obj &amp;lt;- FindNeighbors(nn_obj, reduction = &amp;quot;pca&amp;quot;, dims = 1:10)
nn_obj &amp;lt;- FindClusters(nn_obj, resolution = 0.3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck
#&amp;gt; 
#&amp;gt; Number of nodes: 44174
#&amp;gt; Number of edges: 1194134
#&amp;gt; 
#&amp;gt; Running Louvain algorithm...
#&amp;gt; Maximum modularity in 10 random starts: 0.9215
#&amp;gt; Number of communities: 16
#&amp;gt; Elapsed time: 6 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_obj &amp;lt;- RunUMAP(nn_obj, dims = 1:9)
DimPlot(nn_obj)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-04-14-how-to-do-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data_files/figure-html/unnamed-chunk-16-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize-the-neigborhood.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualize the neigborhood.&lt;/h3&gt;
&lt;p&gt;put the neighborhood cluster info back to the vizgen.obj:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;old_meta&amp;lt;- vizgen.obj@meta.data %&amp;gt;% 
        tibble::rownames_to_column(var= &amp;quot;cell_id&amp;quot;)

nn_meta&amp;lt;- nn_obj@meta.data %&amp;gt;%
        tibble::rownames_to_column(var= &amp;quot;cell_id&amp;quot;) %&amp;gt;%
        select(cell_id, SCT_snn_res.0.3)

## note, we filtered out some cells for the neighborhood analysis
new_meta&amp;lt;- old_meta %&amp;gt;%
        left_join(nn_meta)

new_meta&amp;lt;- as.data.frame(new_meta)
rownames(new_meta)&amp;lt;- old_meta$cell_id

vizgen.obj@meta.data&amp;lt;- new_meta&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Visualize:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## the cells are colored by the clustering of the cells by expression
p1&amp;lt;- ImageDimPlot(vizgen.obj, fov = &amp;quot;p2s2&amp;quot;, cols = &amp;quot;polychrome&amp;quot;, axes = TRUE)


## the cells are colored by the clustering of the cells by neighborhood 
p2&amp;lt;- ImageDimPlot(vizgen.obj, fov = &amp;quot;p2s2&amp;quot;, cols = &amp;quot;polychrome&amp;quot;, axes = TRUE, 
                  group.by = &amp;quot;SCT_snn_res.0.3&amp;quot; )
        
p1 + p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-04-14-how-to-do-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;1344&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Pretty cool! You see the clusters of cellular niches are spatially co-localized.
Next step is to make sense of those neighborhoods/niches. Stay tuned for the next post!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to classify MNIST images with convolutional neural network</title>
      <link>/post/how-to-classify-mnist-images-with-convolutional-neural-network/</link>
      <pubDate>Sun, 09 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-classify-mnist-images-with-convolutional-neural-network/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;An artificial intelligence system called a convolutional neural network (CNN) has gained a lot of popularity recently. For jobs like image recognition, where we want to teach a computer to recognize things in a picture, they are especially well suited.&lt;/p&gt;
&lt;p&gt;CNNs operate by dissecting an image into increasingly minute components, or ‚Äúfeatures.‚Äù The network then examines each feature and searches for patterns shared by various objects. For instance, a CNN might come to understand that some pixel patterns are frequently linked to faces, while others are linked to vehicles or trees.&lt;/p&gt;
&lt;p&gt;The unique feature of CNNs is their capacity to discover these patterns on its own, without having to be explicitly trained to do so. This is what makes them so powerful: by analyzing thousands or even millions of images, a CNN can learn to recognize a wide variety of objects with remarkable accuracy.&lt;/p&gt;
&lt;p&gt;In a &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/deep-learning-with-keras-using-mnst-dataset/&#34;&gt;previous blog post&lt;/a&gt;, we used a two-regular dense layer neural network for the MNIST images classification. The testing accuracy was 97.8%.&lt;/p&gt;
&lt;p&gt;Let‚Äôs implement a convolutional neural network and see how it performs.&lt;/p&gt;
&lt;p&gt;Understand CNN in a high level with &lt;a href=&#34;https://www.youtube.com/watch?v=HGwBXDKFk9I&#34;&gt;Josh Starmer‚Äôs video&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/CNN.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-load-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Let‚Äôs load the data&lt;/h3&gt;
&lt;p&gt;Load the libraries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install.packages(&amp;quot;keras&amp;quot;) install the keras R package
library(keras)
#install_keras(version = &amp;quot;release&amp;quot;)  install the core Keras library and TensorFlow&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)
use_condaenv(&amp;quot;r-reticulate&amp;quot;)
mnist&amp;lt;- dataset_mnist()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;split the training and testing sets&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_images&amp;lt;- mnist$train$x
train_labels&amp;lt;- mnist$train$y
train_labels&amp;lt;- to_categorical(train_labels)

test_images&amp;lt;- mnist$test$x
test_labels&amp;lt;- mnist$test$y
test_labels&amp;lt;- to_categorical(test_labels)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The training sets is a 3D tensor&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(train_images)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 60000    28    28&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is an array of 60,000 matrices of 28x28 integers. Each matrix is a grayscale image:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the fifth matrix
digit&amp;lt;- train_images[5, ,]
dim(digit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 28 28&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(as.raster(digit, max = 255))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-04-09-how-to-classify-mnist-images-with-convolutional-neural-network_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It is a matrix denoting the image of 9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reshape-the-data-into-3d-tensor&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;reshape the data into 3D tensor&lt;/h3&gt;
&lt;p&gt;In our regular dense neural network model, we reshaped the tensor into 2D.&lt;/p&gt;
&lt;p&gt;Importantly, a &lt;code&gt;convnet&lt;/code&gt; takes tensors of shape (image_height, image_width, image_channels), not including the
batch dimension. We will convert the input to size (28, 28, 1). For the MNIST dataset, it is black and white, so only 1 channel.&lt;/p&gt;
&lt;p&gt;For colored images, you will have 3 channels (RGB colors).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# a 2D tensor/matrix
digit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
#&amp;gt;  [1,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [2,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [3,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [4,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [5,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [6,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [7,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [8,]    0    0    0    0    0    0    0    0    0     0     0     0    55
#&amp;gt;  [9,]    0    0    0    0    0    0    0    0    0     0     0    87   232
#&amp;gt; [10,]    0    0    0    0    0    0    0    0    0     4    57   242   252
#&amp;gt; [11,]    0    0    0    0    0    0    0    0    0    96   252   252   183
#&amp;gt; [12,]    0    0    0    0    0    0    0    0  132   253   252   146    14
#&amp;gt; [13,]    0    0    0    0    0    0    0  126  253   247   176     9     0
#&amp;gt; [14,]    0    0    0    0    0    0   16  232  252   176     0     0     0
#&amp;gt; [15,]    0    0    0    0    0    0   22  252  252    30    22   119   197
#&amp;gt; [16,]    0    0    0    0    0    0   16  231  252   253   252   252   252
#&amp;gt; [17,]    0    0    0    0    0    0    0   55  235   253   217   138    42
#&amp;gt; [18,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [19,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [20,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [21,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [22,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [23,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [24,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [25,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [26,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [27,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [28,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]
#&amp;gt;  [1,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [2,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [3,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [4,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [5,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [6,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [7,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [8,]   148   210   253   253   113    87   148    55     0     0     0     0
#&amp;gt;  [9,]   252   253   189   210   252   252   253   168     0     0     0     0
#&amp;gt; [10,]   190    65     5    12   182   252   253   116     0     0     0     0
#&amp;gt; [11,]    14     0     0    92   252   252   225    21     0     0     0     0
#&amp;gt; [12,]     0     0     0   215   252   252    79     0     0     0     0     0
#&amp;gt; [13,]     0     8    78   245   253   129     0     0     0     0     0     0
#&amp;gt; [14,]    36   201   252   252   169    11     0     0     0     0     0     0
#&amp;gt; [15,]   241   253   252   251    77     0     0     0     0     0     0     0
#&amp;gt; [16,]   226   227   252   231     0     0     0     0     0     0     0     0
#&amp;gt; [17,]    24   192   252   143     0     0     0     0     0     0     0     0
#&amp;gt; [18,]    62   255   253   109     0     0     0     0     0     0     0     0
#&amp;gt; [19,]    71   253   252    21     0     0     0     0     0     0     0     0
#&amp;gt; [20,]     0   253   252    21     0     0     0     0     0     0     0     0
#&amp;gt; [21,]    71   253   252    21     0     0     0     0     0     0     0     0
#&amp;gt; [22,]   106   253   252    21     0     0     0     0     0     0     0     0
#&amp;gt; [23,]    45   255   253    21     0     0     0     0     0     0     0     0
#&amp;gt; [24,]     0   218   252    56     0     0     0     0     0     0     0     0
#&amp;gt; [25,]     0    96   252   189    42     0     0     0     0     0     0     0
#&amp;gt; [26,]     0    14   184   252   170    11     0     0     0     0     0     0
#&amp;gt; [27,]     0     0    14   147   252    42     0     0     0     0     0     0
#&amp;gt; [28,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;       [,26] [,27] [,28]
#&amp;gt;  [1,]     0     0     0
#&amp;gt;  [2,]     0     0     0
#&amp;gt;  [3,]     0     0     0
#&amp;gt;  [4,]     0     0     0
#&amp;gt;  [5,]     0     0     0
#&amp;gt;  [6,]     0     0     0
#&amp;gt;  [7,]     0     0     0
#&amp;gt;  [8,]     0     0     0
#&amp;gt;  [9,]     0     0     0
#&amp;gt; [10,]     0     0     0
#&amp;gt; [11,]     0     0     0
#&amp;gt; [12,]     0     0     0
#&amp;gt; [13,]     0     0     0
#&amp;gt; [14,]     0     0     0
#&amp;gt; [15,]     0     0     0
#&amp;gt; [16,]     0     0     0
#&amp;gt; [17,]     0     0     0
#&amp;gt; [18,]     0     0     0
#&amp;gt; [19,]     0     0     0
#&amp;gt; [20,]     0     0     0
#&amp;gt; [21,]     0     0     0
#&amp;gt; [22,]     0     0     0
#&amp;gt; [23,]     0     0     0
#&amp;gt; [24,]     0     0     0
#&amp;gt; [25,]     0     0     0
#&amp;gt; [26,]     0     0     0
#&amp;gt; [27,]     0     0     0
#&amp;gt; [28,]     0     0     0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#reshape it to 3D
digit2&amp;lt;- array_reshape(digit, c(28, 28, 1))
digit2[,,1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
#&amp;gt;  [1,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [2,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [3,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [4,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [5,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [6,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [7,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;  [8,]    0    0    0    0    0    0    0    0    0     0     0     0    55
#&amp;gt;  [9,]    0    0    0    0    0    0    0    0    0     0     0    87   232
#&amp;gt; [10,]    0    0    0    0    0    0    0    0    0     4    57   242   252
#&amp;gt; [11,]    0    0    0    0    0    0    0    0    0    96   252   252   183
#&amp;gt; [12,]    0    0    0    0    0    0    0    0  132   253   252   146    14
#&amp;gt; [13,]    0    0    0    0    0    0    0  126  253   247   176     9     0
#&amp;gt; [14,]    0    0    0    0    0    0   16  232  252   176     0     0     0
#&amp;gt; [15,]    0    0    0    0    0    0   22  252  252    30    22   119   197
#&amp;gt; [16,]    0    0    0    0    0    0   16  231  252   253   252   252   252
#&amp;gt; [17,]    0    0    0    0    0    0    0   55  235   253   217   138    42
#&amp;gt; [18,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [19,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [20,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [21,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [22,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [23,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [24,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [25,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [26,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [27,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt; [28,]    0    0    0    0    0    0    0    0    0     0     0     0     0
#&amp;gt;       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]
#&amp;gt;  [1,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [2,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [3,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [4,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [5,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [6,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [7,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;  [8,]   148   210   253   253   113    87   148    55     0     0     0     0
#&amp;gt;  [9,]   252   253   189   210   252   252   253   168     0     0     0     0
#&amp;gt; [10,]   190    65     5    12   182   252   253   116     0     0     0     0
#&amp;gt; [11,]    14     0     0    92   252   252   225    21     0     0     0     0
#&amp;gt; [12,]     0     0     0   215   252   252    79     0     0     0     0     0
#&amp;gt; [13,]     0     8    78   245   253   129     0     0     0     0     0     0
#&amp;gt; [14,]    36   201   252   252   169    11     0     0     0     0     0     0
#&amp;gt; [15,]   241   253   252   251    77     0     0     0     0     0     0     0
#&amp;gt; [16,]   226   227   252   231     0     0     0     0     0     0     0     0
#&amp;gt; [17,]    24   192   252   143     0     0     0     0     0     0     0     0
#&amp;gt; [18,]    62   255   253   109     0     0     0     0     0     0     0     0
#&amp;gt; [19,]    71   253   252    21     0     0     0     0     0     0     0     0
#&amp;gt; [20,]     0   253   252    21     0     0     0     0     0     0     0     0
#&amp;gt; [21,]    71   253   252    21     0     0     0     0     0     0     0     0
#&amp;gt; [22,]   106   253   252    21     0     0     0     0     0     0     0     0
#&amp;gt; [23,]    45   255   253    21     0     0     0     0     0     0     0     0
#&amp;gt; [24,]     0   218   252    56     0     0     0     0     0     0     0     0
#&amp;gt; [25,]     0    96   252   189    42     0     0     0     0     0     0     0
#&amp;gt; [26,]     0    14   184   252   170    11     0     0     0     0     0     0
#&amp;gt; [27,]     0     0    14   147   252    42     0     0     0     0     0     0
#&amp;gt; [28,]     0     0     0     0     0     0     0     0     0     0     0     0
#&amp;gt;       [,26] [,27] [,28]
#&amp;gt;  [1,]     0     0     0
#&amp;gt;  [2,]     0     0     0
#&amp;gt;  [3,]     0     0     0
#&amp;gt;  [4,]     0     0     0
#&amp;gt;  [5,]     0     0     0
#&amp;gt;  [6,]     0     0     0
#&amp;gt;  [7,]     0     0     0
#&amp;gt;  [8,]     0     0     0
#&amp;gt;  [9,]     0     0     0
#&amp;gt; [10,]     0     0     0
#&amp;gt; [11,]     0     0     0
#&amp;gt; [12,]     0     0     0
#&amp;gt; [13,]     0     0     0
#&amp;gt; [14,]     0     0     0
#&amp;gt; [15,]     0     0     0
#&amp;gt; [16,]     0     0     0
#&amp;gt; [17,]     0     0     0
#&amp;gt; [18,]     0     0     0
#&amp;gt; [19,]     0     0     0
#&amp;gt; [20,]     0     0     0
#&amp;gt; [21,]     0     0     0
#&amp;gt; [22,]     0     0     0
#&amp;gt; [23,]     0     0     0
#&amp;gt; [24,]     0     0     0
#&amp;gt; [25,]     0     0     0
#&amp;gt; [26,]     0     0     0
#&amp;gt; [27,]     0     0     0
#&amp;gt; [28,]     0     0     0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(digit2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 28 28  1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;reshape input tensor including the batch (6000 images):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#train_images&amp;lt;- array_reshape(train_images, c(60000, 28 * 28))

train_images&amp;lt;- array_reshape(train_images, c(60000, 28, 28, 1))

## one of the image
# train_images[1,,,]
train_images&amp;lt;- train_images/255

test_images&amp;lt;- array_reshape(test_images, c(10000, 28, 28, 1))
test_images&amp;lt;- test_images/255&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Read my previous &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/deep-learning-with-keras-using-mnst-dataset/&#34;&gt;post&lt;/a&gt; on how to reshape tensors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(train_images)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 60000    28    28     1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(test_images)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 10000    28    28     1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;build-the-network&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;build the network&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model&amp;lt;- keras_model_sequential() %&amp;gt;%
        layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = &amp;quot;relu&amp;quot;,
                     input_shape = c(28, 28, 1)) %&amp;gt;%
        layer_max_pooling_2d(pool_size = c(2,2)) %&amp;gt;%
        layer_conv_2d(filters = 64, kernel_size =  c(3,3), activation = &amp;quot;relu&amp;quot;) %&amp;gt;%
        layer_max_pooling_2d(pool_size = c(2,2)) %&amp;gt;%
        layer_conv_2d(filters = 64, kernel_size =  c(3,3), activation = &amp;quot;relu&amp;quot;)

model&amp;lt;- model %&amp;gt;%
        layer_flatten() %&amp;gt;%
        layer_dense(units = 64, activation = &amp;quot;relu&amp;quot;) %&amp;gt;%
        layer_dense(units = 10, activation = &amp;quot;softmax&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Take a look at the details of the model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Model: &amp;quot;sequential&amp;quot;
#&amp;gt; ________________________________________________________________________________
#&amp;gt; Layer (type)                        Output Shape                    Param #     
#&amp;gt; ================================================================================
#&amp;gt; conv2d_2 (Conv2D)                   (None, 26, 26, 32)              320         
#&amp;gt; ________________________________________________________________________________
#&amp;gt; max_pooling2d_1 (MaxPooling2D)      (None, 13, 13, 32)              0           
#&amp;gt; ________________________________________________________________________________
#&amp;gt; conv2d_1 (Conv2D)                   (None, 11, 11, 64)              18496       
#&amp;gt; ________________________________________________________________________________
#&amp;gt; max_pooling2d (MaxPooling2D)        (None, 5, 5, 64)                0           
#&amp;gt; ________________________________________________________________________________
#&amp;gt; conv2d (Conv2D)                     (None, 3, 3, 64)                36928       
#&amp;gt; ________________________________________________________________________________
#&amp;gt; flatten (Flatten)                   (None, 576)                     0           
#&amp;gt; ________________________________________________________________________________
#&amp;gt; dense_1 (Dense)                     (None, 64)                      36928       
#&amp;gt; ________________________________________________________________________________
#&amp;gt; dense (Dense)                       (None, 10)                      650         
#&amp;gt; ================================================================================
#&amp;gt; Total params: 93,322
#&amp;gt; Trainable params: 93,322
#&amp;gt; Non-trainable params: 0
#&amp;gt; ________________________________________________________________________________&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Convolutions operates over 3D tensors, called &lt;code&gt;feature maps&lt;/code&gt; with two spatial axes (&lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt;) as well
as the a &lt;code&gt;depth&lt;/code&gt; axis. For an RGB image, the dimension of the depth axis is 3 with Red, green and blue channels.&lt;/p&gt;
&lt;p&gt;For the black and white MNIST images, the depth is 1 (levels of gray).&lt;/p&gt;
&lt;p&gt;The convolution extracts patches from its input feature map and applies the same transformation for all patches, producing
an &lt;code&gt;output feature map&lt;/code&gt;. This out put feature map is still 3D: width, height and depth. But the depth now is an arbitrary
parameter of the layer and it does not represent the RGB colors: they are called filters.&lt;/p&gt;
&lt;p&gt;Filters encode specific aspects of the input data. At a higher level, a single filter can encode the concept ‚Äúpresence of a
face in the image‚Äù.&lt;/p&gt;
&lt;p&gt;In our MNIST example, we take a (28, 28, 1) input feature map and output a feature map of (26, 26, 32). It computes 32 filters over its input.
Each of those 32 output channels contains a 26 x 26 grid of values, which is a response map of the filter over the input, indicating
the response of that filter pattern at different locations in the input.&lt;/p&gt;
&lt;p&gt;Two key parameters we defined in our model&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;size of the patches extracted from the inputs: they are typically 3x3 or 5x5. We used 3x3. Without padding, for a 28 x 28 image, the output feature map
dimension becomes 26 x 26 (Think how many 3x3 patches you can get from a 28x28 grid.)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Depth of the output feature map: the number of filters computed by the convolution. We used 32 and ended with 64.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Max-pooling consists of extracting windows from the output feature maps and outputting the max value of each channel. Instead of transforming local patches
via a learned linear transformation, they are transformed via a hard coded max tensor operation. The max pooling is usually done with 2x2 window.
That‚Äôs why after 1st max pooling, the 26 x 26 grid becomes 13 x 13; and after 2nd max pooling, 11 x 11 becomes 5x 5. Because of the border issues,
the grid becomes smaller and smaller: 28 x 28 to 26 x 26; 13 x 13 to 11 x 11, 5x 5 to 3x3.&lt;/p&gt;
&lt;p&gt;Let‚Äôs make a new model by padding:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model2&amp;lt;- keras_model_sequential() %&amp;gt;%
        layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = &amp;quot;relu&amp;quot;,
                     input_shape = c(28, 28, 1), padding = &amp;quot;same&amp;quot;) %&amp;gt;%
        layer_max_pooling_2d(pool_size = c(2,2), padding = &amp;quot;same&amp;quot;) %&amp;gt;%
        layer_conv_2d(filters = 64, kernel_size =  c(3,3), activation = &amp;quot;relu&amp;quot;, padding = &amp;quot;same&amp;quot;) %&amp;gt;%
        layer_max_pooling_2d(pool_size = c(2,2), padding = &amp;quot;same&amp;quot;) %&amp;gt;%
        layer_conv_2d(filters = 64, kernel_size =  c(3,3), activation = &amp;quot;relu&amp;quot;, padding = &amp;quot;same&amp;quot;)

model2&amp;lt;- model2 %&amp;gt;%
        layer_flatten() %&amp;gt;%
        layer_dense(units = 64, activation = &amp;quot;relu&amp;quot;) %&amp;gt;%
        layer_dense(units = 10, activation = &amp;quot;softmax&amp;quot;)

model2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Model: &amp;quot;sequential_1&amp;quot;
#&amp;gt; ________________________________________________________________________________
#&amp;gt; Layer (type)                        Output Shape                    Param #     
#&amp;gt; ================================================================================
#&amp;gt; conv2d_5 (Conv2D)                   (None, 28, 28, 32)              320         
#&amp;gt; ________________________________________________________________________________
#&amp;gt; max_pooling2d_3 (MaxPooling2D)      (None, 14, 14, 32)              0           
#&amp;gt; ________________________________________________________________________________
#&amp;gt; conv2d_4 (Conv2D)                   (None, 14, 14, 64)              18496       
#&amp;gt; ________________________________________________________________________________
#&amp;gt; max_pooling2d_2 (MaxPooling2D)      (None, 7, 7, 64)                0           
#&amp;gt; ________________________________________________________________________________
#&amp;gt; conv2d_3 (Conv2D)                   (None, 7, 7, 64)                36928       
#&amp;gt; ________________________________________________________________________________
#&amp;gt; flatten_1 (Flatten)                 (None, 3136)                    0           
#&amp;gt; ________________________________________________________________________________
#&amp;gt; dense_3 (Dense)                     (None, 64)                      200768      
#&amp;gt; ________________________________________________________________________________
#&amp;gt; dense_2 (Dense)                     (None, 10)                      650         
#&amp;gt; ================================================================================
#&amp;gt; Total params: 257,162
#&amp;gt; Trainable params: 257,162
#&amp;gt; Non-trainable params: 0
#&amp;gt; ________________________________________________________________________________&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After we use &lt;code&gt;padding = same&lt;/code&gt;(default is valid), our input image is 28x28, after 1st conv2d, it is still 28x28,
max pooling reduces it to half: 14 x 14, but the second conv2d keeps it 14x 14, then max pooling reduced it to half again to 7x7 etc etc.&lt;/p&gt;
&lt;p&gt;Let‚Äôs compile the first model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model %&amp;gt;%
        compile(optimizer = &amp;quot;rmsprop&amp;quot;,
                loss = &amp;quot;categorical_crossentropy&amp;quot;,
                metrics= c(&amp;quot;accuracy&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, train the model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model %&amp;gt;%
        fit(train_images, train_labels, epochs = 5, batch_size = 64)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The network will iterate on the training data in mini-batches of 64 samples, 5 times over(each iteration over all the training data is called an epoch).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluate-the-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;evaluate the model&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;metrics&amp;lt;- model %&amp;gt;% evaluate(test_images, test_labels)
metrics&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;       loss   accuracy 
#&amp;gt; 0.02705173 0.99220002&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It blows my mind that this simple CNN reached an accuracy of ~99%!
The time is a little longer than the regular dense layer neural network.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;take-home-messages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Take home messages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;CNN reduces the number of input nodes and thus total number of parameters (the pooling step does it).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;CNNs are capable of hierarchical feature learning: CNNs use multiple layers to learn hierarchical representations of an image, starting with low-level features like edges and gradually building up to more complex features like shapes and objects. This allows them to extract more meaningful features from images, which can improve their accuracy and performance. it tolerate small shifts in where the pixle are in the image. CNN learns local features such as an ‚Äúear‚Äù and can find it in other places of the image.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;CNNs are able to learn on their own: One of the key advantages of CNNs is that they are able to learn from data without being explicitly programmed to do so. This means that they can automatically adapt to new data and improve their performance over time, making them highly flexible and adaptable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;CNNs can be highly accurate: When trained on large datasets, CNNs can achieve very high levels of accuracy in image recognition tasks. In fact, in some cases they can even outperform humans, making them a valuable tool for tasks like medical diagnosis, quality control, and more.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We can use k-fold cross-validation and a validate set to further increase the prediction accuracy for testing data.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to construct a spatial object in Seurat</title>
      <link>/post/how-to-construct-a-spatial-object-in-seurat/</link>
      <pubDate>Thu, 30 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-construct-a-spatial-object-in-seurat/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;sign-up-for-my-newsletter-to-not-miss-a-post-like-this&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sign up for my newsletter to not miss a post like this&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/newsletter&#34; class=&#34;uri&#34;&gt;https://divingintogeneticsandgenomics.ck.page/newsletter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Single-cell spatial transcriptome data is a new and advanced technology that combines the study of individual cells‚Äô genes and their location in a tissue to understand the complex cellular and molecular differences within it. This allows scientists to investigate how genes are expressed and how cells interact with each other with much greater detail than before.&lt;/p&gt;
&lt;p&gt;Do not be intimidated by the complexity of the data. If you already know how to analyze regular single cell data (e.g., 10x data), it is not hard to understand and analyze spatial data. In this blog post, I will walk you through the basic analsyis steps.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;download-the-demo-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;download the demo data&lt;/h3&gt;
&lt;p&gt;Following &lt;a href=&#34;https://satijalab.org/seurat/articles/spatial_vignette_2.html&#34; class=&#34;uri&#34;&gt;https://satijalab.org/seurat/articles/spatial_vignette_2.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Download the public breast &lt;code&gt;vizgen&lt;/code&gt; cancer data.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;gsutil -m cp -n gs://vz-ffpe-showcase/HumanOvarianCancerPatient2Slice2/cell_by_gene.csv \
    gs://vz-ffpe-showcase/HumanOvarianCancerPatient2Slice2/cell_metadata.csv \
    ./spatial_data/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is critical to understand the data files before you do anything.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The data for each sample is split up across a few different files. &lt;code&gt;cell_by_gene.csv&lt;/code&gt; is the standard file containing cells as rows and genes as columns. &lt;code&gt;cell_metadata.csv&lt;/code&gt; contains additional information for cells relating to spatial data, namely x-y coordinates for each cell (min, center, and max). These files are both preprocessed. To access more raw data, we can examine the cell_bounds/ folder and detected_transcripts.csv. The former contains many files, named feature_data_{fov}.hdf5, corresponding to the fov column in cell_metadata.csv. These hdf5 files contain boundary coordinates for each cell, giving a less boxy outline than provided in the processed data. detected_transcripts.csv contains transcripts in each row with their respective x-y coordinates, which are then assigned to cells based on the cell boundaries.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;read-in-the-data-and-pre-process&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;read in the data and pre-process&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Seurat)
library(here)
library(ggplot2)
library(dplyr)

# the LoadVizgen function requires the raw segmentation files which is too big. We will only use the x,y coordinates 
# vizgen.obj &amp;lt;- LoadVizgen(data.dir = here(&amp;quot;data&amp;quot;))

vizgen.input &amp;lt;- ReadVizgen(data.dir = &amp;quot;~/blog_data/spatial_data&amp;quot;, type = &amp;quot;centroids&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For most of the analysis, we will only need the x,y coordinates (the center of the cell). You can also read in
the raw segmentation file( which gives you more detailed cell shape information), or set &lt;code&gt;type = &#34;box&#34;&lt;/code&gt; to get the
rectangular information of a cell (xmin, xmax, ymin and ymax).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;vizgen.input&lt;/code&gt; is a list containing the count matrix and the spatial centrioids.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vizgen.input$centroids %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           x        y cell
#&amp;gt; 1 10145.793 5611.687 7650
#&amp;gt; 2  9975.309 5626.726 7654
#&amp;gt; 3 10129.183 5630.601 7655
#&amp;gt; 4 10112.692 5635.038 7656
#&amp;gt; 5 10151.574 5634.673 7657
#&amp;gt; 6 10099.624 5636.831 7658&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## This gives you the image 
ggplot(vizgen.input$centroids, aes(x= x, y = y))+
        geom_point(size = 0.1, color = &amp;quot;grey&amp;quot;) +
        theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-30-how-to-construct-a-spatial-object-in-seurat_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Create a seurat object. The documentation for making a spatial object is sparse.
I went to the &lt;a href=&#34;https://github.com/satijalab/seurat/blob/763259d05991d40721dee99c9919ec6d4491d15e/R/convenience.R#L139&#34;&gt;source code&lt;/a&gt;
of &lt;code&gt;LoadVizgen&lt;/code&gt; and came up with the code below.&lt;/p&gt;
&lt;p&gt;You can read the code from the same link and see how other types of spatial data (10x Xenium, nanostring) are read into Seurat.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## remove the Blank-* control probes
blank_index&amp;lt;- which(stringr::str_detect(rownames(vizgen.input$transcripts), &amp;quot;^Blank&amp;quot;))

transcripts&amp;lt;-vizgen.input$transcripts[-blank_index, ]

dim(vizgen.input$transcripts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]   550 71381&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(transcripts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]   500 71381&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are 50 such probes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-seurat-spatial-object&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;create a Seurat spatial object&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vizgen.obj&amp;lt;- CreateSeuratObject(counts = transcripts, assay = &amp;quot;Vizgen&amp;quot;)

cents &amp;lt;- CreateCentroids(vizgen.input$centroids)
segmentations.data &amp;lt;- list(
    &amp;quot;centroids&amp;quot; = cents,
    &amp;quot;segmentation&amp;quot; = NULL
  )

coords &amp;lt;- CreateFOV(
    coords = segmentations.data,
    type = c(&amp;quot;segmentation&amp;quot;, &amp;quot;centroids&amp;quot;),
    molecules = NULL,
    assay = &amp;quot;Vizgen&amp;quot;
  )
 
vizgen.obj[[&amp;quot;p2s2&amp;quot;]] &amp;lt;- coords
 
GetTissueCoordinates(vizgen.obj[[&amp;quot;p2s2&amp;quot;]][[&amp;quot;centroids&amp;quot;]]) %&amp;gt;%
        head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           x        y cell
#&amp;gt; 1 10145.793 5611.687 7650
#&amp;gt; 2  9975.309 5626.726 7654
#&amp;gt; 3 10129.183 5630.601 7655
#&amp;gt; 4 10112.692 5635.038 7656
#&amp;gt; 5 10151.574 5634.673 7657
#&amp;gt; 6 10099.624 5636.831 7658&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ImageDimPlot(vizgen.obj, fov = &amp;quot;p2s2&amp;quot;, cols = &amp;quot;polychrome&amp;quot;, axes = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-30-how-to-construct-a-spatial-object-in-seurat_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note, from this recent paper &lt;a href=&#34;https://www.nature.com/articles/s41467-023-37168-7&#34;&gt;A comprehensive benchmarking with practical guidelines for cellular deconvolution of spatial transcriptomics&lt;/a&gt;, &lt;code&gt;sctransform normalization&lt;/code&gt; works worse than log normalization for deconvolution.&lt;/p&gt;
&lt;p&gt;This part is the same as regular single-cell RNAseq data. For clustering, one can also incorporate the spatial information, but that‚Äôs
something out of this tutorial.&lt;/p&gt;
&lt;p&gt;I will use log normalization.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vizgen.obj &amp;lt;- NormalizeData(vizgen.obj, normalization.method = &amp;quot;LogNormalize&amp;quot;, scale.factor = 10000) %&amp;gt;%
  ScaleData() 
vizgen.obj &amp;lt;- RunPCA(vizgen.obj, npcs = 30, features = rownames(vizgen.obj))
vizgen.obj &amp;lt;- RunUMAP(vizgen.obj, dims = 1:30)
vizgen.obj &amp;lt;- FindNeighbors(vizgen.obj, reduction = &amp;quot;pca&amp;quot;, dims = 1:30)
vizgen.obj &amp;lt;- FindClusters(vizgen.obj, resolution = 0.3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck
#&amp;gt; 
#&amp;gt; Number of nodes: 71381
#&amp;gt; Number of edges: 2100209
#&amp;gt; 
#&amp;gt; Running Louvain algorithm...
#&amp;gt; Maximum modularity in 10 random starts: 0.9109
#&amp;gt; Number of communities: 14
#&amp;gt; Elapsed time: 23 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;umap-by-cluster&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;UMAP by cluster&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DimPlot(vizgen.obj, reduction = &amp;quot;umap&amp;quot;, label = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-30-how-to-construct-a-spatial-object-in-seurat_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;image-plot-by-cluster&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Image plot by cluster&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ImageDimPlot(vizgen.obj, fov = &amp;quot;p2s2&amp;quot;, cols = &amp;quot;polychrome&amp;quot;, axes = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-30-how-to-construct-a-spatial-object-in-seurat_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;find-cell-markers&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Find cell markers&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tictoc)
tic()
markers&amp;lt;- presto::wilcoxauc(vizgen.obj, &amp;#39;seurat_clusters&amp;#39;, assay = &amp;#39;data&amp;#39;,seurat_assay= &amp;quot;Vizgen&amp;quot; )
toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 1.137 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;top_markers&amp;lt;- presto::top_markers(markers, n =3)

top_markers&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 3 √ó 13
#&amp;gt;    rank `0`   `1`    `10`  `11`  `2`   `3`   `4`   `5`   `6`   `7`   `8`   `9`  
#&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
#&amp;gt; 1     1 MUC1  LRP1   KIT   MZB1  FN1   COL1‚Ä¶ C1QC  CDKN‚Ä¶ COL4‚Ä¶ LAMC2 ETS1  IL21 
#&amp;gt; 2     2 PKM   ENG    CTSG  CD79A SFRP2 FFAR2 CD14  LAMC2 VWF   MKI67 IL2RB IDO2 
#&amp;gt; 3     3 SOX9  COL1A1 ITGAM HLA-B COL1‚Ä¶ CXCR1 CSF1R SERP‚Ä¶ PECA‚Ä¶ FOXM1 CD3E  XCL1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;top_markers&amp;lt;- top_markers %&amp;gt;% select(-rank) %&amp;gt;% stack() %&amp;gt;%
        pull(values) %&amp;gt;%
        unique()

top_markers&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1] &amp;quot;MUC1&amp;quot;     &amp;quot;PKM&amp;quot;      &amp;quot;SOX9&amp;quot;     &amp;quot;LRP1&amp;quot;     &amp;quot;ENG&amp;quot;      &amp;quot;COL1A1&amp;quot;  
#&amp;gt;  [7] &amp;quot;KIT&amp;quot;      &amp;quot;CTSG&amp;quot;     &amp;quot;ITGAM&amp;quot;    &amp;quot;MZB1&amp;quot;     &amp;quot;CD79A&amp;quot;    &amp;quot;HLA-B&amp;quot;   
#&amp;gt; [13] &amp;quot;FN1&amp;quot;      &amp;quot;SFRP2&amp;quot;    &amp;quot;FFAR2&amp;quot;    &amp;quot;CXCR1&amp;quot;    &amp;quot;C1QC&amp;quot;     &amp;quot;CD14&amp;quot;    
#&amp;gt; [19] &amp;quot;CSF1R&amp;quot;    &amp;quot;CDKN1A&amp;quot;   &amp;quot;LAMC2&amp;quot;    &amp;quot;SERPINA1&amp;quot; &amp;quot;COL4A1&amp;quot;   &amp;quot;VWF&amp;quot;     
#&amp;gt; [25] &amp;quot;PECAM1&amp;quot;   &amp;quot;MKI67&amp;quot;    &amp;quot;FOXM1&amp;quot;    &amp;quot;ETS1&amp;quot;     &amp;quot;IL2RB&amp;quot;    &amp;quot;CD3E&amp;quot;    
#&amp;gt; [31] &amp;quot;IL21&amp;quot;     &amp;quot;IDO2&amp;quot;     &amp;quot;XCL1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;manual_markers&amp;lt;- c(&amp;quot;CD3D&amp;quot;, &amp;quot;CD4&amp;quot;, &amp;quot;CD8A&amp;quot;, &amp;quot;CD8B&amp;quot;, &amp;quot;CD14&amp;quot;,
                                            &amp;quot;MS4A1&amp;quot;, &amp;quot;FCGR3A&amp;quot;, &amp;quot;PTPRC&amp;quot;, &amp;quot;EPCAM&amp;quot;, 
                                            &amp;quot;KIT&amp;quot;, &amp;quot;PDGFA&amp;quot;, &amp;quot;CCR7&amp;quot;,&amp;quot;GNLY&amp;quot;, 
                                            &amp;quot;PRF1&amp;quot;, &amp;quot;GZMB&amp;quot;, &amp;quot;COL1A1&amp;quot;, &amp;quot;PECAM1&amp;quot;, 
                                            &amp;quot;NKG7&amp;quot;,&amp;quot;XCL1&amp;quot;, &amp;quot;ICOS&amp;quot;, &amp;quot;PDCD1&amp;quot;, &amp;quot;TIGIT&amp;quot;, 
                                            &amp;quot;HAVCR2&amp;quot;, &amp;quot;NCAM1&amp;quot;, &amp;quot;CD79A&amp;quot;, &amp;quot;ITGAM&amp;quot;, 
                                            &amp;quot;ITGAX&amp;quot;, &amp;quot;FCER1A&amp;quot;, &amp;quot;CD86&amp;quot;)
scCustomize::Clustered_DotPlot(vizgen.obj,  
                               features = c(top_markers, manual_markers), 
                               plot_km_elbow = FALSE,
                               row_label_size = 8)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-30-how-to-construct-a-spatial-object-in-seurat_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;768&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(vizgen.obj$seurat_clusters)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 
#&amp;gt;     0     1     2     3     4     5     6     7     8     9    10    11 
#&amp;gt; 34147 12200  6251  5505  5324  3122  1656  1164  1065   647   183   117&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The cancer cell clusters (0,5,7) marked by EPCAM is the most abundant cells in this sample.
cluster 8 is the T cells; cluster 4 is mono/mac, cluster 10 seems to be the MAST (KIT) cells;
cluster 11 is the B (CD79A, MSA41) cells; cluster 2 is fibroblasts (SFRP2);
cluster 1 is a different fibroblasts cluster; cluster 6 is Endothelial cells (PECAM1)&lt;/p&gt;
&lt;p&gt;cluster 9 probably is an artifact cluster. It is the strange circle in the UMAP.
Let‚Äôs take a look at the count distribution for all clusters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

vizgen.obj@meta.data %&amp;gt;%
        ggplot(aes(x=  nCount_Vizgen)) +
        geom_histogram() +
        facet_wrap(~seurat_clusters, scales = &amp;quot;free&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-30-how-to-construct-a-spatial-object-in-seurat_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;
cluster 9 have very low counts for all the cells. Those cells should be removed from the pre-processing steps by:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CreateSeuratObject(min.features = 5)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;min.features: Include cells where at least this many features are detected.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- ImageFeaturePlot(vizgen.obj, features = c(&amp;quot;EPCAM&amp;quot;, &amp;quot;CD79A&amp;quot;))
p1 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-30-how-to-construct-a-spatial-object-in-seurat_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We plotted the feature expression on the image using the &lt;code&gt;ImageFeaturePlot&lt;/code&gt;. Let‚Äôs reproduce it using &lt;code&gt;ggplot2&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vizgen.input$centroids %&amp;gt;%
        ggplot(aes(x=y, y = x)) +
        geom_point(color = &amp;quot;grey&amp;quot;, size = 0.2) +
        theme_classic(base_size = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-30-how-to-construct-a-spatial-object-in-seurat_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now, we need to highlight the points using the expression value of &lt;code&gt;EPCAM&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;Some helper function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;matrix_to_expression_df&amp;lt;- function(x, obj){
        df&amp;lt;- x %&amp;gt;%
                as.matrix() %&amp;gt;% 
                as.data.frame() %&amp;gt;%
                tibble::rownames_to_column(var= &amp;quot;gene&amp;quot;) %&amp;gt;%
                tidyr::pivot_longer(cols = -1, names_to = &amp;quot;cell&amp;quot;, values_to = &amp;quot;expression&amp;quot;) %&amp;gt;%
                tidyr::pivot_wider(names_from = &amp;quot;gene&amp;quot;, values_from = expression) %&amp;gt;%
                left_join(obj@meta.data %&amp;gt;% 
                                  tibble::rownames_to_column(var = &amp;quot;cell&amp;quot;))
        return(df)
}


get_expression_data&amp;lt;- function(obj, assay = &amp;quot;RNA&amp;quot;, slot = &amp;quot;data&amp;quot;, 
                               genes = NULL, cells = NULL){
        if (is.null(genes) &amp;amp; !is.null(cells)){
                df&amp;lt;- GetAssayData(obj, assay = assay, slot = slot)[, cells, drop = FALSE] %&amp;gt;%
                        matrix_to_expression_df(obj = obj)
        } else if (!is.null(genes) &amp;amp; is.null(cells)){
                df &amp;lt;- GetAssayData(obj, assay = assay, slot = slot)[genes, , drop = FALSE] %&amp;gt;%
                        matrix_to_expression_df(obj = obj)
        } else if (is.null(genes &amp;amp; is.null(cells))){
                df &amp;lt;- GetAssayData(obj, assay = assay, slot = slot)[, , drop = FALSE] %&amp;gt;%
                        matrix_to_expression_df(obj = obj)
        } else {
                df&amp;lt;- GetAssayData(obj, assay = assay, slot = slot)[genes, cells, drop = FALSE] %&amp;gt;%
                        matrix_to_expression_df(obj = obj)
        }
        return(df)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Get the expression data and merge with the spatial information.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df&amp;lt;- get_expression_data(vizgen.obj, assay=&amp;quot;Vizgen&amp;quot;, slot = &amp;quot;data&amp;quot;, genes = &amp;quot;EPCAM&amp;quot;)

head(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 6 √ó 7
#&amp;gt;   cell  EPCAM orig.ident    nCount_Vizgen nFeature_Vizgen Vizgen_snn_res.0.3
#&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;                 &amp;lt;dbl&amp;gt;           &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;             
#&amp;gt; 1 0      0    SeuratProject             0               0 9                 
#&amp;gt; 2 1      0    SeuratProject             0               0 9                 
#&amp;gt; 3 2      0    SeuratProject            17              11 3                 
#&amp;gt; 4 3      3.93 SeuratProject           400             108 0                 
#&amp;gt; 5 4      0    SeuratProject             9               9 3                 
#&amp;gt; 6 5      0    SeuratProject             3               3 3                 
#&amp;gt; # ‚Ä¶ with 1 more variable: seurat_clusters &amp;lt;fct&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vizgen.input$centroids %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           x        y cell
#&amp;gt; 1 10145.793 5611.687 7650
#&amp;gt; 2  9975.309 5626.726 7654
#&amp;gt; 3 10129.183 5630.601 7655
#&amp;gt; 4 10112.692 5635.038 7656
#&amp;gt; 5 10151.574 5634.673 7657
#&amp;gt; 6 10099.624 5636.831 7658&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df&amp;lt;- vizgen.input$centroids %&amp;gt;%
        left_join(df)

head(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           x        y cell    EPCAM    orig.ident nCount_Vizgen nFeature_Vizgen
#&amp;gt; 1 10145.793 5611.687 7650 4.091399 SeuratProject           680             173
#&amp;gt; 2  9975.309 5626.726 7654 4.087071 SeuratProject           683             166
#&amp;gt; 3 10129.183 5630.601 7655 4.087276 SeuratProject          1195             225
#&amp;gt; 4 10112.692 5635.038 7656 4.255680 SeuratProject          1151             216
#&amp;gt; 5 10151.574 5634.673 7657 0.000000 SeuratProject             0               0
#&amp;gt; 6 10099.624 5636.831 7658 4.336921 SeuratProject          1325             218
#&amp;gt;   Vizgen_snn_res.0.3 seurat_clusters
#&amp;gt; 1                  4               4
#&amp;gt; 2                  0               0
#&amp;gt; 3                  0               0
#&amp;gt; 4                  0               0
#&amp;gt; 5                  9               9
#&amp;gt; 6                  0               0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we have a dataframe with the spatial coordinates and the gene expression value.&lt;/p&gt;
&lt;p&gt;Ready to plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1&amp;lt;- ggplot(df, aes(x= y, y=x)) +
        geom_point(aes(color = EPCAM), size = 0.1) +
        scale_color_gradient(low=&amp;quot;grey&amp;quot;, high=&amp;quot;red&amp;quot;) +
        coord_fixed()+
        theme_classic(base_size = 14)
        

p2&amp;lt;- ImageFeaturePlot(vizgen.obj, features =&amp;quot;EPCAM&amp;quot;)

p1 + p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-30-how-to-construct-a-spatial-object-in-seurat_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks pretty similar!&lt;/p&gt;
&lt;p&gt;Since it is spatial data, we want to explore the cell-cell contact information.
In a future post, I will show you how to find the closest cells within a fixed radius of a cell.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;take-home-messages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Take home messages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Spatial data is similar to regular single-cell data for the count matrix, but with each cell, we have
additional x,y coordinates for the spatial information.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It is not hard to implement spatial visualization functions if you know the basics of &lt;code&gt;R&lt;/code&gt; and &lt;code&gt;tidyverse&lt;/code&gt;. &lt;code&gt;Seurat&lt;/code&gt;
nicely integrated the spatial information to the Seurat object, so we can plot conveniently.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bioconductor has a &lt;a href=&#34;https://bioconductor.org/packages/release/bioc/html/SpatialExperiment.html&#34;&gt;spatial experiment object&lt;/a&gt; which is extended from the &lt;a href=&#34;https://bioconductor.org/packages/release/bioc/html/SingleCellExperiment.html&#34;&gt;SingleCellExperiment&lt;/a&gt; object.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you use python, check &lt;a href=&#34;https://squidpy.readthedocs.io/en/stable/&#34;&gt;&lt;code&gt;squidpy&lt;/code&gt;&lt;/a&gt; and the &lt;a href=&#34;https://monkeybread.readthedocs.io/en/latest/notebooks/tutorial.html&#34;&gt;&lt;code&gt;monkeybread&lt;/code&gt;&lt;/a&gt; package developed in our compbio group at &lt;a href=&#34;https://www.immunitastx.com/&#34;&gt;Immunitas&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Deep learning to predict cancer from healthy controls using TCRseq data</title>
      <link>/post/deep-learning-to-predict-cancer-from-healthy-controls-using-tcrseq-data/</link>
      <pubDate>Fri, 24 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/deep-learning-to-predict-cancer-from-healthy-controls-using-tcrseq-data/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;sign-up-for-my-newsletter-to-not-miss-a-post-like-this&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sign up for my newsletter to not miss a post like this&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/newsletter&#34; class=&#34;uri&#34;&gt;https://divingintogeneticsandgenomics.ck.page/newsletter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The T-cell receptor (TCR) is a special molecule found on the surface of a type of immune cell called a T-cell. Think of T-cells like soldiers in your body‚Äôs defense system that help identify and attack foreign invaders like viruses and bacteria.&lt;/p&gt;
&lt;p&gt;The TCR is like a sensor or antenna that allows T-cells to recognize specific targets, kind of like how a key fits into a lock. When the TCR encounters a target it recognizes, it sends signals to the T-cell telling it to attack and destroy the invader.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.takarabio.com/about/bioview-blog/research-news/tcr-seq-methods-strengths-weaknesses-and-rankings&#34;&gt;T-cell receptor (TCR) sequencing&lt;/a&gt; data is one type of high-throughput sequencing data that provides valuable insights into the immune system‚Äôs response to cancer. We can now even get single-cell TCRseq data. In this blog post, we will discuss a deep learning model developed to predict cancer from healthy control using TCRseq data.&lt;/p&gt;
&lt;p&gt;This blog post is inspired by the publication &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/32817363/&#34;&gt;De novo prediction of cancer-associated T cell receptors for noninvasive cancer detection&lt;/a&gt;. We will use the same training and testing data from &lt;a href=&#34;https://github.com/s175573/DeepCAT&#34; class=&#34;uri&#34;&gt;https://github.com/s175573/DeepCAT&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Download the data.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;git clone https://github.com/s175573/DeepCAT&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Load in to R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(keras)
library(readr)
set.seed(123)
normal_CDR3&amp;lt;- read_tsv(&amp;quot;/Users/tommytang/github_repos/DeepCAT/TrainingData/NormalCDR3.txt&amp;quot;,
                       col_names = FALSE)

cancer_CDR3&amp;lt;- read_tsv(&amp;quot;/Users/tommytang/github_repos/DeepCAT/TrainingData/TumorCDR3.txt&amp;quot;,
                       col_names = FALSE)

train_CDR3&amp;lt;- rbind(normal_CDR3, cancer_CDR3)
train_label&amp;lt;- c(rep(0, nrow(normal_CDR3)), rep(1, nrow(cancer_CDR3))) %&amp;gt;% as.numeric()

normal_CDR3_test&amp;lt;- read_tsv(&amp;quot;/Users/tommytang/github_repos/DeepCAT/TrainingData/NormalCDR3_test.txt&amp;quot;,
                       col_names = FALSE)

cancer_CDR3_test&amp;lt;- read_tsv(&amp;quot;/Users/tommytang/github_repos/DeepCAT/TrainingData/TumorCDR3_test.txt&amp;quot;,
                       col_names = FALSE)

test_CDR3&amp;lt;- rbind(normal_CDR3_test, cancer_CDR3_test)
test_label&amp;lt;- c(rep(0, nrow(normal_CDR3_test)), rep(1, nrow(cancer_CDR3_test)))

AAindex&amp;lt;- read.table(&amp;quot;/Users/tommytang/github_repos/DeepCAT/AAidx_PCA.txt&amp;quot;,header = TRUE)

## 20 aa
total_aa&amp;lt;- rownames(AAindex)
total_aa&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1] &amp;quot;A&amp;quot; &amp;quot;R&amp;quot; &amp;quot;N&amp;quot; &amp;quot;D&amp;quot; &amp;quot;C&amp;quot; &amp;quot;E&amp;quot; &amp;quot;Q&amp;quot; &amp;quot;G&amp;quot; &amp;quot;H&amp;quot; &amp;quot;I&amp;quot; &amp;quot;L&amp;quot; &amp;quot;K&amp;quot; &amp;quot;M&amp;quot; &amp;quot;F&amp;quot; &amp;quot;P&amp;quot; &amp;quot;S&amp;quot; &amp;quot;T&amp;quot; &amp;quot;W&amp;quot; &amp;quot;Y&amp;quot;
#&amp;gt; [20] &amp;quot;V&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://www.genome.jp/aaindex/&#34;&gt;AAindex&lt;/a&gt; is a database of numerical indices representing various physicochemical and biochemical properties of amino acids and pairs of amino acids. In this example, we are not using it. The original paper uses the PCA components as input on top of the CDR3 amino sequences.&lt;/p&gt;
&lt;p&gt;Because CDR3s with different lengths usually form distinct loop structures to interact with the antigens, the &lt;code&gt;deepcat&lt;/code&gt; paper built five models each for lengths 12 through 16.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;one-hot-encoding-for-cdr3&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;one hot encoding for CDR3&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;encode_one_cdr3&amp;lt;- function(cdr3, length_cutoff){
        res&amp;lt;- matrix(0, nrow = length(total_aa), ncol = length_cutoff)
        cdr3&amp;lt;- unlist(stringr::str_split(cdr3, pattern = &amp;quot;&amp;quot;))
        cdr3&amp;lt;- cdr3[1:length_cutoff]
        row_index&amp;lt;- sapply(cdr3, function(x) which(total_aa==x)[1])
        col_index&amp;lt;- 1: length_cutoff
        res[as.matrix(cbind(row_index, col_index))]&amp;lt;- 1
        return(res)

}
                        
cdr3&amp;lt;- &amp;quot;CASSLKPNTEAFF&amp;quot;

encode_one_cdr3(cdr3, length_cutoff = 12)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
#&amp;gt;  [1,]    0    1    0    0    0    0    0    0    0     0     1     0
#&amp;gt;  [2,]    0    0    0    0    0    0    0    0    0     0     0     0
#&amp;gt;  [3,]    0    0    0    0    0    0    0    1    0     0     0     0
#&amp;gt;  [4,]    0    0    0    0    0    0    0    0    0     0     0     0
#&amp;gt;  [5,]    1    0    0    0    0    0    0    0    0     0     0     0
#&amp;gt;  [6,]    0    0    0    0    0    0    0    0    0     1     0     0
#&amp;gt;  [7,]    0    0    0    0    0    0    0    0    0     0     0     0
#&amp;gt;  [8,]    0    0    0    0    0    0    0    0    0     0     0     0
#&amp;gt;  [9,]    0    0    0    0    0    0    0    0    0     0     0     0
#&amp;gt; [10,]    0    0    0    0    0    0    0    0    0     0     0     0
#&amp;gt; [11,]    0    0    0    0    1    0    0    0    0     0     0     0
#&amp;gt; [12,]    0    0    0    0    0    1    0    0    0     0     0     0
#&amp;gt; [13,]    0    0    0    0    0    0    0    0    0     0     0     0
#&amp;gt; [14,]    0    0    0    0    0    0    0    0    0     0     0     1
#&amp;gt; [15,]    0    0    0    0    0    0    1    0    0     0     0     0
#&amp;gt; [16,]    0    0    1    1    0    0    0    0    0     0     0     0
#&amp;gt; [17,]    0    0    0    0    0    0    0    0    1     0     0     0
#&amp;gt; [18,]    0    0    0    0    0    0    0    0    0     0     0     0
#&amp;gt; [19,]    0    0    0    0    0    0    0    0    0     0     0     0
#&amp;gt; [20,]    0    0    0    0    0    0    0    0    0     0     0     0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This gives you a 20 x 12 matrix, the entry is 1 when the aa is matching the &lt;code&gt;total_aa&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;e.g., the first aa is &lt;code&gt;C&lt;/code&gt;, so the [5, 1] is 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;shape-the-training-and-testing-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;shape the training and testing data&lt;/h3&gt;
&lt;p&gt;Read my &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/basic-tensor-array-manipulations-in-r/&#34;&gt;previous post on tensor reshaping&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length_cutoff = 12

train_data&amp;lt;- purrr::map(train_CDR3$X1, ~encode_one_cdr3(.x, length_cutoff = length_cutoff))

# reshape the data to a 2D tensor
train_data&amp;lt;- array_reshape(unlist(train_data), dim = c(length(train_data), 20 * length_cutoff))

# the 20x12 matrix is linearized to a 240 element vector
dim(train_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 70000   240&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test_data&amp;lt;- purrr::map(test_CDR3$X1,  ~encode_one_cdr3(.x, length_cutoff = length_cutoff))
test_data&amp;lt;- array_reshape(unlist(test_data), dim= c(length(test_data), 20* length_cutoff))
dim(test_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 29851   240&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The original paper used a Convolutional Neural Network (CNN), I will use a regular 2 dense-layer model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y_train &amp;lt;- as.numeric(train_label)
y_test &amp;lt;- as.numeric(test_label)


model &amp;lt;- keras_model_sequential() %&amp;gt;% 
        layer_dense(units = 16, activation = &amp;quot;relu&amp;quot;, input_shape = c(20 * length_cutoff)) %&amp;gt;%
        layer_dense(units = 16, activation = &amp;quot;relu&amp;quot;) %&amp;gt;%
        layer_dense(units = 1, activation = &amp;quot;sigmoid&amp;quot;)


model %&amp;gt;% compile(
        optimizer = &amp;quot;rmsprop&amp;quot;,
        loss = &amp;quot;binary_crossentropy&amp;quot;,
        metrics = c(&amp;quot;accuracy&amp;quot;)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If one use big epochs, the model will be over-fitted. Set apart 35000 CDR3 sequences for validation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
val_indices &amp;lt;- sample(nrow(train_data), 35000)
x_val &amp;lt;- train_data[val_indices,]
partial_x_train &amp;lt;- train_data[-val_indices,]

y_val &amp;lt;- y_train[val_indices]
partial_y_train &amp;lt;- y_train[-val_indices]

history &amp;lt;- model %&amp;gt;% fit(partial_x_train, 
                         partial_y_train, 
                         epochs = 20, 
                         batch_size = 512, 
                         validation_data = list(x_val, y_val)
)

plot(history)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-24-deep-learning-to-predict-cancer-from-healthy-controls-using-tcrseq-data_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;final-training-and-testing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;final training and testing&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model %&amp;gt;% fit(train_data, y_train, epochs = 20, batch_size = 512)
results &amp;lt;- model %&amp;gt;% evaluate(test_data, y_test)
results&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      loss  accuracy 
#&amp;gt; 0.4229931 0.8065391&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;~80% accuracy. Not bad‚Ä¶&lt;/p&gt;
&lt;p&gt;Let‚Äôs increase the number of units in each layer.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- keras_model_sequential() %&amp;gt;% 
        layer_dense(units = 64, activation = &amp;quot;relu&amp;quot;, input_shape = c(20 * length_cutoff)) %&amp;gt;%
        layer_dense(units = 64, activation = &amp;quot;relu&amp;quot;) %&amp;gt;%
        layer_dense(units = 1, activation = &amp;quot;sigmoid&amp;quot;)


model %&amp;gt;% compile(
        optimizer = &amp;quot;rmsprop&amp;quot;,
        loss = &amp;quot;binary_crossentropy&amp;quot;,
        metrics = c(&amp;quot;accuracy&amp;quot;)
)

val_indices &amp;lt;- sample(nrow(train_data), 35000)
x_val &amp;lt;- train_data[val_indices,]
partial_x_train &amp;lt;- train_data[-val_indices,]

y_val &amp;lt;- y_train[val_indices]
partial_y_train &amp;lt;- y_train[-val_indices]

history &amp;lt;- model %&amp;gt;% fit(partial_x_train, 
                         partial_y_train, 
                         epochs = 20, 
                         batch_size = 512, 
                         validation_data = list(x_val, y_val)
)

plot(history)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-24-deep-learning-to-predict-cancer-from-healthy-controls-using-tcrseq-data_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;with more units (neurons) in each layer, overfitting occurs much faster.
after 10 epoch, the validation accuracy starts to plateau.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model %&amp;gt;% fit(train_data, y_train, epochs = 10, batch_size = 512)
results &amp;lt;- model %&amp;gt;% evaluate(test_data, y_test)
results&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      loss  accuracy 
#&amp;gt; 0.3731814 0.8282135&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict(model, test_data[1:10, ])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;             [,1]
#&amp;gt;  [1,] 0.08662453
#&amp;gt;  [2,] 0.23022524
#&amp;gt;  [3,] 0.21670932
#&amp;gt;  [4,] 0.03327328
#&amp;gt;  [5,] 0.03596783
#&amp;gt;  [6,] 0.07136077
#&amp;gt;  [7,] 0.06769678
#&amp;gt;  [8,] 0.03962836
#&amp;gt;  [9,] 0.16300359
#&amp;gt; [10,] 0.36324140&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-improve-the-accuracy-by-using-biology-domian-knowledge&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;How to improve the accuracy by using biology domian knowledge?&lt;/h3&gt;
&lt;p&gt;It is surprising to me that using only the CDR3 aa sequences can reach an accuracy of 80%.
How can we further improve it?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we can add the AA properties&lt;/li&gt;
&lt;li&gt;add the VDJ usage&lt;/li&gt;
&lt;li&gt;add HLA typing for each sample&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;further-reading&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41467-021-21879-w&#34;&gt;DeepTCR is a deep learning framework for revealing sequence concepts within T-cell repertoires&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.science.org/doi/10.1126/sciadv.abq5089&#34;&gt;Deep learning reveals predictive sequence concepts within immune repertoires to immunotherapy&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Basic tensor/array manipulations in R</title>
      <link>/post/basic-tensor-array-manipulations-in-r/</link>
      <pubDate>Sat, 18 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/basic-tensor-array-manipulations-in-r/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;sign-up-for-my-newsletter-to-not-miss-a-post-like-this&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sign up for my newsletter to not miss a post like this&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/newsletter&#34; class=&#34;uri&#34;&gt;https://divingintogeneticsandgenomics.ck.page/newsletter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In my &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/deep-learning-with-keras-using-mnst-dataset/&#34;&gt;last post&lt;/a&gt;, I showed you how to build a neural network in &lt;code&gt;Keras&lt;/code&gt; with less than 20 lines of code.
One of the key road blocks for beginners is to transform the input to the right shape of tensor (the deep learning terminology) or
array (the R built-in type).&lt;/p&gt;
&lt;p&gt;In this post, I am going to show you some basic manipulations of the array.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(keras)
set.seed(123)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;construct-tensors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Construct tensors&lt;/h3&gt;
&lt;p&gt;A 2D tensor is just a matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x&amp;lt;- sample(c(0,1), size= 24, replace = TRUE)
x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1] 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y&amp;lt;- matrix(x, nrow = 4)
y&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4] [,5] [,6]
#&amp;gt; [1,]    0    0    0    1    1    0
#&amp;gt; [2,]    0    1    0    0    0    1
#&amp;gt; [3,]    0    1    1    1    0    0
#&amp;gt; [4,]    1    1    1    0    0    0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The matrix is filled in a column-wise manner.&lt;/p&gt;
&lt;p&gt;A 3D tensor is a 3D array.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y&amp;lt;- array(x, dim = c(2,3,4))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1] 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y[,,1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    0    0    0
#&amp;gt; [2,]    0    1    1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y[,,2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    1    0    1
#&amp;gt; [2,]    1    0    1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y[,,3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    1    1    1
#&amp;gt; [2,]    0    0    0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;pay attention on how the arrays are filled for each dimension.
If you use &lt;code&gt;array&lt;/code&gt; to construct the tensor, it fills the elements starting from the
last dimension in the column wise manner.&lt;/p&gt;
&lt;p&gt;The first dimension is usually the sample. We can think it this 3D tensor represents
two samples, and each sample has a 2D matrix to represent the time and the feature in
timeseries data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y[1,,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4]
#&amp;gt; [1,]    0    1    1    0
#&amp;gt; [2,]    0    0    1    0
#&amp;gt; [3,]    0    1    1    0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y[2,,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4]
#&amp;gt; [1,]    0    1    0    0
#&amp;gt; [2,]    1    0    0    1
#&amp;gt; [3,]    1    1    0    0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;reshape-the-array&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;reshape the array&lt;/h3&gt;
&lt;p&gt;If we use the &lt;code&gt;keras::array_reshape&lt;/code&gt; function.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;by default, array_reshape() will fill the new dimensions in row-major (C-style) ordering, while dim&amp;lt;-() will fill new dimensions in column-major (Fortran-style) ordering. This is done to be consistent with libraries like NumPy, Keras, and TensorFlow, which default to this sort of ordering when reshaping arrays.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the default is the C-stype: order = &amp;quot;C&amp;quot;
z&amp;lt;- array_reshape(x, dim = c(2,3,4))   

x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1] 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;z[1,,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4]
#&amp;gt; [1,]    0    0    0    1
#&amp;gt; [2,]    0    1    1    1
#&amp;gt; [3,]    0    0    1    1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;z[2,,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4]
#&amp;gt; [1,]    1    0    1    0
#&amp;gt; [2,]    1    0    0    0
#&amp;gt; [3,]    0    1    0    0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, it fills in the array starting from the first dimension and in a row-wise manner.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n&amp;lt;- array_reshape(x, dim = c(2,3,4), order = &amp;quot;F&amp;quot;) 

x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1] 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n[,,1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    0    0    0
#&amp;gt; [2,]    0    1    1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n[,,2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    1    0    1
#&amp;gt; [2,]    1    0    1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, it fills in the array staring from the last dimension and in a column-wise manner.
It is the same as the &lt;code&gt;dim()&lt;/code&gt; method output:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(y, n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;permutate-index&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;permutate index&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat &amp;lt;- replicate(3, matrix(runif(24),ncol=4), simplify=FALSE )

mat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [[1]]
#&amp;gt;           [,1]       [,2]      [,3]      [,4]
#&amp;gt; [1,] 0.6557058 0.96302423 0.7584595 0.4137243
#&amp;gt; [2,] 0.7085305 0.90229905 0.2164079 0.3688455
#&amp;gt; [3,] 0.5440660 0.69070528 0.3181810 0.1524447
#&amp;gt; [4,] 0.5941420 0.79546742 0.2316258 0.1388061
#&amp;gt; [5,] 0.2891597 0.02461368 0.1428000 0.2330341
#&amp;gt; [6,] 0.1471136 0.47779597 0.4145463 0.4659625
#&amp;gt; 
#&amp;gt; [[2]]
#&amp;gt;            [,1]      [,2]       [,3]      [,4]
#&amp;gt; [1,] 0.26597264 0.5609480 0.66511519 0.8100644
#&amp;gt; [2,] 0.85782772 0.2065314 0.09484066 0.8123895
#&amp;gt; [3,] 0.04583117 0.1275317 0.38396964 0.7943423
#&amp;gt; [4,] 0.44220007 0.7533079 0.27438364 0.4398317
#&amp;gt; [5,] 0.79892485 0.8950454 0.81464004 0.7544752
#&amp;gt; [6,] 0.12189926 0.3744628 0.44851634 0.6292211
#&amp;gt; 
#&amp;gt; [[3]]
#&amp;gt;              [,1]      [,2]      [,3]      [,4]
#&amp;gt; [1,] 0.7101824014 0.3517979 0.1028646 0.1306957
#&amp;gt; [2,] 0.0006247733 0.1111354 0.4348927 0.6531019
#&amp;gt; [3,] 0.4753165741 0.2436195 0.9849570 0.3435165
#&amp;gt; [4,] 0.2201188852 0.6680556 0.8930511 0.6567581
#&amp;gt; [5,] 0.3798165377 0.4176468 0.8864691 0.3203732
#&amp;gt; [6,] 0.6127710033 0.7881958 0.1750527 0.1876911&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is a list of 3 matrices, each matrix is for one sample.&lt;/p&gt;
&lt;p&gt;Turn it to an array:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;array1&amp;lt;- simplify2array(mat)
dim(array1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 6 4 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the last dimension is the sample.
array1[,,1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           [,1]       [,2]      [,3]      [,4]
#&amp;gt; [1,] 0.6557058 0.96302423 0.7584595 0.4137243
#&amp;gt; [2,] 0.7085305 0.90229905 0.2164079 0.3688455
#&amp;gt; [3,] 0.5440660 0.69070528 0.3181810 0.1524447
#&amp;gt; [4,] 0.5941420 0.79546742 0.2316258 0.1388061
#&amp;gt; [5,] 0.2891597 0.02461368 0.1428000 0.2330341
#&amp;gt; [6,] 0.1471136 0.47779597 0.4145463 0.4659625&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How can I permutate it to have the first dimension to be 3?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;array2&amp;lt;- aperm(array1,  c(3,1,2))
dim(array2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 3 6 4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;array2[1,,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           [,1]       [,2]      [,3]      [,4]
#&amp;gt; [1,] 0.6557058 0.96302423 0.7584595 0.4137243
#&amp;gt; [2,] 0.7085305 0.90229905 0.2164079 0.3688455
#&amp;gt; [3,] 0.5440660 0.69070528 0.3181810 0.1524447
#&amp;gt; [4,] 0.5941420 0.79546742 0.2316258 0.1388061
#&amp;gt; [5,] 0.2891597 0.02461368 0.1428000 0.2330341
#&amp;gt; [6,] 0.1471136 0.47779597 0.4145463 0.4659625&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(mat[[1]], array2[1,,])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use &lt;code&gt;unlist&lt;/code&gt; to vectorize the list of matrices. &lt;code&gt;unlist&lt;/code&gt; collects all the elements
in a column-wise manner.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;unlist(mat) %&amp;gt;% head(n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1] 0.6557058 0.7085305 0.5440660 0.5941420 0.2891597 0.1471136 0.9630242
#&amp;gt;  [8] 0.9022990 0.6907053 0.7954674&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           [,1]       [,2]      [,3]      [,4]
#&amp;gt; [1,] 0.6557058 0.96302423 0.7584595 0.4137243
#&amp;gt; [2,] 0.7085305 0.90229905 0.2164079 0.3688455
#&amp;gt; [3,] 0.5440660 0.69070528 0.3181810 0.1524447
#&amp;gt; [4,] 0.5941420 0.79546742 0.2316258 0.1388061
#&amp;gt; [5,] 0.2891597 0.02461368 0.1428000 0.2330341
#&amp;gt; [6,] 0.1471136 0.47779597 0.4145463 0.4659625&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;array3&amp;lt;- unlist(mat) %&amp;gt;% array(dim= c(6,4,3))
all.equal(array1, array3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;array4&amp;lt;- unlist(mat) %&amp;gt;% array_reshape(dim=c(3,6,4))

array4[1,,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           [,1]      [,2]       [,3]      [,4]
#&amp;gt; [1,] 0.6557058 0.7085305 0.54406602 0.5941420
#&amp;gt; [2,] 0.2891597 0.1471136 0.96302423 0.9022990
#&amp;gt; [3,] 0.6907053 0.7954674 0.02461368 0.4777960
#&amp;gt; [4,] 0.7584595 0.2164079 0.31818101 0.2316258
#&amp;gt; [5,] 0.1428000 0.4145463 0.41372433 0.3688455
#&amp;gt; [6,] 0.1524447 0.1388061 0.23303410 0.4659625&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           [,1]       [,2]      [,3]      [,4]
#&amp;gt; [1,] 0.6557058 0.96302423 0.7584595 0.4137243
#&amp;gt; [2,] 0.7085305 0.90229905 0.2164079 0.3688455
#&amp;gt; [3,] 0.5440660 0.69070528 0.3181810 0.1524447
#&amp;gt; [4,] 0.5941420 0.79546742 0.2316258 0.1388061
#&amp;gt; [5,] 0.2891597 0.02461368 0.1428000 0.2330341
#&amp;gt; [6,] 0.1471136 0.47779597 0.4145463 0.4659625&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;array_reshap&lt;/code&gt; put the sample in the first dimension, but it fills in the matrix in a row-wise manner.&lt;/p&gt;
&lt;p&gt;We can get all the element in a row-wise manner:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# column-wise
mat[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           [,1]       [,2]      [,3]      [,4]
#&amp;gt; [1,] 0.6557058 0.96302423 0.7584595 0.4137243
#&amp;gt; [2,] 0.7085305 0.90229905 0.2164079 0.3688455
#&amp;gt; [3,] 0.5440660 0.69070528 0.3181810 0.1524447
#&amp;gt; [4,] 0.5941420 0.79546742 0.2316258 0.1388061
#&amp;gt; [5,] 0.2891597 0.02461368 0.1428000 0.2330341
#&amp;gt; [6,] 0.1471136 0.47779597 0.4145463 0.4659625&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat[[1]] %&amp;gt;% c()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1] 0.65570580 0.70853047 0.54406602 0.59414202 0.28915974 0.14711365
#&amp;gt;  [7] 0.96302423 0.90229905 0.69070528 0.79546742 0.02461368 0.47779597
#&amp;gt; [13] 0.75845954 0.21640794 0.31818101 0.23162579 0.14280002 0.41454634
#&amp;gt; [19] 0.41372433 0.36884545 0.15244475 0.13880606 0.23303410 0.46596245&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# row-wise, we first transpose it 
mat[[1]] %&amp;gt;% t() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           [,1]      [,2]      [,3]      [,4]       [,5]      [,6]
#&amp;gt; [1,] 0.6557058 0.7085305 0.5440660 0.5941420 0.28915974 0.1471136
#&amp;gt; [2,] 0.9630242 0.9022990 0.6907053 0.7954674 0.02461368 0.4777960
#&amp;gt; [3,] 0.7584595 0.2164079 0.3181810 0.2316258 0.14280002 0.4145463
#&amp;gt; [4,] 0.4137243 0.3688455 0.1524447 0.1388061 0.23303410 0.4659625&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat[[1]] %&amp;gt;% t() %&amp;gt;% c()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1] 0.65570580 0.96302423 0.75845954 0.41372433 0.70853047 0.90229905
#&amp;gt;  [7] 0.21640794 0.36884545 0.54406602 0.69070528 0.31818101 0.15244475
#&amp;gt; [13] 0.59414202 0.79546742 0.23162579 0.13880606 0.28915974 0.02461368
#&amp;gt; [19] 0.14280002 0.23303410 0.14711365 0.47779597 0.41454634 0.46596245&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat1&amp;lt;- lapply(mat, function(x) x %&amp;gt;%t() %&amp;gt;% c()) %&amp;gt;% unlist()

array5&amp;lt;- array_reshape(mat1, dim=c(3,6,4))
array5[1,,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           [,1]       [,2]      [,3]      [,4]
#&amp;gt; [1,] 0.6557058 0.96302423 0.7584595 0.4137243
#&amp;gt; [2,] 0.7085305 0.90229905 0.2164079 0.3688455
#&amp;gt; [3,] 0.5440660 0.69070528 0.3181810 0.1524447
#&amp;gt; [4,] 0.5941420 0.79546742 0.2316258 0.1388061
#&amp;gt; [5,] 0.2891597 0.02461368 0.1428000 0.2330341
#&amp;gt; [6,] 0.1471136 0.47779597 0.4145463 0.4659625&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           [,1]       [,2]      [,3]      [,4]
#&amp;gt; [1,] 0.6557058 0.96302423 0.7584595 0.4137243
#&amp;gt; [2,] 0.7085305 0.90229905 0.2164079 0.3688455
#&amp;gt; [3,] 0.5440660 0.69070528 0.3181810 0.1524447
#&amp;gt; [4,] 0.5941420 0.79546742 0.2316258 0.1388061
#&amp;gt; [5,] 0.2891597 0.02461368 0.1428000 0.2330341
#&amp;gt; [6,] 0.1471136 0.47779597 0.4145463 0.4659625&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(array5[1,,], mat[[1]])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(array5, array2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tensor-operations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;tensor operations&lt;/h3&gt;
&lt;p&gt;In R, everything is vectorized, so you can do element-wise multiplication, subtraction and so on.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1] 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y&amp;lt;- matrix(x, nrow = 4)
y&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4] [,5] [,6]
#&amp;gt; [1,]    0    0    0    1    1    0
#&amp;gt; [2,]    0    1    0    0    0    1
#&amp;gt; [3,]    0    1    1    1    0    0
#&amp;gt; [4,]    1    1    1    0    0    0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y + 2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4] [,5] [,6]
#&amp;gt; [1,]    2    2    2    3    3    2
#&amp;gt; [2,]    2    3    2    2    2    3
#&amp;gt; [3,]    2    3    3    3    2    2
#&amp;gt; [4,]    3    3    3    2    2    2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;z&amp;lt;- array_reshape(x, dim = c(2,3,4)) 
z&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; , , 1
#&amp;gt; 
#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    0    0    0
#&amp;gt; [2,]    1    1    0
#&amp;gt; 
#&amp;gt; , , 2
#&amp;gt; 
#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    0    1    0
#&amp;gt; [2,]    0    0    1
#&amp;gt; 
#&amp;gt; , , 3
#&amp;gt; 
#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    0    1    1
#&amp;gt; [2,]    1    0    0
#&amp;gt; 
#&amp;gt; , , 4
#&amp;gt; 
#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    1    1    1
#&amp;gt; [2,]    0    0    0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;z + 2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; , , 1
#&amp;gt; 
#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    2    2    2
#&amp;gt; [2,]    3    3    2
#&amp;gt; 
#&amp;gt; , , 2
#&amp;gt; 
#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    2    3    2
#&amp;gt; [2,]    2    2    3
#&amp;gt; 
#&amp;gt; , , 3
#&amp;gt; 
#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    2    3    3
#&amp;gt; [2,]    3    2    2
#&amp;gt; 
#&amp;gt; , , 4
#&amp;gt; 
#&amp;gt;      [,1] [,2] [,3]
#&amp;gt; [1,]    3    3    3
#&amp;gt; [2,]    2    2    2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;array6&amp;lt;- replicate(3, matrix(rnorm(24),ncol=4), simplify=FALSE) %&amp;gt;%
        simplify2array()
        
dim(array6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 6 4 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;array6&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; , , 1
#&amp;gt; 
#&amp;gt;             [,1]       [,2]       [,3]        [,4]
#&amp;gt; [1,]  0.77996512 -0.2257710  0.3796395  0.44820978
#&amp;gt; [2,] -0.08336907  1.5164706 -0.5023235  0.05300423
#&amp;gt; [3,]  0.25331851 -1.5487528 -0.3332074  0.92226747
#&amp;gt; [4,] -0.02854676  0.5846137 -1.0185754  2.05008469
#&amp;gt; [5,] -0.04287046  0.1238542 -1.0717912 -0.49103117
#&amp;gt; [6,]  1.36860228  0.2159416  0.3035286 -2.30916888
#&amp;gt; 
#&amp;gt; , , 2
#&amp;gt; 
#&amp;gt;            [,1]         [,2]       [,3]       [,4]
#&amp;gt; [1,]  1.0057385  0.181303480 -0.2204866  0.9935039
#&amp;gt; [2,] -0.7092008 -0.138891362  0.3317820  0.5483970
#&amp;gt; [3,] -0.6880086  0.005764186  1.0968390  0.2387317
#&amp;gt; [4,]  1.0255714  0.385280401  0.4351815 -0.6279061
#&amp;gt; [5,] -0.2847730 -0.370660032 -0.3259316  1.3606524
#&amp;gt; [6,] -1.2207177  0.644376549  1.1488076 -0.6002596
#&amp;gt; 
#&amp;gt; , , 3
#&amp;gt; 
#&amp;gt;            [,1]        [,2]        [,3]       [,4]
#&amp;gt; [1,]  2.1873330 -0.24669188 -0.38022652  0.5194072
#&amp;gt; [2,]  1.5326106 -0.34754260  0.91899661  0.3011534
#&amp;gt; [3,] -0.2357004 -0.95161857 -0.57534696  0.1056762
#&amp;gt; [4,] -1.0264209 -0.04502772  0.60796432 -0.6407060
#&amp;gt; [5,] -0.7104066 -0.78490447 -1.61788271 -0.8497043
#&amp;gt; [6,]  0.2568837 -1.66794194 -0.05556197 -1.0241288&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## turn all negative to 0, the element-wise relu
pmax(array6, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; , , 1
#&amp;gt; 
#&amp;gt;           [,1]      [,2]      [,3]       [,4]
#&amp;gt; [1,] 0.7799651 0.0000000 0.3796395 0.44820978
#&amp;gt; [2,] 0.0000000 1.5164706 0.0000000 0.05300423
#&amp;gt; [3,] 0.2533185 0.0000000 0.0000000 0.92226747
#&amp;gt; [4,] 0.0000000 0.5846137 0.0000000 2.05008469
#&amp;gt; [5,] 0.0000000 0.1238542 0.0000000 0.00000000
#&amp;gt; [6,] 1.3686023 0.2159416 0.3035286 0.00000000
#&amp;gt; 
#&amp;gt; , , 2
#&amp;gt; 
#&amp;gt;          [,1]        [,2]      [,3]      [,4]
#&amp;gt; [1,] 1.005739 0.181303480 0.0000000 0.9935039
#&amp;gt; [2,] 0.000000 0.000000000 0.3317820 0.5483970
#&amp;gt; [3,] 0.000000 0.005764186 1.0968390 0.2387317
#&amp;gt; [4,] 1.025571 0.385280401 0.4351815 0.0000000
#&amp;gt; [5,] 0.000000 0.000000000 0.0000000 1.3606524
#&amp;gt; [6,] 0.000000 0.644376549 1.1488076 0.0000000
#&amp;gt; 
#&amp;gt; , , 3
#&amp;gt; 
#&amp;gt;           [,1] [,2]      [,3]      [,4]
#&amp;gt; [1,] 2.1873330    0 0.0000000 0.5194072
#&amp;gt; [2,] 1.5326106    0 0.9189966 0.3011534
#&amp;gt; [3,] 0.0000000    0 0.0000000 0.1056762
#&amp;gt; [4,] 0.0000000    0 0.6079643 0.0000000
#&amp;gt; [5,] 0.0000000    0 0.0000000 0.0000000
#&amp;gt; [6,] 0.2568837    0 0.0000000 0.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tensor-dot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;tensor dot&lt;/h3&gt;
&lt;p&gt;for 2D tensors, it is like matrix multiplication, the number of columns for the first matrix
has to be the same as the number of rows for the second matrix&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat2&amp;lt;- sample(c(0,1), size= 24, replace = TRUE) %&amp;gt;% matrix(ncol = 4)
mat2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4]
#&amp;gt; [1,]    0    0    1    1
#&amp;gt; [2,]    1    1    0    0
#&amp;gt; [3,]    0    1    0    1
#&amp;gt; [4,]    1    1    0    1
#&amp;gt; [5,]    0    0    0    1
#&amp;gt; [6,]    0    1    0    0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat3&amp;lt;- sample(c(0,1), size= 28, replace = TRUE) %&amp;gt;% matrix(nrow = 4)
mat3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7]
#&amp;gt; [1,]    1    0    0    0    1    0    0
#&amp;gt; [2,]    0    0    1    0    1    1    1
#&amp;gt; [3,]    1    0    0    0    0    1    0
#&amp;gt; [4,]    0    0    1    0    0    1    0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat2 %*% mat3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7]
#&amp;gt; [1,]    1    0    1    0    0    2    0
#&amp;gt; [2,]    1    0    1    0    2    1    1
#&amp;gt; [3,]    0    0    2    0    1    2    1
#&amp;gt; [4,]    1    0    2    0    2    2    1
#&amp;gt; [5,]    0    0    1    0    0    1    0
#&amp;gt; [6,]    0    0    1    0    1    1    1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;6x4 mat1 dot 4x7 mat2 == 6x7 matrix.&lt;/p&gt;
&lt;p&gt;You can take dot product of higher-dimensional tensors following the same rules for shape compatibility.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In my next blog post, I will show you how to use TCR sequences to predict cancer vs healthy samples.&lt;/strong&gt; Stay tuned!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Deep learning with Keras using MNIST dataset </title>
      <link>/post/deep-learning-with-keras-using-mnst-dataset/</link>
      <pubDate>Sat, 11 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/deep-learning-with-keras-using-mnst-dataset/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;sign-up-for-my-newsletter-to-not-miss-a-post-like-this&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sign up for my newsletter to not miss a post like this&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/newsletter&#34; class=&#34;uri&#34;&gt;https://divingintogeneticsandgenomics.ck.page/newsletter&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Are you a machine learning practitioner or data analyst looking to broaden your skill set? Look nowhere else! This blog post will offer an introduction to deep learning, which is currently the hottest topic in machine learning. Using the well-known &lt;a href=&#34;https://en.wikipedia.org/wiki/MNIST_database&#34;&gt;MNIST dataset&lt;/a&gt;) and the Keras package, we will investigate the potential of deep learning.&lt;/p&gt;
&lt;p&gt;A high-level deep learning package called Keras, which is based on TensorFlow, enables quick and simple experimentation with deep neural networks. Anyone can run a deep learning model in a matter of hours with Keras. No prior knowledge is necessary as I walk you through the fundamentals of Keras, from installation to creating a deep learning model from scratch!&lt;/p&gt;
&lt;p&gt;I recommend watching the youtube series from 3blue1brown: &lt;a href=&#34;https://www.3blue1brown.com/topics/neural-networks&#34; class=&#34;uri&#34;&gt;https://www.3blue1brown.com/topics/neural-networks&lt;/a&gt; to get intuitive understanding of how neural network works.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/MNIST.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Josh Starmer also has very nice videos on this topic &lt;a href=&#34;https://statquest.org/video-index/&#34; class=&#34;uri&#34;&gt;https://statquest.org/video-index/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;install-the-package&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Install the package&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install.packages(&amp;quot;keras&amp;quot;) install the keras R package
library(keras)
#install_keras(version = &amp;quot;release&amp;quot;)  install the core Keras library and TensorFlow
set.seed(123)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It installs tensorflow to &lt;code&gt;/Users/tommytang/Library/r-miniconda/envs/r-reticulate/bin/python&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To set the value of &lt;code&gt;RETICULATE_PYTHON&lt;/code&gt;, insert &lt;code&gt;Sys.setenv(RETICULATE_PYTHON = PATH)&lt;/code&gt; into your project‚Äôs &lt;code&gt;.Rprofile&lt;/code&gt;, where PATH is your preferred Python binary.&lt;/p&gt;
&lt;p&gt;I added this
&lt;code&gt;Sys.setenv(RETICULATE_PYTHON = &#34;/Users/tommytang/Library/r-miniconda/envs/r-reticulate/bin/python&#34;)&lt;/code&gt; to my &lt;code&gt;.Rprofile&lt;/code&gt; in the same folder as the &lt;code&gt;.Rproj&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Take a read &lt;a href=&#34;https://rstudio.github.io/reticulate/articles/versions.html&#34; class=&#34;uri&#34;&gt;https://rstudio.github.io/reticulate/articles/versions.html&lt;/a&gt; to further understand how to configure python path inside Rstudio.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;get-the-data-and-do-exploratory-data-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Get the data and do exploratory data analysis&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)
use_condaenv(&amp;quot;r-reticulate&amp;quot;)
mnist&amp;lt;- dataset_mnist()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;split the training and testing sets&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_images&amp;lt;- mnist$train$x
train_labels&amp;lt;- mnist$train$y
train_labels&amp;lt;- to_categorical(train_labels)

test_images&amp;lt;- mnist$test$x
test_labels&amp;lt;- mnist$test$y
test_labels&amp;lt;- to_categorical(test_labels)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The training sets is a 3D tensor. Tensors are just a fancy way to say multi-dimentional array.
A 2D tensor is just a matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(train_images)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 60000    28    28&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is an array of 60,000 matrices of 28x28 integers. Each matrix is a grayscale image:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the fifth matrix
digit&amp;lt;- train_images[5, ,]
dim(digit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 28 28&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(as.raster(digit, max = 255))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-11-deep-learning-with-keras-using-mnst-dataset_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It is a matrix denoting the image of 9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reshape-the-data-into-2d-tensor&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;reshape the data into 2D tensor&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_images&amp;lt;- array_reshape(train_images, c(60000, 28 * 28))
train_images&amp;lt;- train_images/255


test_images&amp;lt;- array_reshape(test_images, c(10000, 28 * 28))
test_images&amp;lt;- test_images/255&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(train_images)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 60000   784&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, it becomes a 6000 x 784 2D tensor.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;exploratory data analysis&lt;/h3&gt;
&lt;p&gt;Before doing any analysis, &lt;a href=&#34;https://en.wikipedia.org/wiki/Exploratory_data_analysis&#34;&gt;exploratory data analysis&lt;/a&gt; (EDA) is the first thing you should do.&lt;/p&gt;
&lt;p&gt;Let‚Äôs use &lt;a href=&#34;https://cran.r-project.org/web/packages/irlba/index.html&#34;&gt;irlba&lt;/a&gt; (Fast Truncated Singular Value Decomposition and Principal Components Analysis for Large Dense and Sparse Matrices) for PCA. &lt;code&gt;irlba&lt;/code&gt; is both faster and more memory efficient than the usual R &lt;code&gt;svd&lt;/code&gt; function for computing a few of the largest singular vectors and corresponding singular values of a matrix.&lt;/p&gt;
&lt;p&gt;Read my old post on &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/pca-in-action/&#34;&gt;PCA&lt;/a&gt; if you want to learn more.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(irlba)
library(ggplot2)
library(dplyr)

dim(train_images)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 60000   784&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pca.results &amp;lt;- irlba(A = train_images, nv = 30)

image_pc_loadings&amp;lt;- pca.results$u

colnames(image_pc_loadings)&amp;lt;- paste0(&amp;quot;PC_&amp;quot;, 1:30)


labels_vector&amp;lt;- apply(mnist$train$y, 1, max) %&amp;gt;%
        as.character()

image_pc_df&amp;lt;- image_pc_loadings %&amp;gt;%
        as.data.frame() %&amp;gt;%
        dplyr::bind_cols(label = labels_vector)


ggplot(image_pc_df, aes(x=PC_1, y = PC_2)) +
        scattermore::geom_scattermore(aes(color = label)) +
        theme_classic(base_size = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-11-deep-learning-with-keras-using-mnst-dataset_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can see some structure of the data by using PCA.&lt;/p&gt;
&lt;p&gt;Let‚Äôs use &lt;a href=&#34;https://github.com/jlmelville/uwot&#34;&gt;&lt;code&gt;uwot&lt;/code&gt;&lt;/a&gt; for UMAP dimension reduction which may give you a better visualization of
the data structure.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://umap-learn.readthedocs.io/en/latest/&#34;&gt;UMAP&lt;/a&gt; is a form of non-linear dimension reduction technique that is useful for visualizing the data. It is very popular in single-cell
data analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(uwot)
mnist_umap &amp;lt;- umap(train_images, n_neighbors = 15, min_dist = 0.001, verbose = TRUE, pca = 50)

colnames(mnist_umap)&amp;lt;- c(&amp;quot;UMAP_1&amp;quot;, &amp;quot;UMAP_2&amp;quot;)
mnist_umap&amp;lt;- bind_cols(mnist_umap, label = labels_vector)

ggplot(mnist_umap, aes(x=UMAP_1, y = UMAP_2)) +
        scattermore::geom_scattermore(aes(color = label)) +
        theme_classic(base_size = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-11-deep-learning-with-keras-using-mnst-dataset_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wow. most of the images are separated by its digits. Note that when you have many data points, they plot on top
of each other. The best way is to calculate a metric on the cluster purity rather than judge by your eyes.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
I think most people using UMAPs don&#39;t realize that when points are colored in order (the default way of plotting), buried colors make the points appear to be (much!) better grouped together than they really are. &lt;br&gt;This figure is from the supplement of &lt;a href=&#34;https://t.co/a0Ltb5lCGN&#34;&gt;https://t.co/a0Ltb5lCGN&lt;/a&gt; &lt;a href=&#34;https://t.co/ZMVYB9bJTW&#34;&gt;pic.twitter.com/ZMVYB9bJTW&lt;/a&gt;
&lt;/p&gt;
‚Äî Lior Pachter (&lt;span class=&#34;citation&#34;&gt;@lpachter&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/lpachter/status/1634194744783040512?ref_src=twsrc%5Etfw&#34;&gt;March 10, 2023&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;See also my previous blog post &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/how-to-deal-with-overplotting-without-being-fooled/&#34;&gt;How to deal with overplotting without being fooled&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;train-the-network&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Train the network&lt;/h3&gt;
&lt;p&gt;Now, let‚Äôs construct the network using two dense layers.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;network&amp;lt;- keras_model_sequential() %&amp;gt;%
        layer_dense(unit= 512, activation = &amp;quot;relu&amp;quot;, input_shape = c(28 * 28))%&amp;gt;%
        layer_dense(units = 10, activation = &amp;quot;softmax&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last layer has 10 neurons because we are predicting the images to be &lt;code&gt;0-9&lt;/code&gt; and the activation function is softmax
to give a probability of the image predicted to 0-9. The sum of them will be 1.&lt;/p&gt;
&lt;p&gt;In the compilation step, you may configure the learning process by specifying the optimizer and loss function(s) the model should employ as well as the metrics you wish to track while it is being trained.&lt;/p&gt;
&lt;p&gt;Compile the network by telling the loss function and metrics. &lt;code&gt;categorical_crossentropy&lt;/code&gt; is good for categorical classifications.
For binary classification, you will use &lt;code&gt;binary_crossentropy&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;network %&amp;gt;%
        compile(optimizer = &amp;quot;rmsprop&amp;quot;,
                loss = &amp;quot;categorical_crossentropy&amp;quot;,
                metrics= c(&amp;quot;accuracy&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;compile() function modifies the network in place (rather than returning a new network object, as is more conventional in R.&lt;/p&gt;
&lt;p&gt;Finally, the training:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;network %&amp;gt;%
        fit(train_images, train_labels, epochs = 5, batch_size = 128)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The network will iterate on the training data in mini-batches of 128 samples, 5 times over(each iteration over all the training data is called an epoch).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluate-the-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;evaluate the model&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;metrics&amp;lt;- network %&amp;gt;% evaluate(test_images, test_labels)
metrics&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;       loss   accuracy 
#&amp;gt; 0.08828809 0.97460002&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;98% accuracy! impressive.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-does-random-forest-perform&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;How does random forest perform?&lt;/h3&gt;
&lt;p&gt;Random forest is my go-to for machine learning after linear regression, before deep learning.&lt;/p&gt;
&lt;p&gt;Let‚Äôs see how it performs using &lt;a href=&#34;https://www.tidymodels.org/&#34;&gt;tidymodels&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A book for you to read &lt;a href=&#34;https://www.tidymodels.org/books/tmwr/&#34; class=&#34;uri&#34;&gt;https://www.tidymodels.org/books/tmwr/&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidymodels)
set.seed(123)

data_train&amp;lt;- train_images
colnames(data_train)&amp;lt;- paste0(&amp;quot;feature&amp;quot;, 1:784)
data_train&amp;lt;- bind_cols(as.data.frame(data_train), label =  apply(mnist$train$y, 1, max) %&amp;gt;%
        as.character())

data_test&amp;lt;- test_images
colnames(data_test)&amp;lt;- paste0(&amp;quot;feature&amp;quot;, 1:784)
data_test&amp;lt;- bind_cols(as.data.frame(data_test), label = apply(mnist$test$y, 1, max) %&amp;gt;%
        as.character())

# it is key to turn it to a factor for classification
data_train$label&amp;lt;- factor(data_train$label)
data_test$label&amp;lt;- factor(data_test$label)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It turns out 60,000 images is a lot for random forest and it takes hours to fit the model.
what impresses me about the deep learning model apart from its accuracy is its speed.
For 60,000 images, it finished in seconds.&lt;/p&gt;
&lt;p&gt;Let me just randomly take 3000 images.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_train&amp;lt;- dplyr::sample_n(data_train, size = 3000)
dim(data_train)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 3000  785&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidymodels)
library(tictoc)

tic()
rf_recipe &amp;lt;- 
  recipe(formula = label ~ ., data = data_train)

## feature importance sore to TRUE, one can tune the trees and mtry 
rf_spec &amp;lt;- rand_forest() %&amp;gt;%
  set_engine(&amp;quot;randomForest&amp;quot;, importance = TRUE) %&amp;gt;%
  set_mode(&amp;quot;classification&amp;quot;)

rf_workflow &amp;lt;- workflow() %&amp;gt;% 
  add_recipe(rf_recipe) %&amp;gt;% 
  add_model(rf_spec)


rf_fit &amp;lt;- fit(rf_workflow, data = data_train)


res&amp;lt;- predict(rf_fit, new_data = data_test) %&amp;gt;%
        bind_cols(data_test %&amp;gt;% select(label)) 

toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 193.75 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;accuracy(res, truth = label, estimate = .pred_class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 1 √ó 3
#&amp;gt;   .metric  .estimator .estimate
#&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
#&amp;gt; 1 accuracy multiclass     0.936&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## confusion matrix,
res %&amp;gt;% conf_mat(truth = label, estimate = .pred_class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           Truth
#&amp;gt; Prediction    0    1    2    3    4    5    6    7    8    9
#&amp;gt;          0  967    0   11    4    1   10   17    2    4    6
#&amp;gt;          1    1 1121    4    3    1    8    4   15    6    7
#&amp;gt;          2    1    2  958   15    4    2    3   27    4    3
#&amp;gt;          3    0    3    6  930    0   37    1    4   23   12
#&amp;gt;          4    0    0   11    1  931    6   11    6    9   27
#&amp;gt;          5    5    2    1   21    0  793    9    0   15    8
#&amp;gt;          6    3    3   10    2    7   13  910    0    6    3
#&amp;gt;          7    1    0   19   12    0    2    0  936    5    6
#&amp;gt;          8    2    4    9   17    2   14    3    6  883    8
#&amp;gt;          9    0    0    3    5   36    7    0   32   19  929&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An accuracy of this un-tuned random forest model gives 93.6% accuracy. Not bad! However, it is very slow.&lt;/p&gt;
&lt;p&gt;Calling &lt;code&gt;P&lt;/code&gt; the number of simultaneous workers you have) the complexities should be (depending on the implementations) :
&lt;img src=&#34;/img/rf_vs_nn.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/215970/speed-of-prediction-neural-network-vs-random-forest&#34;&gt;you should expect random forests to be slower than neural networks&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;take-home-messages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Take home messages&lt;/h3&gt;
&lt;p&gt;Running a deep learning model with Keras is not hard (with less than 20 lines of code). What is harder? üëá&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Defining the right question. This is always the most challenging part. How can deep learning help with this certain problem? have you tried conventional ML methods? Do you have the right/size data? When you have millions of data points, the accuracy of deep learning models can be really high.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Getting the data into the proper format and reshaping the tensor into the right dimension is hard. In the next post, I will walk you through how to manipulate and do calculations for the arrays (tensors).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tuning the model is hard. What are some hyper-parameters to try? We have not tuned the hyperparameter in this example. In a future post. I will show you how to tune the epoch hyper-parameter to avoid over-fitting.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Making sense of the model is hard (DL is notorious for its black box). what can you learn from the model. Random forest gives you the feature importance, so you can study the features. Deep learning is like a black box. It performs well, but you do not really know what‚Äôs going on within the black box.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How can you improve it by adding additional information to the input (domain knowledge is the key)? In a future post, I will show you how to use T cell receptor (TCR) sequence to predict cancer and what information we can add to the input to improve the accuracy of prediction.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Learn Computational Biology the Right Way</title>
      <link>/talk/2023-bioinfocongress/</link>
      <pubDate>Mon, 06 Mar 2023 11:15:00 -0500</pubDate>
      
      <guid>/talk/2023-bioinfocongress/</guid>
      <description>&lt;p&gt;As the Bioinforange platform, we prepare and share Turkish and English review articles, news articles, videos, and scientific short notes on many biological science fields, especially bioinformatics. At the same time, we organize seminars, workshops, conferences, and congress events with the participation of valuable scientists. We have a website called www.bioinforange.com (Turkish content) and www.bioinfocodes.com (English content). We are also present on all social media platforms as @bioinforange and @bioinfocodes. Our platform is followed by scientists and our student friends who are studying in many scientific fields. We have 10300 followers on Instagram and 8000 followers on Twitter and LinkedIn.&lt;/p&gt;

&lt;p&gt;Our entire team consists of students; We have more than 150 members and 128 volunteer representatives from 80 universities over the world. We continue our efforts to increase the scientific sharing culture in Turkey and to contribute to the students without any profit motive, based on volunteerism. For more detailed information, you can visit &lt;a href=&#34;https://www.bioinforange.com&#34; target=&#34;_blank&#34;&gt;https://www.bioinforange.com&lt;/a&gt; or &lt;a href=&#34;https://www.youtube.com/@Bioinforange&#34; target=&#34;_blank&#34;&gt;https://www.youtube.com/@Bioinforange&lt;/a&gt;. At the same time, you can review our most recent congress (&lt;a href=&#34;https://www.bioinforange.com/bioinfocongress3/&#34; target=&#34;_blank&#34;&gt;https://www.bioinforange.com/bioinfocongress3/&lt;/a&gt;) and our published scientific journals (&lt;a href=&#34;https://www.bioinforange.com/bioinfojournal/&#34; target=&#34;_blank&#34;&gt;https://www.bioinforange.com/bioinfojournal/&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;By inviting scientists like you to our events, we would like to contribute to our student friends and science culture in the name of sharing knowledge thanks to you.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/bioinfocongress.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;/img/bioinfocongress2.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to deal with overplotting without being fooled </title>
      <link>/post/how-to-deal-with-overplotting-without-being-fooled/</link>
      <pubDate>Sun, 05 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-deal-with-overplotting-without-being-fooled/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;sign-up-for-my-newsletter-to-not-miss-a-post-like-this&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sign up for my newsletter to not miss a post like this&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/newsletter&#34; class=&#34;uri&#34;&gt;https://divingintogeneticsandgenomics.ck.page/newsletter&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-problem&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The problem&lt;/h3&gt;
&lt;p&gt;Let me be clear, when you have gazillions of data points in a scatter plot, you
want to deal with the overplotting to avoid drawing misleading conclusions.&lt;/p&gt;
&lt;p&gt;Let‚Äôs start with a single-cell example.&lt;/p&gt;
&lt;p&gt;Load the libraries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(Seurat)
library(patchwork)
library(ggplot2)
library(ComplexHeatmap)
library(SeuratData)
set.seed(1234)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;prepare the data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;pbmc3k&amp;quot;)

pbmc3k&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; An object of class Seurat 
#&amp;gt; 13714 features across 2700 samples within 1 assay 
#&amp;gt; Active assay: RNA (13714 features, 0 variable features)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## routine processing
pbmc3k&amp;lt;- pbmc3k %&amp;gt;% 
  NormalizeData(normalization.method = &amp;quot;LogNormalize&amp;quot;, scale.factor = 10000) %&amp;gt;%
  FindVariableFeatures(selection.method = &amp;quot;vst&amp;quot;, nfeatures = 2000) %&amp;gt;%
  ScaleData() %&amp;gt;%
  RunPCA(verbose = FALSE) %&amp;gt;%
  FindNeighbors(dims = 1:10, verbose = FALSE) %&amp;gt;%
  FindClusters(resolution = 0.5, verbose = FALSE) %&amp;gt;%
  RunUMAP(dims = 1:10, verbose = FALSE)

Idents(pbmc3k)&amp;lt;- pbmc3k$seurat_annotations

pbmc3k&amp;lt;- pbmc3k[, !is.na(pbmc3k$seurat_annotations)]

DimPlot(pbmc3k, reduction = &amp;quot;umap&amp;quot;, label = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-05-how-to-deal-with-overplotting-without-being-fooled_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;illusion-1-dots-are-masked.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Illusion 1: dots are masked.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FeaturePlot(pbmc3k, features = c(&amp;quot;CD4&amp;quot;, &amp;quot;CD3D&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-05-how-to-deal-with-overplotting-without-being-fooled_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ggplot2&lt;/code&gt; plots the dots with the order that they show in the dataframe. When you have
a lot of dots, they plot on top of each other. The blue dot can be masked by
the grey dot if the grey dot/cell appears after the blue dot/cell.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FeaturePlot(pbmc3k, features = c(&amp;quot;CD4&amp;quot;, &amp;quot;CD3D&amp;quot;), order = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-05-how-to-deal-with-overplotting-without-being-fooled_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can tell that it appears both CD4 and CD3D have enhanced expression after you set the &lt;code&gt;order =TRUE&lt;/code&gt;.
Essentially, this will cause the cells with some expression of those genes plotted in the last.&lt;/p&gt;
&lt;p&gt;Note, by default, &lt;code&gt;scCustomize::FeaturePlot_scCustom&lt;/code&gt; set the order by TRUE. &lt;a href=&#34;https://samuel-marsh.github.io/scCustomize/articles/Gene_Expression_Plotting.html#plot-gene-expression-in-2d-space-pcatsneumap&#34; class=&#34;uri&#34;&gt;https://samuel-marsh.github.io/scCustomize/articles/Gene_Expression_Plotting.html#plot-gene-expression-in-2d-space-pcatsneumap&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;illusion2-number-of-dots&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Illusion2: number of dots&lt;/h3&gt;
&lt;p&gt;Only when you plot the density of the points you know where are the dots are concentrated.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1&amp;lt;- FeaturePlot(pbmc3k, features = &amp;quot;CD3D&amp;quot;, order = TRUE)

p2&amp;lt;- scCustomize::Plot_Density_Custom(seurat_object = pbmc3k, features = &amp;quot;CD3D&amp;quot;,
                                      viridis_palette= &amp;quot;viridis&amp;quot;)

p1 | p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-05-how-to-deal-with-overplotting-without-being-fooled_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;How the plot on the right was made?
No worries, let me show you how to plot the density plot from scratch using &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First, some helper functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;matrix_to_expression_df&amp;lt;- function(x, obj){
        df&amp;lt;- x %&amp;gt;%
                as.matrix() %&amp;gt;% 
                as.data.frame() %&amp;gt;%
                tibble::rownames_to_column(var= &amp;quot;gene&amp;quot;) %&amp;gt;%
                tidyr::pivot_longer(cols = -1, names_to = &amp;quot;cell&amp;quot;, values_to = &amp;quot;expression&amp;quot;) %&amp;gt;%
                tidyr::pivot_wider(names_from = &amp;quot;gene&amp;quot;, values_from = expression) %&amp;gt;%
                left_join(obj@meta.data %&amp;gt;% 
                                  tibble::rownames_to_column(var = &amp;quot;cell&amp;quot;))
        return(df)
}


get_expression_data&amp;lt;- function(obj, assay = &amp;quot;RNA&amp;quot;, slot = &amp;quot;data&amp;quot;, 
                               genes = NULL, cells = NULL){
        if (is.null(genes) &amp;amp; !is.null(cells)){
                df&amp;lt;- GetAssayData(obj, assay = assay, slot = slot)[, cells, drop = FALSE] %&amp;gt;%
                        matrix_to_expression_df(obj = obj)
        } else if (!is.null(genes) &amp;amp; is.null(cells)){
                df &amp;lt;- GetAssayData(obj, assay = assay, slot = slot)[genes, , drop = FALSE] %&amp;gt;%
                        matrix_to_expression_df(obj = obj)
        } else if (is.null(genes &amp;amp; is.null(cells))){
                df &amp;lt;- GetAssayData(obj, assay = assay, slot = slot)[, , drop = FALSE] %&amp;gt;%
                        matrix_to_expression_df(obj = obj)
        } else {
                df&amp;lt;- GetAssayData(obj, assay = assay, slot = slot)[genes, cells, drop = FALSE] %&amp;gt;%
                        matrix_to_expression_df(obj = obj)
        }
        return(df)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggpointdensity)

## fetch the dataframe
df&amp;lt;- get_expression_data(pbmc3k, genes = &amp;quot;CD3D&amp;quot;)

umap_cor&amp;lt;- pbmc3k@reductions$umap@cell.embeddings  %&amp;gt;%
        as.data.frame() %&amp;gt;%
        tibble::rownames_to_column(var = &amp;quot;cell&amp;quot;)

df&amp;lt;- left_join(df, umap_cor)

head(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 6 √ó 10
#&amp;gt;   cell            CD3D orig.ident nCount_RNA nFeature_RNA seurat_annotations
#&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;           &amp;lt;dbl&amp;gt;        &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;             
#&amp;gt; 1 AAACATACAACCAC  2.86 pbmc3k           2419          779 Memory CD4 T      
#&amp;gt; 2 AAACATTGAGCTAC  0    pbmc3k           4903         1352 B                 
#&amp;gt; 3 AAACATTGATCAGC  3.49 pbmc3k           3147         1129 Memory CD4 T      
#&amp;gt; 4 AAACCGTGCTTCCG  0    pbmc3k           2639          960 CD14+ Mono        
#&amp;gt; 5 AAACCGTGTATGCG  0    pbmc3k            980          521 NK                
#&amp;gt; 6 AAACGCACTGGTAC  1.73 pbmc3k           2163          781 Memory CD4 T      
#&amp;gt; # ‚Ä¶ with 4 more variables: RNA_snn_res.0.5 &amp;lt;fct&amp;gt;, seurat_clusters &amp;lt;fct&amp;gt;,
#&amp;gt; #   UMAP_1 &amp;lt;dbl&amp;gt;, UMAP_2 &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p3&amp;lt;- ggplot(df, aes(x= UMAP_1, y= UMAP_2 )) +
        geom_point(data = df %&amp;gt;% filter(CD3D == 0), color = &amp;quot;#440154FF&amp;quot;, size = 0.6) +
        ggpointdensity::geom_pointdensity(data = df %&amp;gt;% filter(CD3D &amp;gt; 0), size = 0.6) +
        viridis::scale_color_viridis() +
        theme_classic(base_size = 14) +
        ggtitle(&amp;quot;from scratch&amp;quot;)

p2 | p3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-05-how-to-deal-with-overplotting-without-being-fooled_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;They look similar enough. Note the legend is different (density vs number of neighbors), but you get the idea.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rastering&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Rastering&lt;/h3&gt;
&lt;p&gt;Have you found that when you have gazillions of points, the resulting PDF or PNG file is so big and your computer
is so slow to view them?&lt;/p&gt;
&lt;p&gt;Rastering the image come to the rescue. Let‚Äôs use &lt;a href=&#34;https://github.com/exaexa/scattermore&#34; class=&#34;uri&#34;&gt;https://github.com/exaexa/scattermore&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(scattermore)

ggplot(df, aes(x=UMAP_1, y= UMAP_2)) +
        geom_scattermore() +
        theme_classic(base_size = 14) +
        ggtitle(&amp;quot;geom_scattermore&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-03-05-how-to-deal-with-overplotting-without-being-fooled_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can not see the difference here. But if you zoom in
the figure on your computer, you will see the rectangles of the points.&lt;/p&gt;
&lt;p&gt;For this small dataset (only 3000 cells), you can not feel the differences of plotting speed.
However, when you have millions of cells, you may want to give &lt;code&gt;scattermore&lt;/code&gt; a try!&lt;/p&gt;
&lt;p&gt;The same thing applies to heatmap too.&lt;/p&gt;
&lt;p&gt;Please read:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://jokergoo.github.io/2020/06/30/rasterization-in-complexheatmap/&#34; class=&#34;uri&#34;&gt;https://jokergoo.github.io/2020/06/30/rasterization-in-complexheatmap/&lt;/a&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gdevailly.netlify.app/post/plotting-big-matrices-in-r/&#34;&gt;Plotting heatmaps from big matrices in R&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to commit changes to a docker image</title>
      <link>/post/how-to-commit-changes-to-a-docker-image/</link>
      <pubDate>Thu, 16 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-commit-changes-to-a-docker-image/</guid>
      <description>

&lt;h3 id=&#34;sign-up-for-my-newsletter-to-not-miss-a-post-like-this&#34;&gt;Sign up for my newsletter to not miss a post like this&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://divingintogeneticsandgenomics.ck.page/newsletter&#34; target=&#34;_blank&#34;&gt;https://divingintogeneticsandgenomics.ck.page/newsletter&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;start-here&#34;&gt;Start here&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.docker.com/&#34; target=&#34;_blank&#34;&gt;Docker&lt;/a&gt; is a great tool to ensure reproducibility of your computing work. I was
using the bioconductor image on google cloud, but the image does not have the &lt;code&gt;gsutil&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;You can install once in the container, but once you exit the container, the gsutil command
will be gone. You will need to modify the docker image if you want to keep using it.&lt;/p&gt;

&lt;h3 id=&#34;step-1&#34;&gt;Step 1&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo docker images -a

REPOSITORY                         TAG            IMAGE ID       CREATED         SIZE
rocker/tidyverse                   latest         d4d41e410fb7   2 months ago    2.16GB
r-base                             latest         3de1ef2039fb   3 months ago    838MB
bioconductor/bioconductor_docker   RELEASE_3_15   75cc0e27e8ea   6 months ago    4.23GB
hello-world                        latest         feb5d9fea6a5   17 months ago   13.3kB
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;step-2&#34;&gt;Step 2&lt;/h3&gt;

&lt;p&gt;run the &lt;code&gt;bioconductor/bioconductor_docker&lt;/code&gt; docker container interactively in bash:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo docker run -it 75cc0e27e8ea bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;step-3&#34;&gt;Step 3&lt;/h3&gt;

&lt;p&gt;Modify the container by installing &lt;code&gt;gsutils&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ gsutil
bash: gsutil: command not found

$ curl -sSL https://sdk.cloud.google.com | bash

Performing post processing steps...done.

Update done!


Modify profile to update your $PATH and enable shell command completion?

Do you want to continue (Y/n)?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It will add the gsutil to your &lt;code&gt;PATH&lt;/code&gt;. Exit the container:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ exit
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;step-4&#34;&gt;Step 4&lt;/h3&gt;

&lt;p&gt;Find the container ID:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo docker ps -a | head
CONTAINER ID   IMAGE                                           COMMAND      CREATED             STATUS                          PORTS                                       NAMES
ab9c4b13c67c   bioconductor/bioconductor_docker:RELEASE_3_15   &amp;quot;/init&amp;quot;      36 seconds ago      Up 35 seconds                   0.0.0.0:8787-&amp;gt;8787/tcp, :::8787-&amp;gt;8787/tcp   keen_khayyam
d3786b7b53a5   75cc0e27e8ea                                    &amp;quot;bin/bash&amp;quot;   10 minutes ago      Exited (127) 23 seconds ago                                                 quirky_cori
d6a94d025154   bioconductor/bioconductor_docker:RELEASE_3_15   &amp;quot;/init&amp;quot;      About an hour ago   Exited (0) About a minute ago                                               kind_goldwasser
ab7e03d1d665   bioconductor/bioconductor_docker:RELEASE_3_15   &amp;quot;/init&amp;quot;      About an hour ago   Exited (0) About an hour ago                                                wonderful_bouman
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;sudo docker commit [CONTAINER_ID] [new_image_name]&lt;/code&gt; to commit the changes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo docker commit d3786b7b53a5 bioconductor_gstuils
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;step-5&#34;&gt;Step 5&lt;/h3&gt;

&lt;p&gt;Hoary! The &lt;code&gt;bioconductor_gstuils&lt;/code&gt; image is created!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo docker images
REPOSITORY                         TAG            IMAGE ID       CREATED         SIZE
bioconductor_gstuils               latest         375c7ec8354f   2 minutes ago   5.49GB
rocker/tidyverse                   latest         d4d41e410fb7   2 months ago    2.16GB
r-base                             latest         3de1ef2039fb   3 months ago    838MB
bioconductor/bioconductor_docker   RELEASE_3_15   75cc0e27e8ea   6 months ago    4.23GB
hello-world                        latest         feb5d9fea6a5   17 months ago   13.3kB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;gsutil&lt;/code&gt; command is now avaiable in the new docker container.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo docker run -it bioconductor_gstuils bin/bash

$ gsutil
Usage: gsutil [-D] [-DD] [-h header]... [-i service_account] [-m] [-o section:flag=value]... [-q] [-u user_project] [command [opts...] args...]
Available commands:
  acl              Get, set, or change bucket and/or object ACLs
  autoclass        Configure Autoclass feature
  bucketpolicyonly Configure uniform bucket-level access
  cat              Concatenate object content to stdout
  compose          Concatenate a sequence of objects into a new composite object.
  config           Obtain credentials and create configuration file
  cors             Get or set a CORS JSON document for one or more buckets
  cp               Copy files and objects
  defacl           Get, set, or change default ACL on buckets
  defstorageclass  Get or set the default storage class on buckets
  du               Display object size usage
  hash             Calculate file hashes
  help             Get help about commands and topics
  hmac             CRUD operations on service account HMAC keys.
  iam              Get, set, or change bucket and/or object IAM permissions.
  kms              Configure Cloud KMS encryption
  label            Get, set, or change the label configuration of a bucket.
  lifecycle        Get or set lifecycle configuration for a bucket
  logging          Configure or retrieve logging on buckets
  ls               List providers, buckets, or objects
  mb               Make buckets
  mv               Move/rename objects
  notification     Configure object change notification
  pap              Configure public access prevention
  perfdiag         Run performance diagnostic
  rb               Remove buckets
  requesterpays    Enable or disable requester pays for one or more buckets
  retention        Provides utilities to interact with Retention Policy feature.
  rewrite          Rewrite objects
  rm               Remove objects
  rpo              Configure replication
  rsync            Synchronize content of two buckets/directories
  setmeta          Set metadata on already uploaded objects
  signurl          Create a signed URL
  stat             Display object status
  test             Run gsutil unit/integration tests (for developers)
  ubla             Configure Uniform bucket-level access
  update           Update to the latest gsutil release
  version          Print version info about gsutil
  versioning       Enable or suspend versioning for one or more buckets
  web              Set a website configuration for a bucket

...

Use gsutil help &amp;lt;command or topic&amp;gt; for detailed help.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hmm.. but now the below command does not bring up the Rstudio.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo docker run \
    -v /home/tommytang:/home/rstudio/tommytang \
    -v /home/tommytang/R/host-site-library:/usr/local/lib/R/host-site-library \
    -e R_LIBS_USER=/home/tommytang/R/host-site-library \
  	-p 8787:8787 \
  	bioconductor_gstuils
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What&amp;rsquo;s wrong?&lt;/p&gt;

&lt;p&gt;I know I can also add &lt;code&gt;RUN curl -sSL https://sdk.cloud.google.com | bash&lt;/code&gt; to the bioconductor &lt;a href=&#34;https://github.com/Bioconductor/bioconductor_docker/blob/master/Dockerfile&#34; target=&#34;_blank&#34;&gt;docker file&lt;/a&gt; and
build a new docker image. That probably will work.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
