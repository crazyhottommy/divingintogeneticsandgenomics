<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DNA confesses Data speak on DNA confesses Data speak</title>
    <link>/</link>
    <description>Recent content in DNA confesses Data speak on DNA confesses Data speak</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Ming &#39;Tommy&#39; Tang</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Predict TCR cancer specificity using 1d convolutional and LSTM neural networks</title>
      <link>/post/predict-tcr-cancer-specificity-using-1d-convolutional-and-lstm-neural-networks/</link>
      <pubDate>Tue, 03 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/predict-tcr-cancer-specificity-using-1d-convolutional-and-lstm-neural-networks/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


</description>
    </item>
    
    <item>
      <title>Unleashing the power of computational biology</title>
      <link>/talk/2023-antiverse/</link>
      <pubDate>Sun, 01 Oct 2023 12:00:00 -0400</pubDate>
      
      <guid>/talk/2023-antiverse/</guid>
      <description>&lt;p&gt;I had the fun to be on the podcast hosted by the CEO of &lt;a href=&#34;https://www.antiverse.io/&#34; target=&#34;_blank&#34;&gt;antiverse&lt;/a&gt;: Murat Tunaboylu.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/antiverse.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to create pseudobulk from single-cell RNAseq data </title>
      <link>/post/how-to-create-pseudobulk-from-single-cell-rnaseq-data/</link>
      <pubDate>Thu, 28 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-create-pseudobulk-from-single-cell-rnaseq-data/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/vembedr/css/vembedr.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;div id=&#34;what-is-pseduobulk&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What is pseduobulk?&lt;/h3&gt;
&lt;p&gt;Many of you have heard about bulk-RNAseq data. What is pseduobulk?&lt;/p&gt;
&lt;p&gt;Single-cell RNAseq can profile the gene expression at single-cell resolution. For differential expression, psedobulk seems to perform really well(see paper &lt;a href=&#34;https://www.nature.com/articles/s41467-020-19894-4&#34;&gt;muscat detects subpopulation-specific state transitions from multi-sample multi-condition single-cell transcriptomics data&lt;/a&gt;). To create a pseudobulk, one can artificially add up the counts for cells from the same cell type of the same sample.&lt;/p&gt;
&lt;p&gt;In this blog post, I’ll guide you through the art of creating pseudobulk data from scRNA-seq experiments. By the end, you’ll have the skills to transform complex single-cell data into manageable, meaningful results, and learn skills to explore and make sense of the results.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;download-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Download the data&lt;/h3&gt;
&lt;p&gt;The data are from this paper &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0092867421000106&#34;&gt;A pan-cancer single-cell transcriptional atlas of tumor infiltrating myeloid cells&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GEO accession:
&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE154763&#34; class=&#34;uri&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE154763&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Get the data from ftp &lt;a href=&#34;https://ftp.ncbi.nlm.nih.gov/geo/series/GSE154nnn/GSE154763/suppl/&#34; class=&#34;uri&#34;&gt;https://ftp.ncbi.nlm.nih.gov/geo/series/GSE154nnn/GSE154763/suppl/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;on-command-line&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;On command line&lt;/h3&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;
wget -nH --cut-dirs=5  --no-clobber --convert-links --random-wait -r -p -E -e robots=off https://ftp.ncbi.nlm.nih.gov/geo/series/GSE154nnn/GSE154763/suppl/

ls *gz | xargs gunzip&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;use &lt;a href=&#34;https://github.com/immunitastx/recover-counts&#34; class=&#34;uri&#34;&gt;https://github.com/immunitastx/recover-counts&lt;/a&gt; to convert the log normalized the counts back to raw counts.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;## for one file
 ./recover_counts_from_log_normalized_data.py -m 10000 -d CSV GSE154763_ESCA_normalized_expression.csv -o GSE154763_ESCA_raw_counts.txt
 
## for all files
# mamba install parallel 
# regular expression to remove the normalized_expression.csv and rename the output to _raw_counts.txt
ls *expression.csv | parallel --rpl &amp;#39;{%(.+?)} s/$$1$//;&amp;#39; ./recover_counts_from_log_normalized_data.py -m 10000 -d CSV {} -o {%_normalized_expression.csv}_raw_count.txt
 &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;switch-to-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Switch to R&lt;/h3&gt;
&lt;p&gt;load libraries&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(here)
library(stringr)
library(dplyr)
library(ggplot2)
library(Seurat)
library(purrr)
library(readr)
library(harmony)
library(scCustomize)
library(SeuratDisk)
library(ggpointdensity)
library(viridis)
library(grid)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;read-in-counts-files&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;read in counts files&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## the count matrix is cell x gene
read_counts&amp;lt;- function(file){
  x&amp;lt;- read_csv(file)
  x&amp;lt;- as.data.frame(x)
  cells&amp;lt;- x$index
  
  mat&amp;lt;- as.matrix(x[,-1])
  
  rownames(mat)&amp;lt;- cells
  mat&amp;lt;- t(mat)
  return(mat)
}


counts_files&amp;lt;- list.files(&amp;quot;~/blog_data/GSE154763&amp;quot;, full.names = TRUE, pattern = &amp;quot;*raw_count.txt&amp;quot;)
counts_files&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;/Users/tommytang/blog_data/GSE154763/GSE154763_cDC2_raw_count.txt&amp;quot;  
#&amp;gt; [2] &amp;quot;/Users/tommytang/blog_data/GSE154763/GSE154763_ESCA_raw_count.txt&amp;quot;  
#&amp;gt; [3] &amp;quot;/Users/tommytang/blog_data/GSE154763/GSE154763_KIDNEY_raw_count.txt&amp;quot;
#&amp;gt; [4] &amp;quot;/Users/tommytang/blog_data/GSE154763/GSE154763_LYM_raw_count.txt&amp;quot;   
#&amp;gt; [5] &amp;quot;/Users/tommytang/blog_data/GSE154763/GSE154763_MYE_raw_count.txt&amp;quot;   
#&amp;gt; [6] &amp;quot;/Users/tommytang/blog_data/GSE154763/GSE154763_OV-FTC_raw_count.txt&amp;quot;
#&amp;gt; [7] &amp;quot;/Users/tommytang/blog_data/GSE154763/GSE154763_PAAD_raw_count.txt&amp;quot;  
#&amp;gt; [8] &amp;quot;/Users/tommytang/blog_data/GSE154763/GSE154763_THCA_raw_count.txt&amp;quot;  
#&amp;gt; [9] &amp;quot;/Users/tommytang/blog_data/GSE154763/GSE154763_UCEC_raw_count.txt&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# only use the last 3 cancer types to demonstrate, as the data are too big. 
counts_files&amp;lt;- counts_files %&amp;gt;%
        tail(n=3)

samples&amp;lt;- map_chr(counts_files, basename) 
samples&amp;lt;- str_replace(samples, &amp;quot;(GSE[0-9]+)_(.+)_raw_count.txt&amp;quot;, &amp;quot;\\2&amp;quot;)
names(counts_files)&amp;lt;- samples
counts&amp;lt;- purrr::map(counts_files, read_counts)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;read in metadata for each cancer&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## the tissue column contain some non-tumor cells
read_meta&amp;lt;- function(file){
  y&amp;lt;- read_csv(file, guess_max = 100000, 
               col_types = cols(tissue = col_character()))
  y&amp;lt;- as.data.frame(y)
  cells&amp;lt;- y$index
  y&amp;lt;- y[,-1]
  rownames(y)&amp;lt;- cells
  return(y)
}


meta_files&amp;lt;- list.files(&amp;quot;~/blog_data/GSE154763&amp;quot;, full.names = TRUE, pattern = &amp;quot;metadata.csv&amp;quot;)
# take only 3 cancer types
meta_files&amp;lt;- meta_files %&amp;gt;% tail(n=3)
meta_names&amp;lt;- map_chr(meta_files, basename)
meta_names&amp;lt;- str_replace(meta_names, &amp;quot;(GSE[0-9]+)_(.+)_metadata.csv&amp;quot;, &amp;quot;\\2&amp;quot;)
names(meta_files)&amp;lt;- meta_names

meta&amp;lt;- purrr::map(meta_files, read_meta)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Different cancer types have different number of genes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map(counts, nrow)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; $PAAD
#&amp;gt; [1] 14140
#&amp;gt; 
#&amp;gt; $THCA
#&amp;gt; [1] 15211
#&amp;gt; 
#&amp;gt; $UCEC
#&amp;gt; [1] 15849&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How many genes are in common among the 3 datasets?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map(counts, ~rownames(.x)) %&amp;gt;%
  purrr::reduce( function(x,y) {intersect(x,y)}) %&amp;gt;%
  length()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 13762&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;make-seurat-objects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;make Seurat objects&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;objs&amp;lt;- purrr::map2(counts, meta,  
                   ~ CreateSeuratObject(counts = as(.x, &amp;quot;sparseMatrix&amp;quot;), 
                                                      meta.data = .y))

## remain only the tumor samples with tissue == T
#subset(objs$ESCA, subset = tissue == &amp;quot;T&amp;quot;)

objs&amp;lt;- purrr::map(objs, ~ subset(.x, subset = tissue == &amp;quot;T&amp;quot;))

objs&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; $PAAD
#&amp;gt; An object of class Seurat 
#&amp;gt; 14140 features across 2628 samples within 1 assay 
#&amp;gt; Active assay: RNA (14140 features, 0 variable features)
#&amp;gt; 
#&amp;gt; $THCA
#&amp;gt; An object of class Seurat 
#&amp;gt; 15211 features across 4171 samples within 1 assay 
#&amp;gt; Active assay: RNA (15211 features, 0 variable features)
#&amp;gt; 
#&amp;gt; $UCEC
#&amp;gt; An object of class Seurat 
#&amp;gt; 15849 features across 4724 samples within 1 assay 
#&amp;gt; Active assay: RNA (15849 features, 0 variable features)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is a list of 3 seurat objects.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;preprocessSeurat&amp;lt;- function(obj){
  obj&amp;lt;-
    NormalizeData(obj, normalization.method = &amp;quot;LogNormalize&amp;quot;, scale.factor = 10000) %&amp;gt;%
    FindVariableFeatures( selection.method = &amp;quot;vst&amp;quot;, nfeatures = 2000) %&amp;gt;%
    ScaleData() %&amp;gt;%
    RunPCA() %&amp;gt;%
    RunHarmony(group.by.vars = &amp;quot;patient&amp;quot;, dims.use = 1:30) %&amp;gt;%
    RunUMAP(reduction = &amp;quot;harmony&amp;quot;, dims = 1:30) %&amp;gt;%
    FindNeighbors(reduction = &amp;quot;harmony&amp;quot;, dims = 1:30) %&amp;gt;% 
    FindClusters(resolution = 0.6)
  
  return(obj)
}


objs&amp;lt;- purrr::map(objs, preprocessSeurat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck
#&amp;gt; 
#&amp;gt; Number of nodes: 2628
#&amp;gt; Number of edges: 99201
#&amp;gt; 
#&amp;gt; Running Louvain algorithm...
#&amp;gt; Maximum modularity in 10 random starts: 0.8476
#&amp;gt; Number of communities: 10
#&amp;gt; Elapsed time: 0 seconds
#&amp;gt; Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck
#&amp;gt; 
#&amp;gt; Number of nodes: 4171
#&amp;gt; Number of edges: 167212
#&amp;gt; 
#&amp;gt; Running Louvain algorithm...
#&amp;gt; Maximum modularity in 10 random starts: 0.9003
#&amp;gt; Number of communities: 17
#&amp;gt; Elapsed time: 0 seconds
#&amp;gt; Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck
#&amp;gt; 
#&amp;gt; Number of nodes: 4724
#&amp;gt; Number of edges: 172629
#&amp;gt; 
#&amp;gt; Running Louvain algorithm...
#&amp;gt; Maximum modularity in 10 random starts: 0.8709
#&amp;gt; Number of communities: 15
#&amp;gt; Elapsed time: 0 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1&amp;lt;- scCustomize::DimPlot_scCustom(objs$UCEC)

p2&amp;lt;- scCustomize::DimPlot_scCustom(objs$UCEC, group.by = &amp;quot;MajorCluster&amp;quot;)

p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-09-28-how-to-create-pseudobulk-from-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-09-28-how-to-create-pseudobulk-from-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-10-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-psedobulk-for-the-single-cell-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Create psedobulk for the single cell data&lt;/h3&gt;
&lt;p&gt;Clean up the cell type annotation so it is consistent across cancer types.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;purrr::map(objs, ~.x$MajorCluster %&amp;gt;% unique() %&amp;gt;% sort())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; $PAAD
#&amp;gt; [1] &amp;quot;M01_Mast_KIT&amp;quot;    &amp;quot;M03_cDC1_CLEC9A&amp;quot; &amp;quot;M04_cDC2_CD1C&amp;quot;   &amp;quot;M05_cDC3_LAMP3&amp;quot; 
#&amp;gt; [5] &amp;quot;M06_Mono_CD14&amp;quot;   &amp;quot;M07_Mono_CD16&amp;quot;   &amp;quot;M08_Macro_SPP1&amp;quot;  &amp;quot;M09_Macro_C1QC&amp;quot; 
#&amp;gt; 
#&amp;gt; $THCA
#&amp;gt;  [1] &amp;quot;M01_Mast_KIT&amp;quot;    &amp;quot;M02_pDC_LILRA4&amp;quot;  &amp;quot;M03_cDC1_CLEC9A&amp;quot; &amp;quot;M04_cDC2_CD1C&amp;quot;  
#&amp;gt;  [5] &amp;quot;M05_cDC3_LAMP3&amp;quot;  &amp;quot;M06_Mono_CD14&amp;quot;   &amp;quot;M07_Mono_CD16&amp;quot;   &amp;quot;M08_Macro_NLRP3&amp;quot;
#&amp;gt;  [9] &amp;quot;M09_Macro_SPP1&amp;quot;  &amp;quot;M10_Macro_C1QC&amp;quot;  &amp;quot;M11_Macro_ISG15&amp;quot; &amp;quot;M12_Macro_LYVE1&amp;quot;
#&amp;gt; [13] &amp;quot;M13_Macro_INHBA&amp;quot;
#&amp;gt; 
#&amp;gt; $UCEC
#&amp;gt;  [1] &amp;quot;M01_Mast_KIT&amp;quot;    &amp;quot;M02_pDC_LILRA4&amp;quot;  &amp;quot;M03_cDC1_CLEC9A&amp;quot; &amp;quot;M04_cDC2_CD1C&amp;quot;  
#&amp;gt;  [5] &amp;quot;M05_cDC3_LAMP3&amp;quot;  &amp;quot;M06_Mono_CD14&amp;quot;   &amp;quot;M07_Mono_CD16&amp;quot;   &amp;quot;M08_Macro_NLRP3&amp;quot;
#&amp;gt;  [9] &amp;quot;M09_Macro_ISG15&amp;quot; &amp;quot;M10_Macro_SPP1&amp;quot;  &amp;quot;M11_Macro_C1QC&amp;quot;  &amp;quot;M12_Macro_LYVE1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clean_cluster_name&amp;lt;- function(obj){
  annotation&amp;lt;- obj@meta.data %&amp;gt;%
     mutate(annotation = str_replace(MajorCluster, &amp;quot;^M[0-9]{2}_&amp;quot;, &amp;quot;&amp;quot;)) %&amp;gt;%
    pull(annotation)
  obj$annotation&amp;lt;- annotation
  return(obj)
}


objs&amp;lt;- purrr::map(objs, clean_cluster_name)

purrr::map(objs, ~.x$annotation %&amp;gt;% unique() %&amp;gt;% sort())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; $PAAD
#&amp;gt; [1] &amp;quot;cDC1_CLEC9A&amp;quot; &amp;quot;cDC2_CD1C&amp;quot;   &amp;quot;cDC3_LAMP3&amp;quot;  &amp;quot;Macro_C1QC&amp;quot;  &amp;quot;Macro_SPP1&amp;quot; 
#&amp;gt; [6] &amp;quot;Mast_KIT&amp;quot;    &amp;quot;Mono_CD14&amp;quot;   &amp;quot;Mono_CD16&amp;quot;  
#&amp;gt; 
#&amp;gt; $THCA
#&amp;gt;  [1] &amp;quot;cDC1_CLEC9A&amp;quot; &amp;quot;cDC2_CD1C&amp;quot;   &amp;quot;cDC3_LAMP3&amp;quot;  &amp;quot;Macro_C1QC&amp;quot;  &amp;quot;Macro_INHBA&amp;quot;
#&amp;gt;  [6] &amp;quot;Macro_ISG15&amp;quot; &amp;quot;Macro_LYVE1&amp;quot; &amp;quot;Macro_NLRP3&amp;quot; &amp;quot;Macro_SPP1&amp;quot;  &amp;quot;Mast_KIT&amp;quot;   
#&amp;gt; [11] &amp;quot;Mono_CD14&amp;quot;   &amp;quot;Mono_CD16&amp;quot;   &amp;quot;pDC_LILRA4&amp;quot; 
#&amp;gt; 
#&amp;gt; $UCEC
#&amp;gt;  [1] &amp;quot;cDC1_CLEC9A&amp;quot; &amp;quot;cDC2_CD1C&amp;quot;   &amp;quot;cDC3_LAMP3&amp;quot;  &amp;quot;Macro_C1QC&amp;quot;  &amp;quot;Macro_ISG15&amp;quot;
#&amp;gt;  [6] &amp;quot;Macro_LYVE1&amp;quot; &amp;quot;Macro_NLRP3&amp;quot; &amp;quot;Macro_SPP1&amp;quot;  &amp;quot;Mast_KIT&amp;quot;    &amp;quot;Mono_CD14&amp;quot;  
#&amp;gt; [11] &amp;quot;Mono_CD16&amp;quot;   &amp;quot;pDC_LILRA4&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;create-psedobulk&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Create Psedobulk&lt;/h3&gt;
&lt;p&gt;There are many ways to do it.&lt;/p&gt;
&lt;p&gt;Let’s use &lt;a href=&#34;https://github.com/immunogenomics/presto&#34;&gt;presto&lt;/a&gt; for more low-level analysis instead of using the wrapper functions in &lt;code&gt;muscat&lt;/code&gt;. To use &lt;code&gt;muscat&lt;/code&gt;, you will need to convert the Seurat object to a &lt;code&gt;SingleCellExperiment&lt;/code&gt; object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(presto)

objs$PAAD@meta.data %&amp;gt;% 
        head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                        orig.ident nCount_RNA nFeature_RNA percent_mito n_counts
#&amp;gt; AAACGGGGTGTGCCTG-35 SeuratProject       7626         2353   0.03575639     7635
#&amp;gt; AAAGATGAGCGATTCT-35 SeuratProject       9953         2396   0.02630258     9961
#&amp;gt; AAAGATGCAATTGCTG-35 SeuratProject      11091         2930   0.04469274    11098
#&amp;gt; AAAGATGCATGGTCTA-35 SeuratProject       9739         2551   0.03981121     9746
#&amp;gt; AAAGTAGCAAACGCGA-35 SeuratProject       6959         1145   0.02802030     9850
#&amp;gt; AAATGCCTCCACGACG-35 SeuratProject       2404         1031   0.03742204     2405
#&amp;gt;                     percent_hsp          barcode batch       library_id cancer
#&amp;gt; AAACGGGGTGTGCCTG-35 0.020563196 AAACGGGGTGTGCCTG    35 PACA-P20181121-T   PAAD
#&amp;gt; AAAGATGAGCGATTCT-35 0.003312921 AAAGATGAGCGATTCT    35 PACA-P20181121-T   PAAD
#&amp;gt; AAAGATGCAATTGCTG-35 0.004234997 AAAGATGCAATTGCTG    35 PACA-P20181121-T   PAAD
#&amp;gt; AAAGATGCATGGTCTA-35 0.031089678 AAAGATGCATGGTCTA    35 PACA-P20181121-T   PAAD
#&amp;gt; AAAGTAGCAAACGCGA-35 0.015837563 AAAGTAGCAAACGCGA    35 PACA-P20181121-T   PAAD
#&amp;gt; AAATGCCTCCACGACG-35 0.007484408 AAATGCCTCCACGACG    35 PACA-P20181121-T   PAAD
#&amp;gt;                       patient tissue n_genes   MajorCluster   source tech
#&amp;gt; AAACGGGGTGTGCCTG-35 P20181121      T    2362   M01_Mast_KIT ZhangLab 10X5
#&amp;gt; AAAGATGAGCGATTCT-35 P20181121      T    2404  M06_Mono_CD14 ZhangLab 10X5
#&amp;gt; AAAGATGCAATTGCTG-35 P20181121      T    2937 M08_Macro_SPP1 ZhangLab 10X5
#&amp;gt; AAAGATGCATGGTCTA-35 P20181121      T    2558  M07_Mono_CD16 ZhangLab 10X5
#&amp;gt; AAAGTAGCAAACGCGA-35 P20181121      T    2891   M01_Mast_KIT ZhangLab 10X5
#&amp;gt; AAATGCCTCCACGACG-35 P20181121      T    1032   M01_Mast_KIT ZhangLab 10X5
#&amp;gt;                         UMAP1      UMAP2 RNA_snn_res.0.6 seurat_clusters
#&amp;gt; AAACGGGGTGTGCCTG-35  7.324396 -0.6997318               4               4
#&amp;gt; AAAGATGAGCGATTCT-35 -5.009157 -0.8700839               2               2
#&amp;gt; AAAGATGCAATTGCTG-35 -5.944770  1.9433328               7               7
#&amp;gt; AAAGATGCATGGTCTA-35 -3.173428 -2.7142875               2               2
#&amp;gt; AAAGTAGCAAACGCGA-35  7.285788 -0.4640464               4               4
#&amp;gt; AAATGCCTCCACGACG-35  4.864260 -0.9610466               4               4
#&amp;gt;                     annotation
#&amp;gt; AAACGGGGTGTGCCTG-35   Mast_KIT
#&amp;gt; AAAGATGAGCGATTCT-35  Mono_CD14
#&amp;gt; AAAGATGCAATTGCTG-35 Macro_SPP1
#&amp;gt; AAAGATGCATGGTCTA-35  Mono_CD16
#&amp;gt; AAAGTAGCAAACGCGA-35   Mast_KIT
#&amp;gt; AAATGCCTCCACGACG-35   Mast_KIT&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will need to create a pseduobulk per cancer type, per sample, and per cell type.
those are in the metadata column: ‘annotation’, ‘patient’, ‘cancer’.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_pseduo_bulk&amp;lt;- function(obj){
  data_collapsed &amp;lt;- presto::collapse_counts(obj@assays$RNA@counts, 
                                  obj@meta.data, 
                                  c(&amp;#39;annotation&amp;#39;, &amp;#39;patient&amp;#39;, &amp;#39;cancer&amp;#39;))
  meta_data&amp;lt;- data_collapsed$meta_data 

  mat&amp;lt;- data_collapsed$counts_mat

  colnames(mat)&amp;lt;- paste(meta_data$cancer, colnames(mat), sep=&amp;quot;_&amp;quot;)
  return(list(mat = mat, meta_data = meta_data))
}

pseduo_bulk_objs&amp;lt;- purrr::map(objs, create_pseduo_bulk)

### different number of genes per dataset 
purrr::map(pseduo_bulk_objs, ~nrow(.x$mat)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; $PAAD
#&amp;gt; [1] 14140
#&amp;gt; 
#&amp;gt; $THCA
#&amp;gt; [1] 15211
#&amp;gt; 
#&amp;gt; $UCEC
#&amp;gt; [1] 15849&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;genes_per_data&amp;lt;- purrr::map(pseduo_bulk_objs, ~rownames(.x$mat)) 

## common number of genes
common_genes&amp;lt;- purrr::reduce(genes_per_data, intersect)

length(common_genes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 13762&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;subset_common_mat&amp;lt;- function(mat){
  mat&amp;lt;- mat[common_genes, ]
  return(mat)
}


mats&amp;lt;- map(pseduo_bulk_objs, ~subset_common_mat(.x$mat))
map(mats, dim)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; $PAAD
#&amp;gt; [1] 13762    42
#&amp;gt; 
#&amp;gt; $THCA
#&amp;gt; [1] 13762   120
#&amp;gt; 
#&amp;gt; $UCEC
#&amp;gt; [1] 13762    93&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta_data&amp;lt;- map(pseduo_bulk_objs, ~.x$meta_data)

meta_data$PAAD %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;   annotation   patient cancer
#&amp;gt; 1   Mast_KIT P20181121   PAAD
#&amp;gt; 2  Mono_CD14 P20181121   PAAD
#&amp;gt; 3 Macro_SPP1 P20181121   PAAD
#&amp;gt; 4  Mono_CD16 P20181121   PAAD
#&amp;gt; 5  cDC2_CD1C P20181121   PAAD
#&amp;gt; 6 Macro_C1QC P20181121   PAAD&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mats$PAAD[1:5, 1:6]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;               PAAD_sample_5 PAAD_sample_6 PAAD_sample_4 PAAD_sample_7
#&amp;gt; FO538757.2               69            19            50             5
#&amp;gt; AP006222.2                0             1             0             0
#&amp;gt; RP4-669L17.10             0             1             0             0
#&amp;gt; RP11-206L10.9             0             0             2             0
#&amp;gt; LINC00115                 2             5             6             1
#&amp;gt;               PAAD_sample_1 PAAD_sample_3
#&amp;gt; FO538757.2                2            17
#&amp;gt; AP006222.2                0             0
#&amp;gt; RP4-669L17.10             0             0
#&amp;gt; RP11-206L10.9             0             1
#&amp;gt; LINC00115                 0             3&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;pca-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;PCA analysis&lt;/h3&gt;
&lt;p&gt;merge all the count table into a big one (I am going to do PCA!)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mats&amp;lt;- purrr::reduce(mats, cbind)
meta_data&amp;lt;- purrr::reduce(meta_data, rbind)
dim(mats)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 13762   255&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;final_meta&amp;lt;- meta_data

## log normalize the count matrix 
total_reads&amp;lt;- colSums(mats)

final_mat&amp;lt;- t(t(mats)/total_reads)
final_mat&amp;lt;- log2(final_mat + 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(genefilter)

# choose the top 1000 most variabel genes 
top_genes&amp;lt;- genefilter::rowVars(final_mat) %&amp;gt;% 
  sort(decreasing = TRUE) %&amp;gt;%
  names() %&amp;gt;%
  head(1000)

# subset only the top 1000 genes
expression_mat_sub&amp;lt;- final_mat[top_genes, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;PCA analysis. If you are new to it, read my old blog post: &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/pca-in-action/&#34;&gt;PCA in action&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# calculate the PCA
pca&amp;lt;- prcomp(t(expression_mat_sub),center = TRUE, scale. = TRUE) 

# check the order of the samples are the same.
all.equal(rownames(pca$x), colnames(expression_mat_sub))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;PC1_and_PC2&amp;lt;- data.frame(PC1=pca$x[,1], PC2= pca$x[,2])

PC1_and_PC2&amp;lt;- cbind(PC1_and_PC2, final_meta)

head(PC1_and_PC2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                      PC1       PC2 annotation   patient cancer
#&amp;gt; PAAD_sample_5 -10.131179 28.929632   Mast_KIT P20181121   PAAD
#&amp;gt; PAAD_sample_6  16.801059  6.981512  Mono_CD14 P20181121   PAAD
#&amp;gt; PAAD_sample_4  18.822229  9.311594 Macro_SPP1 P20181121   PAAD
#&amp;gt; PAAD_sample_7  13.646380  4.989768  Mono_CD16 P20181121   PAAD
#&amp;gt; PAAD_sample_1  -4.800154  2.925677  cDC2_CD1C P20181121   PAAD
#&amp;gt; PAAD_sample_3  13.641424  7.164102 Macro_C1QC P20181121   PAAD&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;plot PCA plot&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

p1&amp;lt;- ggplot(PC1_and_PC2, aes(x=PC1, y=PC2)) + 
        geom_point(aes(color = cancer)) +
        theme_bw(base_size = 14) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s color it by cell type&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Polychrome)
set.seed(123)

length(unique(PC1_and_PC2$annotation))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 13&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mypal &amp;lt;- kelly.colors(14)[-1]

p2&amp;lt;- ggplot(PC1_and_PC2, aes(x=PC1, y=PC2)) + 
        geom_point(aes(color = annotation)) +
        theme_bw(base_size = 14) +
        scale_color_manual(values = mypal %&amp;gt;% unname()) 

p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-09-28-how-to-create-pseudobulk-from-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-09-28-how-to-create-pseudobulk-from-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-18-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see the psedobulk of the same myeloid cell types of different cancer types tend to cluster together which makes sense!&lt;/p&gt;
&lt;p&gt;Visualize in heatmap.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(RColorBrewer)
library(ComplexHeatmap)
#RColorBrewer::display.brewer.all()
set.seed(123)
cols&amp;lt;- RColorBrewer::brewer.pal(n = 3, name = &amp;quot;Set1&amp;quot;)
unique(final_meta$cancer)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;PAAD&amp;quot; &amp;quot;THCA&amp;quot; &amp;quot;UCEC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rownames(final_meta)&amp;lt;- colnames(expression_mat_sub)

ha&amp;lt;- HeatmapAnnotation(df = final_meta[, -2],
                       col=list(cancer = setNames(cols, unique(final_meta$cancer) %&amp;gt;% sort()),
                       annotation= setNames(unname(mypal), unique(final_meta$annotation) %&amp;gt;% sort())),
                       show_annotation_name = TRUE)

col_fun&amp;lt;- circlize::colorRamp2(c(-2,0, 2), colors = c(&amp;quot;blue&amp;quot;, &amp;quot;white&amp;quot;, &amp;quot;red&amp;quot;))

Heatmap(t(scale(t(expression_mat_sub))), top_annotation = ha,
         show_row_names = FALSE, show_column_names = FALSE,
         show_row_dend = FALSE,
        col = col_fun,
        name = &amp;quot;expression&amp;quot;,
        column_dend_reorder = TRUE,
        raster_quality = 3,
        use_raster = FALSE,
        )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-09-28-how-to-create-pseudobulk-from-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s run Harmony to correct the batches of different cancer type and patients.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
harmony_embeddings &amp;lt;- harmony::HarmonyMatrix(
    expression_mat_sub, final_meta, c(&amp;#39;cancer&amp;#39;, &amp;#39;patient&amp;#39;), do_pca = TRUE, verbose= TRUE
)

rownames(harmony_embeddings)&amp;lt;- rownames(final_meta)
harmony_pc&amp;lt;- data.frame(harmony1=harmony_embeddings[,1], harmony2= harmony_embeddings[,2])

harmony_pc&amp;lt;- cbind(harmony_pc, final_meta)

## plot PCA plot
library(ggplot2)

p1&amp;lt;- ggplot(harmony_pc, aes(x=harmony1, y=harmony2)) + 
        geom_point(aes(color = cancer)) +
        theme_bw(base_size = 14) +
  scale_color_manual(values = cols)

p2&amp;lt;- ggplot(harmony_pc, aes(x=harmony1, y=harmony2)) + 
        geom_point(aes(color = annotation)) +
        theme_bw(base_size = 14) +
        scale_color_manual(values = mypal %&amp;gt;% unname())

p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-09-28-how-to-create-pseudobulk-from-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-09-28-how-to-create-pseudobulk-from-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-20-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It looks like the samples are clustered a little better (which is expected as harmony artifically mixes the samples from different batches).&lt;/p&gt;
&lt;p&gt;Read this paper &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2023.05.05.539614v3&#34;&gt;Signal recovery in single cell batch integration&lt;/a&gt; as harmony or any single-cell integration method may erase biological differences.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
What gets erased when you integrate &lt;a href=&#34;https://twitter.com/hashtag/singlecell?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#singlecell&lt;/a&gt; data across samples/studies, and can you get it back? When samples are from e.g. healthy &amp;amp; disease, should you simply massage cells together? FINALLY, I feel we can answer this question: &lt;a href=&#34;https://t.co/0PrkIZDyDp&#34;&gt;https://t.co/0PrkIZDyDp&lt;/a&gt; &lt;a href=&#34;https://t.co/l8FbHgGrrA&#34;&gt;pic.twitter.com/l8FbHgGrrA&lt;/a&gt;
&lt;/p&gt;
— Nancy Zhang (&lt;span class=&#34;citation&#34;&gt;@NancyZh60672287&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/NancyZh60672287/status/1705655738578653640?ref_src=twsrc%5Etfw&#34;&gt;September 23, 2023&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;Let’s visulize the heatmap by the sample correlations in the harmony space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Heatmap(cor(t(harmony_embeddings)), top_annotation = ha, show_row_names = FALSE,
        show_column_names = FALSE, column_dend_reorder = TRUE, 
        name=&amp;quot;harmony space\ncorrelation&amp;quot;,
        raster_quality = 3,
        use_raster = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-09-28-how-to-create-pseudobulk-from-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;576&#34; /&gt;
You see the annotation bar looks much cleaner.&lt;/p&gt;
&lt;p&gt;That’s a wrap! I hope you learned how to construct pseduobulk for single cell data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;further-reading&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Further reading&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;A blog post by Jean Fan: &lt;a href=&#34;https://jef.works/blog/2020/04/06/quickly-creating-pseudobulks/&#34;&gt;Create psedobulk by linear algebra&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;presto::collapse_counts()&lt;/code&gt; followed by DESeq2 workflow: &lt;a href=&#34;https://github.com/immunogenomics/presto/blob/master/vignettes/pseudobulk.ipynb&#34; class=&#34;uri&#34;&gt;https://github.com/immunogenomics/presto/blob/master/vignettes/pseudobulk.ipynb&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://rdrr.io/bioc/scran/man/pseudoBulkDGE.html&#34;&gt;scran::pseudoBulkDGE&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.bioconductor.org/packages/release/bioc/html/muscat.html&#34;&gt;muscat&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I have used &lt;code&gt;muscat&lt;/code&gt; before and it wraps &lt;code&gt;DESeq2&lt;/code&gt;, &lt;code&gt;EdgeR&lt;/code&gt; etc for mutli-sample, multi-condition differential analysis. I recommend you to use it.&lt;/p&gt;
&lt;p&gt;You can watch the video for this tutorial too:&lt;/p&gt;
&lt;div class=&#34;vembedr&#34;&gt;
&lt;div&gt;
&lt;iframe src=&#34;https://www.youtube.com/embed/nt_fOIkNS0s&#34; width=&#34;533&#34; height=&#34;300&#34; frameborder=&#34;0&#34; allowfullscreen=&#34;&#34; data-external=&#34;1&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Generative AI: Text generation using Long short-term memory (LSTM) model</title>
      <link>/post/generative-ai-text-generation-using-long-short-term-memory-lstm-model/</link>
      <pubDate>Sun, 24 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/generative-ai-text-generation-using-long-short-term-memory-lstm-model/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In the world of deep learning, generating sequence data is a fundamental task. Typically, this involves training a network, often an RNN (Recurrent Neural Network) or a convnet (Convolutional Neural Network), to &lt;strong&gt;predict the next token or a sequence of tokens in a given sequence, using the preceding tokens as input&lt;/strong&gt;. For example, when provided with the input “the cat is on the ma,” the network’s objective is to predict the next character, such as ‘t.’ When working with textual data, tokens typically represent words or characters.&lt;/p&gt;
&lt;p&gt;Any network capable of estimating the likelihood of the next token based on the previous ones is known as a &lt;strong&gt;language model&lt;/strong&gt;, which effectively captures the underlying statistical structure of language.&lt;/p&gt;
&lt;p&gt;You may have used ChatGPT. ChatGPT is a specialized version of the GPT (Generative Pre-trained Transformer) model created by OpenAI. Its primary purpose is to generate human-like text and engage in natural language conversations.&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;large language model(LLM)&lt;/strong&gt;, on the other hand, refers to models with significantly more parameters than earlier versions. These models, such as GPT-3 and its successors, are trained on extensive datasets and possess a high capacity for understanding and generating human language&lt;/p&gt;
&lt;p&gt;Once you’ve trained such a language model, you can employ it to generate new sequences. To do this, you provide it with an initial text string, often referred to as conditioning data. You then ask the model to predict the subsequent character or word, and you can even request several tokens at once. The generated output is appended to the input data, and this process repeats iteratively, allowing you to generate sequences of varying lengths that mimic the structure of the data on which the model was trained, resembling human-authored sentences.&lt;/p&gt;
&lt;p&gt;In the example we’ll use an LSTM (Long Short-Term Memory) layer. This layer will be fed with strings of N words taken from a text corpus (news headlines) and trained to predict the N + 1 word. The model’s output will be a softmax distribution encompassing all potential words, essentially representing the probability distribution for the forthcoming word.&lt;/p&gt;
&lt;p&gt;Load the libraries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(keras)
library(reticulate)
library(ggplot2)
library(dplyr)
library(readr)
use_condaenv(&amp;quot;r-reticulate&amp;quot;)

# Set a random seed in R to make it more reproducible 
set.seed(123)

# Set the seed for Keras/TensorFlow
tensorflow::set_random_seed(123)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dataset can be downloaded from my github &lt;a href=&#34;https://github.com/crazyhottommy/machine_learning_datasets/tree/main/news_headlines&#34; class=&#34;uri&#34;&gt;https://github.com/crazyhottommy/machine_learning_datasets/tree/main/news_headlines&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;file_dir&amp;lt;- &amp;quot;~/blog_data/news_headlines&amp;quot;

files&amp;lt;- list.files(file_dir, full.names = TRUE, pattern = &amp;quot;Articles&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;clean the dataset&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dfs&amp;lt;- purrr::map(files, read_csv)
df&amp;lt;- dplyr::bind_rows(dfs)
headlines&amp;lt;- df %&amp;gt;%
        filter(headline != &amp;quot;Unknown&amp;quot;) %&amp;gt;%
        pull(headline)

headlines[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;Finding an Expansive View  of a Forgotten People in Niger&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;headlines[2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;And Now,  the Dreaded Trump Curse&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(headlines)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 8603&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tokenize the words&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;headlines&amp;lt;- stringr::str_to_lower(headlines)

max_words&amp;lt;- 10000
tokenizer&amp;lt;- text_tokenizer(num_words = max_words) %&amp;gt;%
  fit_text_tokenizer(headlines)


word_index&amp;lt;- tokenizer$word_index

#total_words &amp;lt;- length(tokenizer$word_index) + 1
total_words&amp;lt;- max_words + 1

sequences&amp;lt;- texts_to_sequences(tokenizer, headlines)

## first review turned into integers
sequences[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1]  403   17 5242  543    4    2 1616  151    5 1992&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sequences[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]    7   76    1 5243   10 5244&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create input sequences and output sequences. Given the words seen, the model predicts the next word/token.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;input_sequences &amp;lt;- list()
output_sequences &amp;lt;- list()

for (sentence_seq in sequences) {
        # at least 3 words in the headline
        seq_length&amp;lt;- 2
          if (length(sentence_seq) &amp;lt; seq_length + 1) {
    next
  }

  for (i in 1:(length(sentence_seq) - seq_length)) {
    seq_in &amp;lt;- sentence_seq[i:(i + seq_length - 1)]
    seq_out &amp;lt;- sentence_seq[i + seq_length]
    
    input_sequences[[length(input_sequences) + 1]] &amp;lt;- seq_in
    output_sequences[[length(output_sequences) + 1]] &amp;lt;- seq_out
  }
}

range(purrr::map(sequences, length))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]  0 28&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The longest headline is 28 words.&lt;/p&gt;
&lt;p&gt;pad the sequence to the same length.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;maxlen&amp;lt;- 20 #you may change it to 28 for example

input_sequences &amp;lt;- pad_sequences(input_sequences, maxlen = maxlen, padding = &amp;#39;pre&amp;#39;)
output_sequences &amp;lt;- to_categorical(output_sequences, num_classes = total_words )


## it becomes a 2D matrix of samples x seq_length
dim(input_sequences) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 43073    20&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(output_sequences)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 43073 10001&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;construct the model. First a layer_embedding layer. Read my previous blog to understand word embeddings.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- keras_model_sequential() %&amp;gt;%
  layer_embedding(input_dim = max_words + 1, output_dim = 10) %&amp;gt;%
  layer_lstm(units = 100) %&amp;gt;%
        layer_dropout(rate = 0.1) %&amp;gt;%
  layer_dense(units = max_words + 1, activation = &amp;#39;softmax&amp;#39;)


# you could try a different architecture. The results are not that different...
# model &amp;lt;- keras_model_sequential() %&amp;gt;%
#         layer_embedding(input_dim = max_words + 1, output_dim = 100) %&amp;gt;%
#         layer_lstm(units = 128, return_sequences = TRUE) %&amp;gt;%
#         layer_dropout(rate = 0.4) %&amp;gt;%
#         layer_lstm(units = 128) %&amp;gt;%
#         layer_dropout(rate = 0.4) %&amp;gt;%
#         layer_dense(units = max_words + 1, activation = &amp;#39;softmax&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compile the model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model %&amp;gt;% compile(
  loss = &amp;#39;categorical_crossentropy&amp;#39;,
  optimizer = optimizer_adam(),
  metrics = c(&amp;#39;accuracy&amp;#39;)
)

summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Model: &amp;quot;sequential&amp;quot;
#&amp;gt; ________________________________________________________________________________
#&amp;gt; Layer (type)                        Output Shape                    Param #     
#&amp;gt; ================================================================================
#&amp;gt; embedding (Embedding)               (None, None, 10)                100010      
#&amp;gt; ________________________________________________________________________________
#&amp;gt; lstm (LSTM)                         (None, 100)                     44400       
#&amp;gt; ________________________________________________________________________________
#&amp;gt; dropout (Dropout)                   (None, 100)                     0           
#&amp;gt; ________________________________________________________________________________
#&amp;gt; dense (Dense)                       (None, 10001)                   1010101     
#&amp;gt; ================================================================================
#&amp;gt; Total params: 1,154,511
#&amp;gt; Trainable params: 1,154,511
#&amp;gt; Non-trainable params: 0
#&amp;gt; ________________________________________________________________________________&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Train the model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Training the model
history&amp;lt;- model %&amp;gt;% fit(
  input_sequences,
  output_sequences,
  batch_size = 64,
  epochs = 100,
  validation_split = 0.2
)


plot(history)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-09-24-generative-ai-text-generation-using-long-short-term-memory-lstm-model_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It gets overfit quickly as you can see the validation accuracy is saturated in about 10 epoch with an accuracy of little over 0.1! It is such a small dataset. The &lt;code&gt;layer_embedding&lt;/code&gt; may not as good, and we may improve the accuracy by using some pre-built word embeddings.&lt;/p&gt;
&lt;p&gt;read my previous blog to &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/understand-word-embedding-and-use-deep-learning-to-classify-movie-reviews/&#34;&gt;understand word embeddings&lt;/a&gt; and &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/long-short-term-memory-lstm-recurrent-neural-network-rnn-to-classify-movie-reviews/&#34;&gt;Long short-term memory (LSTM)&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;generate-new-headlines&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Generate new headlines&lt;/h3&gt;
&lt;p&gt;Now that we have trained the model, we can feed the model some seed words and ask the model to generate new text.&lt;/p&gt;
&lt;p&gt;To manage the level of randomness during the sampling process, we will introduce a parameter known as the softmax temperature. This parameter defines the degree of uncertainty within the probability distribution utilized for sampling, essentially describing how unexpected or foreseeable the selection of the next character will be. When provided with a temperature value, it results in the calculation of a fresh probability distribution derived from the original one.&lt;/p&gt;
&lt;p&gt;The temperature is to re-normalize the probability of the next words so some new random words can be picked up. The higher the temperature, the more random the words will be picked.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Generate text using the trained model
generate_text &amp;lt;- function(seed_text, length, temperature = 0.5) {
        cat(seed_text, &amp;quot; &amp;quot;)
  for (i in 1:length) {
    encoded_sequence &amp;lt;- texts_to_sequences(tokenizer, seed_text)[[1]]
    encoded_sequence &amp;lt;- pad_sequences(list(encoded_sequence), maxlen = maxlen, padding = &amp;#39;pre&amp;#39;)
    
    next_word_prob&amp;lt;- model %&amp;gt;% predict(encoded_sequence)
    # Apply temperature to the softmax probabilities
    scaled_probs &amp;lt;- log(next_word_prob) / temperature
    exp_probs &amp;lt;- exp(scaled_probs)
    adjusted_probs &amp;lt;- exp_probs / sum(exp_probs)
    
    predicted_word_index &amp;lt;- sample(1:(max_words+1), size = 1, prob = adjusted_probs)
    predicted_word &amp;lt;- names(tokenizer$word_index)[predicted_word_index]
    
    cat(predicted_word, &amp;quot; &amp;quot;)
    seed_text &amp;lt;- c(seed_text, predicted_word)[-1]
  }
  cat(&amp;quot;\n&amp;quot;)
}


# Generate text starting from a seed text

generate_text(&amp;quot;india and china&amp;quot;, length = 5, temperature = 0.1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; india and china  green  dedicated  of  a  paradise&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;generate_text(&amp;quot;science and technology&amp;quot;, length = 8, temperature = 0.3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; science and technology  long  to  we  plan  for  better  of  a&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;generate_text(&amp;quot;science and technology&amp;quot;, length = 15, temperature = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; science and technology  justice  to  tells  a  paradise  provocateur  in  empathy  for  glare  details  and  variety  ado  but&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;generate_text(&amp;quot;new york is&amp;quot;, length = 15, temperature = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; new york is  eat  to  news  trump’s  king  congress  to  judge  finding  to  ditch  and  to  to  to&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;generate_text(&amp;quot;new york is&amp;quot;, length = 5, temperature = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; new york is  eat  to  hypocrisy  and  to&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this dummy example, the output from the model is not that accurate and interesting. With a larger training datasets and a better model, we can generate the text better.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;further-readings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Further readings&lt;/h3&gt;
&lt;p&gt;If you want to know more on the language model&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.borealisai.com/research-blogs/a-high-level-overview-of-large-language-models/&#34;&gt;A High-level Overview of Large Language Models&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.borealisai.com/research-blogs/training-and-fine-tuning-large-language-models/&#34;&gt;Training and fine-tuning large language models&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=jkrNMKz9pWU&#34;&gt;A Hackers’ Guide to Language Models&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://medium.com/@annikabrundyn1/the-beginners-guide-to-recurrent-neural-networks-and-text-generation-44a70c34067f&#34; class=&#34;uri&#34;&gt;https://medium.com/@annikabrundyn1/the-beginners-guide-to-recurrent-neural-networks-and-text-generation-44a70c34067f&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/code/shivamb/beginners-guide-to-text-generation-using-lstms&#34; class=&#34;uri&#34;&gt;https://www.kaggle.com/code/shivamb/beginners-guide-to-text-generation-using-lstms&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.manning.com/books/deep-learning-with-r&#34;&gt;Deep learning with R&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Monkeybread: A Python toolkit for the analysis of cellular niches in single-cell resolution spatial transcriptomics data</title>
      <link>/publication/2023-09-15-monkeybread/</link>
      <pubDate>Fri, 15 Sep 2023 00:00:00 -0400</pubDate>
      
      <guid>/publication/2023-09-15-monkeybread/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The tidyomics ecosystem: Enhancing omic data analyses</title>
      <link>/publication/2023-09-13-tidyomics/</link>
      <pubDate>Wed, 13 Sep 2023 00:00:00 -0400</pubDate>
      
      <guid>/publication/2023-09-13-tidyomics/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Omics Playground: Derive biological insights from your omics data at your fingertip</title>
      <link>/post/omics-playground-derive-biological-insights-from-your-omics-data-at-your-fingertip/</link>
      <pubDate>Mon, 11 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/omics-playground-derive-biological-insights-from-your-omics-data-at-your-fingertip/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Disclaimer: This post is sponsored by &lt;a href=&#34;https://bigomics.ch/&#34; target=&#34;_blank&#34;&gt;BigOmics platform&lt;/a&gt;. I have personally tested the platform. The opinions and views expressed in this post are solely those of the author and do not represent the views of my employer&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;a-brief-description-of-the-platform-what-challenges-could-the-platform-solve&#34;&gt;A brief description of the platform. What challenges could the platform solve?&lt;/h3&gt;

&lt;p&gt;The BigOmics platform - &lt;a href=&#34;https://playground.bigomics.ch/&#34; target=&#34;_blank&#34;&gt;Omics Playground&lt;/a&gt;- provides a simplified approach for the effective processing of bulk RNA-seq data and proteomics data, resolving many issues experienced by scientists in the field.&lt;/p&gt;

&lt;p&gt;This platform has an intuitive user interface that makes analysis more straightforward. It incorporates crucial elements like sample quality control and a gene-centric view to ensure users can easily browse their data. A count/expression data file (counts.csv), a sample information file (samples.csv), and an optional file defining statistical comparisons (comparisons.csv) are among the necessary input files.&lt;/p&gt;

&lt;p&gt;When these files are uploaded, the platform quickly creates a Principal Component Analysis (PCA) graphic. Once the analysis is configured, it gives quick insights into the data structure. The analytical workflow is streamlined by creating comparative contrasts by dragging and dropping objects.&lt;/p&gt;

&lt;p&gt;Omics Playground&amp;rsquo;s noteworthy benefit is its ability to automatically perform various downstream RNA-seq analyses. It conducts differential expression analysis, produces MA and volcano plots, and builds heatmaps. It also carries out gene-gene correlation analysis, gene set enrichment analysis (&lt;a href=&#34;https://www.gsea-msigdb.org/gsea/index.jsp&#34; target=&#34;_blank&#34;&gt;GSEA&lt;/a&gt;), possible biomarker identification, and weighted gene co-expression network analysis (&lt;a href=&#34;https://horvath.genetics.ucla.edu/html/CoexpressionNetwork/Rpackages/WGCNA/Tutorials/&#34; target=&#34;_blank&#34;&gt;WGCNA&lt;/a&gt;) for gene module analysis.&lt;/p&gt;

&lt;p&gt;With sophisticated experimental designs that require several varied comparisons, this platform successfully tackles the issue of labor-intensive and time-consuming bespoke analyses. Researchers may now rely upon Omics Playground to speed up the processing of their RNA-seq data, giving them more time for crucial interpretation and scientific breakthroughs.&lt;/p&gt;

&lt;h3 id=&#34;what-could-be-the-value-proposition-for-i-biologists-ii-bioinformaticians-and-iii-biotech-companies&#34;&gt;What could be the value proposition for i) biologists, ii) bioinformaticians and iii) biotech companies?&lt;/h3&gt;

&lt;p&gt;For biologists: Omics Playground serves as a user-friendly data analysis dashboard, offering a range of visualizations that facilitate quick data understanding and insight extraction. Notably, the platform automatically converts ENSEMBL IDs for genes in the count table into official gene symbols, making it easier to analyze the data. The platform also provides a gene overview that shows the levels of gene expression in distinct &lt;a href=&#34;https://www.gtexportal.org/home/&#34; target=&#34;_blank&#34;&gt;GTEX&lt;/a&gt; tissues, enhancing our understanding of biology. Using feature importances produced by six machine learning algorithms, including XGBoost and Random Forest, biologists may also quickly find new biomarkers. This feature enables scientists to extract important biological insights easily.&lt;/p&gt;

&lt;p&gt;For bioinformaticians: Omics Playground is a valuable tool since it eliminates the need for considerable custom code creation, saving them time. It speeds up the data analysis, enabling bioinformaticians to conduct studies quickly and work efficiently with wet lab scientists. The platform&amp;rsquo;s capacity to promptly discover prospective biomarkers is quite helpful since it speeds the identification of essential targets and genes of interest.&lt;/p&gt;

&lt;p&gt;For Biotech: Because Omics Playground makes it possible to quickly and effectively analyze large amounts of RNA-seq data, biotech businesses stand to benefit significantly from it. Due to its efficiency, Research and Development (R&amp;amp;D) activities move more quickly, and decision-making processes accelerate. Biotech businesses may maximize resource allocation and strengthen their competitive edge in the dynamic and quick-moving biotechnology industry by utilizing Omics Playground.&lt;/p&gt;

&lt;h3 id=&#34;what-are-the-capabilities-and-strengths-of-the-platform-what-do-i-like-the-most&#34;&gt;What are the capabilities and strengths of the platform? What do I like the most?&lt;/h3&gt;

&lt;p&gt;The feature that appeals to me the most about this platform is the interactive features of many plots generated. For example, it is easy to upload customized gene sets and highlight them in the volcano plot; the heatmaps are interactive (&lt;strong&gt;see the figure below&lt;/strong&gt;), and one can zoom in and out or hover over the mouse to get the gene information.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/bigomics.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Another noteworthy aspect of the platform is its ability to compare many comparisons simultaneously. Additionally, the Weighted Gene Co-expression Network Analysis (WGCNA) module&amp;rsquo;s integration with drug connectivity analysis is tremendously beneficial since it quickly identifies new drug candidates and interesting gene modules. Those features make it an essential tool for thorough data exploration and analysis.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/wgcna.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;what-can-be-improved&#34;&gt;What can be improved?&lt;/h3&gt;

&lt;p&gt;A more interactive visualization option for the pathway analysis module would be great. For example, it will be nice for the users to click a gene in the pathway that is identified and get more information. It would also be beneficial to give users a wider variety of choices for editing and configuring figures so they are easily suited for publishing.&lt;/p&gt;

&lt;p&gt;The efficiency and synergy of research teams might be significantly improved by enhancing the platform&amp;rsquo;s collaboration capabilities by enabling bioinformaticians to easily share their projects with wet lab scientists, allowing them to view and study the same dataset together. These suggested changes will improve user experience and promote seamless scientific cooperation.&lt;/p&gt;

&lt;p&gt;In conclusion, biotech businesses without dedicated bioinformatics will benefit from using &lt;a href=&#34;https://bigomics.ch/&#34; target=&#34;_blank&#34;&gt;Omics Playground&lt;/a&gt;. Omics Playground may also successfully free up the valuable time of bioinformaticians, allowing them to focus on more critical exploratory work for businesses with limited bioinformatics resources. In turn, wet biologists are thus free to explore data in more depth, eventually increasing the speed and effectiveness of data processing procedures.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to use 1d convolutional neural network (conv1d) to predict DNA sequence binding to protein</title>
      <link>/post/how-to-use-1d-convolutional-neural-network-conv1d-to-predict-dna-sequence-binding-to-protein/</link>
      <pubDate>Sat, 09 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-use-1d-convolutional-neural-network-conv1d-to-predict-dna-sequence-binding-to-protein/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In the mysterious world of DNA, where the secrets of life are encoded, scientists are harnessing the power of cutting-edge technology to decipher the language of genes. One of the remarkable tools they’re using is the 1D Convolutionary Neural Network, or 1D CNN, which might sound like jargon from a sci-fi movie, but it’s actually a game-changer in DNA sequence analysis.&lt;/p&gt;
&lt;p&gt;Imagine DNA as a long, intricate string of letters, like a never-ending alphabet book. Each letter holds a unique piece of information that dictates our traits and characteristics. Understanding this code is crucial for unraveling genetic mysteries, detecting diseases, and even designing personalized medicine.&lt;/p&gt;
&lt;p&gt;In this blog post, I will walk you through an example to predict DNA sequences binding to proteins using 1D CNN.&lt;/p&gt;
&lt;p&gt;The original dataset is described in this paper &lt;a href=&#34;https://www.nature.com/articles/s41588-018-0295-5&#34;&gt;A primer on deep learning in genomics&lt;/a&gt; and the python implementation can be found at:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/abidlabs/deep-learning-genomics-primer/tree/master&#34; class=&#34;uri&#34;&gt;https://github.com/abidlabs/deep-learning-genomics-primer/tree/master&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We will use simulated data that consists of DNA sequences of length 50 bases (chosen to be artificially short so that the data is easy to play around with), and is labeled with 0 or 1 depending on the result of the assay. Our goal is to build a classifier that can predict whether a particular sequence will bind to the protein and discover the short motif that is the binding site in the sequences that are bound to the protein.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We will follow it from the paper:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/primer_dl.png&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(keras)
library(reticulate)
library(ggplot2)
use_condaenv(&amp;quot;r-reticulate&amp;quot;)
library(readr)
library(tictoc) #monitoring the time

# Set a random seed in R to make it more reproducible 
set.seed(123)

# Set the seed for Keras/TensorFlow
tensorflow::set_random_seed(123)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;SEQUENCES_URL&amp;lt;-  &amp;#39;https://raw.githubusercontent.com/abidlabs/deep-learning-genomics-primer/master/sequences.txt&amp;#39;

LABELS_URL&amp;lt;-  &amp;#39;https://raw.githubusercontent.com/abidlabs/deep-learning-genomics-primer/master/labels.txt&amp;#39;

sequences&amp;lt;- read_tsv(SEQUENCES_URL, col_names = FALSE)
labels&amp;lt;- read_tsv(LABELS_URL, col_names = FALSE)

head(sequences)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 6 × 1
#&amp;gt;   X1                                                
#&amp;gt;   &amp;lt;chr&amp;gt;                                             
#&amp;gt; 1 CCGAGGGCTATGGTTTGGAAGTTAGAACCCTGGGGCTTCTCGCGGACACC
#&amp;gt; 2 GAGTTTATATGGCGCGAGCCTAGTGGTTTTTGTACTTGTTTGTCGCGTCG
#&amp;gt; 3 GATCAGTAGGGAAACAAACAGAGGGCCCAGCCACATCTAGCAGGTAGCCT
#&amp;gt; 4 GTCCACGACCGAACTCCCACCTTGACCGCAGAGGTACCACCAGAGCCCTG
#&amp;gt; 5 GGCGACCGAACTCCAACTAGAACCTGCATAACTGGCCTGGGAGATATGGT
#&amp;gt; 6 AGACATTGTCAGAACTTAGTGTGCGCCGCACTGAGCGACCGAACTCCGAC&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(labels)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 6 × 1
#&amp;gt;      X1
#&amp;gt;   &amp;lt;dbl&amp;gt;
#&amp;gt; 1     0
#&amp;gt; 2     0
#&amp;gt; 3     0
#&amp;gt; 4     1
#&amp;gt; 5     1
#&amp;gt; 6     1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nrow(sequences)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 2000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sequences&amp;lt;- sequences$X1
labels&amp;lt;- labels$X1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One-hot encoding for the DNA sequences.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one_hot_encode_dna &amp;lt;- function(sequence) {
  # Define a dictionary for mapping nucleotides to one-hot encoding
  # no dictionary/hash in R, use list 
  nucleotide_dict &amp;lt;- list(A = c(1, 0, 0, 0),
                       T = c(0, 1, 0, 0),
                       C = c(0, 0, 1, 0),
                       G = c(0, 0, 0, 1))
  
  # Split the sequence into individual nucleotides
  nucleotides &amp;lt;- unlist(strsplit(sequence, &amp;quot;&amp;quot;))
  
  # Initialize an empty matrix to store the one-hot encoding
  one_hot_matrix &amp;lt;- matrix(0, nrow = length(nucleotides), ncol = 4)
  
  # Fill the one-hot matrix based on the sequence
  for (i in 1:length(nucleotides)) {
    one_hot_matrix[i,] &amp;lt;- nucleotide_dict[[nucleotides[i]]]
  }
  
  return(one_hot_matrix)
}



# Perform one-hot encoding
one_hot_matrix &amp;lt;- one_hot_encode_dna(sequences[1])

# Print the one-hot encoded matrix
print(one_hot_matrix)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;       [,1] [,2] [,3] [,4]
#&amp;gt;  [1,]    0    0    1    0
#&amp;gt;  [2,]    0    0    1    0
#&amp;gt;  [3,]    0    0    0    1
#&amp;gt;  [4,]    1    0    0    0
#&amp;gt;  [5,]    0    0    0    1
#&amp;gt;  [6,]    0    0    0    1
#&amp;gt;  [7,]    0    0    0    1
#&amp;gt;  [8,]    0    0    1    0
#&amp;gt;  [9,]    0    1    0    0
#&amp;gt; [10,]    1    0    0    0
#&amp;gt; [11,]    0    1    0    0
#&amp;gt; [12,]    0    0    0    1
#&amp;gt; [13,]    0    0    0    1
#&amp;gt; [14,]    0    1    0    0
#&amp;gt; [15,]    0    1    0    0
#&amp;gt; [16,]    0    1    0    0
#&amp;gt; [17,]    0    0    0    1
#&amp;gt; [18,]    0    0    0    1
#&amp;gt; [19,]    1    0    0    0
#&amp;gt; [20,]    1    0    0    0
#&amp;gt; [21,]    0    0    0    1
#&amp;gt; [22,]    0    1    0    0
#&amp;gt; [23,]    0    1    0    0
#&amp;gt; [24,]    1    0    0    0
#&amp;gt; [25,]    0    0    0    1
#&amp;gt; [26,]    1    0    0    0
#&amp;gt; [27,]    1    0    0    0
#&amp;gt; [28,]    0    0    1    0
#&amp;gt; [29,]    0    0    1    0
#&amp;gt; [30,]    0    0    1    0
#&amp;gt; [31,]    0    1    0    0
#&amp;gt; [32,]    0    0    0    1
#&amp;gt; [33,]    0    0    0    1
#&amp;gt; [34,]    0    0    0    1
#&amp;gt; [35,]    0    0    0    1
#&amp;gt; [36,]    0    0    1    0
#&amp;gt; [37,]    0    1    0    0
#&amp;gt; [38,]    0    1    0    0
#&amp;gt; [39,]    0    0    1    0
#&amp;gt; [40,]    0    1    0    0
#&amp;gt; [41,]    0    0    1    0
#&amp;gt; [42,]    0    0    0    1
#&amp;gt; [43,]    0    0    1    0
#&amp;gt; [44,]    0    0    0    1
#&amp;gt; [45,]    0    0    0    1
#&amp;gt; [46,]    1    0    0    0
#&amp;gt; [47,]    0    0    1    0
#&amp;gt; [48,]    1    0    0    0
#&amp;gt; [49,]    0    0    1    0
#&amp;gt; [50,]    0    0    1    0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Do it for all the sequences&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dna_data&amp;lt;- purrr::map(sequences, one_hot_encode_dna)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;dna_data&lt;/code&gt; is a list of matrix, each entry is one DNA sequence&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dna_data[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;       [,1] [,2] [,3] [,4]
#&amp;gt;  [1,]    0    0    1    0
#&amp;gt;  [2,]    0    0    1    0
#&amp;gt;  [3,]    0    0    0    1
#&amp;gt;  [4,]    1    0    0    0
#&amp;gt;  [5,]    0    0    0    1
#&amp;gt;  [6,]    0    0    0    1
#&amp;gt;  [7,]    0    0    0    1
#&amp;gt;  [8,]    0    0    1    0
#&amp;gt;  [9,]    0    1    0    0
#&amp;gt; [10,]    1    0    0    0
#&amp;gt; [11,]    0    1    0    0
#&amp;gt; [12,]    0    0    0    1
#&amp;gt; [13,]    0    0    0    1
#&amp;gt; [14,]    0    1    0    0
#&amp;gt; [15,]    0    1    0    0
#&amp;gt; [16,]    0    1    0    0
#&amp;gt; [17,]    0    0    0    1
#&amp;gt; [18,]    0    0    0    1
#&amp;gt; [19,]    1    0    0    0
#&amp;gt; [20,]    1    0    0    0
#&amp;gt; [21,]    0    0    0    1
#&amp;gt; [22,]    0    1    0    0
#&amp;gt; [23,]    0    1    0    0
#&amp;gt; [24,]    1    0    0    0
#&amp;gt; [25,]    0    0    0    1
#&amp;gt; [26,]    1    0    0    0
#&amp;gt; [27,]    1    0    0    0
#&amp;gt; [28,]    0    0    1    0
#&amp;gt; [29,]    0    0    1    0
#&amp;gt; [30,]    0    0    1    0
#&amp;gt; [31,]    0    1    0    0
#&amp;gt; [32,]    0    0    0    1
#&amp;gt; [33,]    0    0    0    1
#&amp;gt; [34,]    0    0    0    1
#&amp;gt; [35,]    0    0    0    1
#&amp;gt; [36,]    0    0    1    0
#&amp;gt; [37,]    0    1    0    0
#&amp;gt; [38,]    0    1    0    0
#&amp;gt; [39,]    0    0    1    0
#&amp;gt; [40,]    0    1    0    0
#&amp;gt; [41,]    0    0    1    0
#&amp;gt; [42,]    0    0    0    1
#&amp;gt; [43,]    0    0    1    0
#&amp;gt; [44,]    0    0    0    1
#&amp;gt; [45,]    0    0    0    1
#&amp;gt; [46,]    1    0    0    0
#&amp;gt; [47,]    0    0    1    0
#&amp;gt; [48,]    1    0    0    0
#&amp;gt; [49,]    0    0    1    0
#&amp;gt; [50,]    0    0    1    0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The input of the 1D convolutionary neural network is a 3D tensor (sample, time, feature).
In this case, it will be (sample, position_in_DNA_sequence, 4_DNA_bases/A,T,C,G).&lt;/p&gt;
&lt;p&gt;It can be confusing because R and python fill in the matrix in column-wise and row-wise manner, respectively.&lt;/p&gt;
&lt;p&gt;read my previous blog post on tensor reshaping in &lt;code&gt;R&lt;/code&gt;: &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/basic-tensor-array-manipulations-in-r/&#34; class=&#34;uri&#34;&gt;https://divingintogeneticsandgenomics.com/post/basic-tensor-array-manipulations-in-r/&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dna_data_tensor&amp;lt;- array_reshape(lapply(dna_data, 
                                       function(x) x %&amp;gt;%t() %&amp;gt;% c()) %&amp;gt;% unlist(),
                                dim = c(2000, 50, 4))

# the first entry
# dna_data_tensor[1,,]

all.equal(dna_data[[1]], dna_data_tensor[1,,])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Split training set and testing set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# save 25% for testing
testing_len&amp;lt;- length(dna_data)*0.25

test_index&amp;lt;- sample(1:length(dna_data), testing_len)

train_x&amp;lt;- dna_data_tensor[-test_index,,]
train_y&amp;lt;- labels[-test_index]

test_x&amp;lt;- dna_data_tensor[test_index,, ]
test_y&amp;lt;- labels[test_index]

dim(train_x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 1500   50    4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(test_x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 500  50   4&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;d-convolutionary-neural-network&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;1D convolutionary neural network&lt;/h3&gt;
&lt;p&gt;2D convolutions, which involved extracting 2D patches from image tensors and applying the same transformation to each patch. Similarly, you can employ 1D convolutions to extract local 1D patches or subsequences from sequences, as illustrated below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/conv1d.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Image from &lt;a href=&#34;https://www.manning.com/books/deep-learning-with-r&#34;&gt;Deep Learning with R&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;These 1D convolution layers excel at recognizing local patterns within a sequence. Since they apply the same transformation to every patch, a pattern learned at one position in a sequence can subsequently be identified at a different location. This property enables 1D convolutional networks with DNA motif recognition.&lt;/p&gt;
&lt;p&gt;For example, when processing sequences of DNA using 1D convolutions with a window size of 5, the network should be capable of learning motifs or DNA fragments of up to 5 characters in length. Moreover, it can recognize these words in any context within an input sequence.&lt;/p&gt;
&lt;p&gt;Spoiler alert: the true regulatory motif is &lt;code&gt;CGACCGAACTCC&lt;/code&gt; which is 12 bases in length in the dataset.&lt;/p&gt;
&lt;p&gt;That’s why we choose the &lt;code&gt;kernal_size&lt;/code&gt; to 12. Again, understanding the biology is key. If you know the motifs that you are trying to find, you can feed the conv1D the right parameters.&lt;/p&gt;
&lt;p&gt;If you want to understand more on the 2D convolutionary neural network on &lt;code&gt;filters&lt;/code&gt; and &lt;code&gt;max pooling&lt;/code&gt;, read my previous &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/how-to-classify-mnist-images-with-convolutional-neural-network/&#34;&gt;blog post&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model&amp;lt;- keras_model_sequential() %&amp;gt;%
  layer_conv_1d(filters = 32, kernel_size = 12, activation = &amp;quot;relu&amp;quot;,
                input_shape = c(50, 4)) %&amp;gt;%
  layer_max_pooling_1d(pool_size = 4) %&amp;gt;%
  layer_flatten() %&amp;gt;%
  layer_dense(units = 16, activation = &amp;quot;relu&amp;quot;) %&amp;gt;%
  layer_dense(units = 1, activation= &amp;quot;sigmoid&amp;quot;)

summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Model: &amp;quot;sequential&amp;quot;
#&amp;gt; ________________________________________________________________________________
#&amp;gt; Layer (type)                        Output Shape                    Param #     
#&amp;gt; ================================================================================
#&amp;gt; conv1d (Conv1D)                     (None, 39, 32)                  1568        
#&amp;gt; ________________________________________________________________________________
#&amp;gt; max_pooling1d (MaxPooling1D)        (None, 9, 32)                   0           
#&amp;gt; ________________________________________________________________________________
#&amp;gt; flatten (Flatten)                   (None, 288)                     0           
#&amp;gt; ________________________________________________________________________________
#&amp;gt; dense_1 (Dense)                     (None, 16)                      4624        
#&amp;gt; ________________________________________________________________________________
#&amp;gt; dense (Dense)                       (None, 1)                       17          
#&amp;gt; ================================================================================
#&amp;gt; Total params: 6,209
#&amp;gt; Trainable params: 6,209
#&amp;gt; Non-trainable params: 0
#&amp;gt; ________________________________________________________________________________&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compile the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model %&amp;gt;% compile(
        optimizer = &amp;quot;rmsprop&amp;quot;,
        loss = &amp;quot;binary_crossentropy&amp;quot;,
        metrics = c(&amp;quot;accuracy&amp;quot;)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;training&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;history&amp;lt;- model %&amp;gt;%
  fit(
    train_x, train_y,
    epochs = 10,
    batch_size = 32,
    validation_split = 0.2
  )

plot(history)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-09-09-how-to-use-1d-convolutional-neural-network-conv1d-to-predict-dna-sequence-binding-to-protein_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;train on full dataset&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model %&amp;gt;%
        fit(train_x, train_y, epochs = 10, batch_size = 32)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;validation on testing data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;metrics&amp;lt;- model %&amp;gt;% 
  evaluate(test_x, test_y)

metrics&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;       loss   accuracy 
#&amp;gt; 0.01939072 0.99199998&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res&amp;lt;- predict(model, test_x) %&amp;gt;%
        dplyr::bind_cols(test_y)

colnames(res)&amp;lt;- c(&amp;quot;prob&amp;quot;, &amp;quot;label&amp;quot;)

threshold &amp;lt;- 0.5
res&amp;lt;- res %&amp;gt;%
  dplyr::mutate(.pred_class = ifelse(prob &amp;gt;= threshold, 1, 0)) %&amp;gt;%
  dplyr::mutate(.pred_class = factor(.pred_class)) %&amp;gt;%
  dplyr::mutate(label = factor(label))

library(tidymodels)
accuracy(res, truth = label, estimate = .pred_class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 1 × 3
#&amp;gt;   .metric  .estimator .estimate
#&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
#&amp;gt; 1 accuracy binary         0.992&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res %&amp;gt;% conf_mat(truth = label, estimate = .pred_class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           Truth
#&amp;gt; Prediction   0   1
#&amp;gt;          0 260   2
#&amp;gt;          1   2 236&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this simple example, the &lt;code&gt;conv_1d&lt;/code&gt; only made 4 mistakes among the 500 testing DNA sequences with an accuracy of ~99%. That’s pretty impressive.&lt;/p&gt;
&lt;p&gt;We can also add another layer of &lt;code&gt;conv_1d&lt;/code&gt; and &lt;code&gt;max_pool&lt;/code&gt; again. The architecture of a deep neural network is an art.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;random-forest&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;random forest&lt;/h3&gt;
&lt;p&gt;In this paper &lt;a href=&#34;https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009803&#34;&gt;Ten quick tips for deep learning in biology&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tip 1: Decide whether deep learning is appropriate for your problem&lt;/li&gt;
&lt;li&gt;Tip 2: Use traditional methods to establish performance baselines&lt;/li&gt;
&lt;li&gt;Tip 3: Understand the complexities of training deep neural networks&lt;/li&gt;
&lt;li&gt;Tip 4: Know your data and your question&lt;/li&gt;
&lt;li&gt;Tip 5: Choose an appropriate data representation and neural network architecture&lt;/li&gt;
&lt;li&gt;Tip 6: Tune your hyperparameters extensively and systematically&lt;/li&gt;
&lt;li&gt;Tip 7: Address deep neural networks’ increased tendency to overfit the dataset&lt;/li&gt;
&lt;li&gt;Tip 8: Deep learning models can be made more transparent&lt;/li&gt;
&lt;li&gt;Tip 9: Don’t over interpret predictions&lt;/li&gt;
&lt;li&gt;Tip 10: Actively consider the ethical implications of your work&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Regression based methods and random forest are always my go-to baseline machine learning approach.
Let’s see how random forest perform for this problem.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidymodels)

dim(train_x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 1500   50    4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# flatten the 50x4 matrix to a single vector
data_train&amp;lt;- array_reshape(train_x, dim = c(1500, 50*4))

dim(data_train)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 1500  200&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colnames(data_train)&amp;lt;- paste0(&amp;quot;feature&amp;quot;, 1:200)

data_train[1:5, 1:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      feature1 feature2 feature3 feature4 feature5
#&amp;gt; [1,]        0        0        1        0        0
#&amp;gt; [2,]        0        0        0        1        1
#&amp;gt; [3,]        0        0        0        1        1
#&amp;gt; [4,]        0        0        0        1        0
#&amp;gt; [5,]        0        0        0        1        0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# turn the label to a factor so tidymodel knows it is a classification problem
data_train&amp;lt;- bind_cols(as.data.frame(data_train), label = train_y %&amp;gt;%
        as.factor())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;do the same for the testing data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_test&amp;lt;- array_reshape(test_x, dim = c(500, 50*4))
colnames(data_test)&amp;lt;- paste0(&amp;quot;feature&amp;quot;, 1:200)
data_test&amp;lt;- bind_cols(as.data.frame(data_test), label = test_y %&amp;gt;%
        as.factor())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;build the model using &lt;code&gt;tidymodels&lt;/code&gt;. PS, read &lt;a href=&#34;https://www.tmwr.org/&#34;&gt;Tidy Modeling with R&lt;/a&gt; for FREE.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic()
rf_recipe &amp;lt;- 
  recipe(formula = label ~ ., data = data_train)

## feature importance sore to TRUE, one can tune the trees and mtry 
rf_spec &amp;lt;- rand_forest() %&amp;gt;%
  set_engine(&amp;quot;randomForest&amp;quot;, importance = TRUE) %&amp;gt;%
  set_mode(&amp;quot;classification&amp;quot;)

rf_workflow &amp;lt;- workflow() %&amp;gt;% 
  add_recipe(rf_recipe) %&amp;gt;% 
  add_model(rf_spec)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;train the model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rf_fit &amp;lt;- fit(rf_workflow, data = data_train)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;test the model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res&amp;lt;- predict(rf_fit, new_data = data_test) %&amp;gt;%
        bind_cols(data_test %&amp;gt;% select(label)) 

toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 24.129 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;what’s the accuracy?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;accuracy(res, truth = label, estimate = .pred_class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 1 × 3
#&amp;gt;   .metric  .estimator .estimate
#&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
#&amp;gt; 1 accuracy binary         0.826&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## confusion matrix,
res %&amp;gt;% conf_mat(truth = label, estimate = .pred_class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;           Truth
#&amp;gt; Prediction   0   1
#&amp;gt;          0 207  32
#&amp;gt;          1  55 206&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An accuracy of this un-tuned random forest model gives ~82% accuracy. This is much worse than the &lt;code&gt;conv1d&lt;/code&gt; model and is slower. This demonstrate where the deep learning models shine in sequence analysis.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Long Short-term memory (LSTM) Recurrent Neural Network (RNN) to classify movie reviews </title>
      <link>/post/long-short-term-memory-lstm-recurrent-neural-network-rnn-to-classify-movie-reviews/</link>
      <pubDate>Sun, 03 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/long-short-term-memory-lstm-recurrent-neural-network-rnn-to-classify-movie-reviews/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/vembedr/css/vembedr.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;p&gt;A major characteristic of all neural networks I have used so far, such as densely connected networks and convnets (CNN) (see my previous &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/how-to-classify-mnist-images-with-convolutional-neural-network/&#34;&gt;post&lt;/a&gt;), is that they have no memory. Each input shown to them is processed independently, with no state kept in between inputs. In other words, they do not take into the context of the words (the words around the word).&lt;/p&gt;
&lt;p&gt;Imagine you’re reading a book, and you want to understand the story by keeping track of what’s happening in the plot. Your brain naturally remembers information from the beginning of the book even as you read through new chapters. It’s like having a special memory that can remember important details from the past.&lt;/p&gt;
&lt;p&gt;Long short-term memory (LSTM) is like that special memory for computers when they’re working with text or sequences of data. In regular computer programs, information can easily get lost as the program processes new data. But LSTM is designed to remember important stuff from the past, just like your brain when reading a book.&lt;/p&gt;
&lt;p&gt;I highly recommend Josh Starmer’s video on Long short-term memory to understand the math behind it.&lt;/p&gt;
&lt;div class=&#34;vembedr&#34;&gt;
&lt;div&gt;
&lt;iframe src=&#34;https://www.youtube.com/embed/YCzL96nL7j0&#34; width=&#34;533&#34; height=&#34;300&#34; frameborder=&#34;0&#34; allowfullscreen=&#34;&#34; data-external=&#34;1&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Load the libraries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(keras)
library(reticulate)
library(ggplot2)
use_condaenv(&amp;quot;r-reticulate&amp;quot;)

# Set a random seed in R to make it more reproducible 
set.seed(123)

# Set the seed for Keras/TensorFlow
tensorflow::set_random_seed(123)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s use the &lt;code&gt;IMDB&lt;/code&gt; movie-review sentiment-prediction dataset for demonstration again.&lt;/p&gt;
&lt;p&gt;It is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews need to be preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer “3” encodes the 3rd most frequent word in the data. Read my previous &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/understand-word-embedding-and-use-deep-learning-to-classify-movie-reviews/&#34;&gt;post on word embedding&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Download the data from &lt;a href=&#34;http://mng.bz/0tIo&#34; class=&#34;uri&#34;&gt;http://mng.bz/0tIo&lt;/a&gt; and unzip it.&lt;/p&gt;
&lt;p&gt;read the reviews (text files) into R for the training set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imdb_dir&amp;lt;- &amp;quot;~/blog_data/aclImdb&amp;quot;
train_dir&amp;lt;- file.path(imdb_dir, &amp;quot;train&amp;quot;)
labels&amp;lt;- c()
texts&amp;lt;- c()

for (label_type in c(&amp;quot;neg&amp;quot;, &amp;quot;pos&amp;quot;)){
  label&amp;lt;- switch(label_type, neg = 0, pos = 1)
  dir_name&amp;lt;- file.path(train_dir, label_type)
  for (fname in list.files(dir_name, pattern = glob2rx(&amp;quot;*txt&amp;quot;),
                           full.names = TRUE)){
    texts&amp;lt;- c(texts, readChar(fname, file.info(fname)$size))
    labels&amp;lt;- c(labels, label)
  }
}


length(labels)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 25000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(texts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 25000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the first review 
texts[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it&amp;#39;s singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it&amp;#39;s better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tokenize the data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;maxlen&amp;lt;- 100
max_words&amp;lt;- 10000

tokenizer&amp;lt;- text_tokenizer(num_words = max_words) %&amp;gt;%
  fit_text_tokenizer(texts)

tokenizer$num_words&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 10000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tokenizer$word_index[1:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; $the
#&amp;gt; [1] 1
#&amp;gt; 
#&amp;gt; $and
#&amp;gt; [1] 2
#&amp;gt; 
#&amp;gt; $a
#&amp;gt; [1] 3
#&amp;gt; 
#&amp;gt; $of
#&amp;gt; [1] 4
#&amp;gt; 
#&amp;gt; $to
#&amp;gt; [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;word_index&amp;lt;- tokenizer$word_index

sequences&amp;lt;- texts_to_sequences(tokenizer, texts)

## first review turned into integers
sequences[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;   [1]   62    4    3  129   34   44 7576 1414   15    3 4252  514   43   16    3
#&amp;gt;  [16]  633  133   12    6    3 1301  459    4 1751  209    3 7693  308    6  676
#&amp;gt;  [31]   80   32 2137 1110 3008   31    1  929    4   42 5120  469    9 2665 1751
#&amp;gt;  [46]    1  223   55   16   54  828 1318  847  228    9   40   96  122 1484   57
#&amp;gt;  [61]  145   36    1  996  141   27  676  122    1  411   59   94 2278  303  772
#&amp;gt;  [76]    5    3  837   20    3 1755  646   42  125   71   22  235  101   16   46
#&amp;gt;  [91]   49  624   31  702   84  702  378 3493    2 8422   67   27  107 3348&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x_train&amp;lt;- pad_sequences(sequences, maxlen = maxlen)

## it becomes a 2D matrix of samples x max_words
dim(x_train)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 25000   100&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y_train&amp;lt;- as.array(labels)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Do the same thing for the test dataset&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test_dir&amp;lt;- file.path(imdb_dir, &amp;quot;test&amp;quot;)
labels&amp;lt;- c()
texts&amp;lt;- c()

for (label_type in c(&amp;quot;neg&amp;quot;, &amp;quot;pos&amp;quot;)){
  label&amp;lt;- switch(label_type, neg = 0, pos = 1)
  dir_name&amp;lt;- file.path(test_dir, label_type)
  for (fname in list.files(dir_name, pattern = glob2rx(&amp;quot;*.txt&amp;quot;), 
                           full.names = TRUE)){
    texts&amp;lt;- c(texts, readChar(fname, file.info(fname)$size))
    labels&amp;lt;- c(labels, label)
  }
}

sequences&amp;lt;- texts_to_sequences(tokenizer, texts)
x_test&amp;lt;- pad_sequences(sequences, maxlen = maxlen)
y_test&amp;lt;- as.array(labels)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s consider adding a LSTM layer. The underlying Long Short-Term Memory (LSTM) algorithm was developed by Hochreiter and Schmidhuber in 1997; it was the culmination of their research on the &lt;a href=&#34;https://en.wikipedia.org/wiki/Vanishing_gradient_problem&#34;&gt;vanishing gradient problem&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- keras_model_sequential() %&amp;gt;%
  layer_embedding(input_dim = max_words + 1, output_dim = 32) %&amp;gt;%
  layer_lstm(units = 32) %&amp;gt;%
  layer_dense(units = 1, activation = &amp;quot;sigmoid&amp;quot;)

model %&amp;gt;% compile(
  optimizer = &amp;quot;rmsprop&amp;quot;,
  loss = &amp;quot;binary_crossentropy&amp;quot;,
  metrics = c(&amp;quot;acc&amp;quot;)
)

summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Model: &amp;quot;sequential&amp;quot;
#&amp;gt; ________________________________________________________________________________
#&amp;gt; Layer (type)                        Output Shape                    Param #     
#&amp;gt; ================================================================================
#&amp;gt; embedding (Embedding)               (None, None, 32)                320032      
#&amp;gt; ________________________________________________________________________________
#&amp;gt; lstm (LSTM)                         (None, 32)                      8320        
#&amp;gt; ________________________________________________________________________________
#&amp;gt; dense (Dense)                       (None, 1)                       33          
#&amp;gt; ================================================================================
#&amp;gt; Total params: 328,385
#&amp;gt; Trainable params: 328,385
#&amp;gt; Non-trainable params: 0
#&amp;gt; ________________________________________________________________________________&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;history &amp;lt;- model %&amp;gt;% fit(
  x_train, y_train,
  epochs = 10,
  batch_size = 128,
  validation_split = 0.2
)

plot(history)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-09-03-long-short-term-memory-lstm-recurrent-neural-network-rnn-to-classify-movie-reviews_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# train on the full dataset
model %&amp;gt;%
        fit(x_train, y_train, epochs = 7, batch_size = 32)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;evaluate the model on the testing data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;metrics&amp;lt;- model %&amp;gt;% 
  evaluate(x_test, y_test)

metrics&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      loss       acc 
#&amp;gt; 0.4781031 0.8294800&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;~84% accuracy. It is a little better than the fully connected approach in &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/understand-word-embedding-and-use-deep-learning-to-classify-movie-reviews/&#34;&gt;my last post&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;take-home-messages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Take-home messages&lt;/h3&gt;
&lt;p&gt;I was expecting the accuracy to be even higher with such a computation intensive LSTM.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;We didn’t fine-tune some settings&lt;/strong&gt;: One reason our approach didn’t work extremely well could be that we didn’t adjust certain settings like how we represent words or the complexity of our model.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;We didn’t use some techniques to prevent overfitting&lt;/strong&gt;: Another reason could be that we didn’t use methods to prevent our model from memorizing the data it saw, which can lead to poor generalization.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The main reason&lt;/strong&gt;: But honestly, the biggest reason is that for this specific task of figuring out if a review is positive or negative, we don’t really need to look at the big picture of the entire review. We can do a good job just by counting how often certain words appear in the review. That’s what our previous approach did.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;LSTM shines in tougher tasks&lt;/strong&gt;: However, there are more challenging tasks in language processing where LSTM, a type of neural network, shows its strengths. For example, when answering complex questions or translating languages, LSTM can be a valuable tool because it’s good at understanding the context and relationships between words in long pieces of text. So, while it might not be necessary for simple sentiment analysis, it becomes really useful in more complicated language tasks.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Bottom line&lt;/strong&gt; : choosing the right method for the right problem is more important than the complexity of the method. In fact, I always prefer simpler method first (e.g, regression, random forest etc) because they are more intepretable.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How To Switch From Wet-Lab To Dry-Lab? Tips for single cell scientists</title>
      <link>/talk/2023-transform/</link>
      <pubDate>Sat, 02 Sep 2023 12:00:00 -0400</pubDate>
      
      <guid>/talk/2023-transform/</guid>
      <description>&lt;p&gt;This episode isn&amp;rsquo;t about methods or technology; it&amp;rsquo;s about inspiring scientists around the #singlecell world.
Listen to 🎯 Ming &amp;ldquo;Tommy&amp;rdquo; Tang&amp;rsquo;s story and let it inspire you.
It might just sparkle ✨ a transformation in your own scientific journey!&lt;/p&gt;

&lt;p&gt;In this episode, Dr. Ming “Tommy” Tang shares his story of changing from hands-on lab work to computer-based research. Tommy talks about the steps, challenges, and skills he learned along the way. Plus, find out how he got so many followers on X!&lt;/p&gt;

&lt;p&gt;This episode is not about methods or technology; it&amp;rsquo;s about inspiring people in the single-cell research world. Give it a listen and get inspired by Tommy’s story. It can be a change in your own science journey!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Understand word embedding and use deep learning to classify movie reviews</title>
      <link>/post/understand-word-embedding-and-use-deep-learning-to-classify-movie-reviews/</link>
      <pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/understand-word-embedding-and-use-deep-learning-to-classify-movie-reviews/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Picture this: a computer that can actually grasp the emotions hidden in movie reviews – sensing whether they’re shouting with joy or grumbling in disappointment. This mind-bending capability comes from two incredible technologies: deep learning and word embedding. But don’t worry if these sound like jargon; I am here to unravel the mystery.&lt;/p&gt;
&lt;p&gt;Think of deep learning as a supercharged brain for computers. Just like we learn from experience, computers learn from data. Word embedding, on the other hand, is like converting words into a language computers understand – numbers! It’s like teaching your dog to respond to hand signals instead of just words.&lt;/p&gt;
&lt;p&gt;In this blog post, I am your guides on this adventure. I will show you how deep learning and word embedding join forces to train computers in deciphering the tones of movie reviews. We’re talking about those moments when the computer understands that a review saying “This movie was a rollercoaster of emotions” is positive, not about a literal amusement park.&lt;/p&gt;
&lt;p&gt;So, fasten your seatbelts. We’re about to journey into the realms of AI, exploring how machines learn, adapt, and finally crack the code of sentiments tucked within movie reviews.&lt;/p&gt;
&lt;p&gt;Load the libraries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(keras)
library(reticulate)
library(ggplot2)
use_condaenv(&amp;quot;r-reticulate&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Computers do not understand text. Let’s turn it into numeric vectors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;samples&amp;lt;- c(&amp;quot;The cat sat on the mat.&amp;quot;, &amp;quot;The dog ate my homework.&amp;quot;)

tokenizer&amp;lt;- text_tokenizer(num_words = 1000) %&amp;gt;%
  fit_text_tokenizer(samples)

sequences&amp;lt;- texts_to_sequences(tokenizer, samples)

one_hot_results&amp;lt;- texts_to_matrix(tokenizer, samples, mode= &amp;quot;binary&amp;quot;)

one_hot_results[1:2, 1:20]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]
#&amp;gt; [1,]    0    1    1    1    1    1    0    0    0     0     0     0     0     0
#&amp;gt; [2,]    0    1    0    0    0    0    1    1    1     1     0     0     0     0
#&amp;gt;      [,15] [,16] [,17] [,18] [,19] [,20]
#&amp;gt; [1,]     0     0     0     0     0     0
#&amp;gt; [2,]     0     0     0     0     0     0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;word_index&amp;lt;- tokenizer$word_index&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s use the &lt;code&gt;IMDB&lt;/code&gt; movie-review sentiment-prediction dataset for demonstration.&lt;/p&gt;
&lt;p&gt;Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer “3” encodes the 3rd most frequent word in the data.&lt;/p&gt;
&lt;p&gt;Download the data from &lt;a href=&#34;http://mng.bz/0tIo&#34; class=&#34;uri&#34;&gt;http://mng.bz/0tIo&lt;/a&gt; and unzip it.&lt;/p&gt;
&lt;p&gt;read the reviews (text files) into R for the training set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imdb_dir&amp;lt;- &amp;quot;~/blog_data/aclImdb&amp;quot;
train_dir&amp;lt;- file.path(imdb_dir, &amp;quot;train&amp;quot;)
labels&amp;lt;- c()
texts&amp;lt;- c()

for (label_type in c(&amp;quot;neg&amp;quot;, &amp;quot;pos&amp;quot;)){
  label&amp;lt;- switch(label_type, neg = 0, pos = 1)
  dir_name&amp;lt;- file.path(train_dir, label_type)
  for (fname in list.files(dir_name, pattern = glob2rx(&amp;quot;*txt&amp;quot;),
                           full.names = TRUE)){
    texts&amp;lt;- c(texts, readChar(fname, file.info(fname)$size))
    labels&amp;lt;- c(labels, label)
  }
}


length(labels)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 25000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(texts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 25000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the first review 
texts[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it&amp;#39;s singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it&amp;#39;s better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tokenize the data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;maxlen&amp;lt;- 100
max_words&amp;lt;- 10000

tokenizer&amp;lt;- text_tokenizer(num_words = max_words) %&amp;gt;%
  fit_text_tokenizer(texts)

tokenizer$num_words&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 10000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tokenizer$word_index[1:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; $the
#&amp;gt; [1] 1
#&amp;gt; 
#&amp;gt; $and
#&amp;gt; [1] 2
#&amp;gt; 
#&amp;gt; $a
#&amp;gt; [1] 3
#&amp;gt; 
#&amp;gt; $of
#&amp;gt; [1] 4
#&amp;gt; 
#&amp;gt; $to
#&amp;gt; [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;word_index&amp;lt;- tokenizer$word_index

sequences&amp;lt;- texts_to_sequences(tokenizer, texts)

## first review turned into integers
sequences[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;   [1]   62    4    3  129   34   44 7576 1414   15    3 4252  514   43   16    3
#&amp;gt;  [16]  633  133   12    6    3 1301  459    4 1751  209    3 7693  308    6  676
#&amp;gt;  [31]   80   32 2137 1110 3008   31    1  929    4   42 5120  469    9 2665 1751
#&amp;gt;  [46]    1  223   55   16   54  828 1318  847  228    9   40   96  122 1484   57
#&amp;gt;  [61]  145   36    1  996  141   27  676  122    1  411   59   94 2278  303  772
#&amp;gt;  [76]    5    3  837   20    3 1755  646   42  125   71   22  235  101   16   46
#&amp;gt;  [91]   49  624   31  702   84  702  378 3493    2 8422   67   27  107 3348&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x_train&amp;lt;- pad_sequences(sequences, maxlen = maxlen)

## it becomes a 2D matrix of samples x max_words
dim(x_train)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 25000   100&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y_train&amp;lt;- as.array(labels)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Do the same thing for the test dataset&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test_dir&amp;lt;- file.path(imdb_dir, &amp;quot;test&amp;quot;)
labels&amp;lt;- c()
texts&amp;lt;- c()

for (label_type in c(&amp;quot;neg&amp;quot;, &amp;quot;pos&amp;quot;)){
  label&amp;lt;- switch(label_type, neg = 0, pos = 1)
  dir_name&amp;lt;- file.path(test_dir, label_type)
  for (fname in list.files(dir_name, pattern = glob2rx(&amp;quot;*.txt&amp;quot;), 
                           full.names = TRUE)){
    texts&amp;lt;- c(texts, readChar(fname, file.info(fname)$size))
    labels&amp;lt;- c(labels, label)
  }
}

sequences&amp;lt;- texts_to_sequences(tokenizer, texts)
x_test&amp;lt;- pad_sequences(sequences, maxlen = maxlen)
y_test&amp;lt;- as.array(labels)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;build the model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;embedding_dim&amp;lt;- 100

# for the embedding weights matrix, index 1 is not suppose to be any word or token, it is a placeholder. that&amp;#39;s why we use tokenizer$num_words (10000) + 1 as input_dim

model&amp;lt;- keras_model_sequential() %&amp;gt;%
  layer_embedding(input_dim = tokenizer$num_words + 1, output_dim = embedding_dim, 
                  input_length = maxlen) %&amp;gt;%
  layer_flatten() %&amp;gt;%
  layer_dense(units = 32, activation = &amp;quot;relu&amp;quot;) %&amp;gt;%
  layer_dense(units = 1, activation = &amp;quot;sigmoid&amp;quot;) # for the binary classification&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;compile the model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model %&amp;gt;%
  compile(
    optimizer = &amp;quot;rmsprop&amp;quot;,
    loss = &amp;quot;binary_crossentropy&amp;quot;,
    metric = c(&amp;quot;acc&amp;quot;)
  ) 
  
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Model: &amp;quot;sequential&amp;quot;
#&amp;gt; ________________________________________________________________________________
#&amp;gt; Layer (type)                        Output Shape                    Param #     
#&amp;gt; ================================================================================
#&amp;gt; embedding (Embedding)               (None, 100, 100)                1000100     
#&amp;gt; ________________________________________________________________________________
#&amp;gt; flatten (Flatten)                   (None, 10000)                   0           
#&amp;gt; ________________________________________________________________________________
#&amp;gt; dense_1 (Dense)                     (None, 32)                      320032      
#&amp;gt; ________________________________________________________________________________
#&amp;gt; dense (Dense)                       (None, 1)                       33          
#&amp;gt; ================================================================================
#&amp;gt; Total params: 1,320,165
#&amp;gt; Trainable params: 1,320,165
#&amp;gt; Non-trainable params: 0
#&amp;gt; ________________________________________________________________________________&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The input is a tensor of 25000 (sample) x 100 (maxlen) dimension, the embedding layer is a 3D tensor of 25000(sample) x 100 (sequence_length) x 100 (embedding_dim) dimension;&lt;/p&gt;
&lt;p&gt;it then flatten to a vector of length 100 x100 = 10000, and then connect to a dense layer of 32 units, and then connected with a dense layer of unit 1 with sigmoid activation function for prediction.&lt;/p&gt;
&lt;p&gt;train the model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;history&amp;lt;- model %&amp;gt;%
  fit(
    x_train, y_train,
    epochs = 10,
    batch_size = 32,
    validation_split = 0.2
  )

plot(history)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-31-understand-word-embedding-and-use-deep-learning-to-classify-movie-reviews_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Final train&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model %&amp;gt;%
        fit(x_train, y_train, epochs = 5, batch_size = 32)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;accuracy&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;metrics&amp;lt;- model %&amp;gt;% 
  evaluate(x_test, y_test)

metrics&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;     loss      acc 
#&amp;gt; 2.314948 0.790920&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;~80% accuracy! not bad.&lt;/p&gt;
&lt;div id=&#34;understand-the-embedding&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Understand the embedding&lt;/h3&gt;
&lt;p&gt;We can get the weights of the embedding layer:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get the weights of the embedding layer
embedding_layer &amp;lt;- model$layers[[1]]  # Assuming the embedding layer is the first layer
embedding_weights &amp;lt;- embedding_layer$get_weights()[[1]]

dim(embedding_weights)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 10001   100&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;embedding_weights[1:5, 1:20]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;              [,1]         [,2]         [,3]        [,4]         [,5]
#&amp;gt; [1,] -0.038108733  0.034164231 -0.010926410 -0.01945905  0.006259503
#&amp;gt; [2,]  0.006445600 -0.005163373  0.077650383  0.02167805 -0.063152276
#&amp;gt; [3,]  0.054408096 -0.025189560  0.059026342  0.05764490 -0.099164285
#&amp;gt; [4,]  0.043150455  0.041099135  0.004985804  0.01686079 -0.062039867
#&amp;gt; [5,] -0.004684128  0.046648771 -0.008564522  0.04492320 -0.034164682
#&amp;gt;              [,6]         [,7]         [,8]        [,9]        [,10]
#&amp;gt; [1,] -0.007477300  0.008997128  0.022076523  0.01617429 -0.011652625
#&amp;gt; [2,] -0.017004006 -0.060964763 -0.006172073 -0.04898103  0.008079287
#&amp;gt; [3,] -0.002061349 -0.079386219  0.038137231 -0.05804368  0.037487414
#&amp;gt; [4,] -0.041052923 -0.008180849 -0.002805086 -0.01827856  0.018388636
#&amp;gt; [5,]  0.016365541 -0.076942243 -0.059156016 -0.07605161  0.004471917
#&amp;gt;             [,11]        [,12]        [,13]       [,14]       [,15]       [,16]
#&amp;gt; [1,]  0.006929873 -0.001043276 -0.007549608 -0.01186891  0.00502130 0.002877086
#&amp;gt; [2,]  0.006907295  0.058686450 -0.020892052 -0.02132107 -0.01123977 0.040830452
#&amp;gt; [3,] -0.007843471 -0.038126167  0.003755015  0.02115629  0.03360209 0.039373539
#&amp;gt; [4,] -0.047682714 -0.017012399 -0.029800395  0.01147485  0.02615152 0.106722914
#&amp;gt; [5,] -0.054134578  0.002277025  0.015656594 -0.02716585  0.01887219 0.063780047
#&amp;gt;            [,17]       [,18]        [,19]       [,20]
#&amp;gt; [1,] -0.01611450  0.03136891 0.0213537812  0.01389796
#&amp;gt; [2,] -0.01134415 -0.01135702 0.0154857207  0.03979484
#&amp;gt; [3,] -0.01122028 -0.04163784 0.0848641545  0.06389144
#&amp;gt; [4,] -0.08052496 -0.06622744 0.0001179522 -0.02714739
#&amp;gt; [5,]  0.04176097  0.04005887 0.0083893426  0.04704465&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The embedding weights matrix dimension is 10001 (1000 max_words + 1 placeholder) x100(embedding_dim).&lt;/p&gt;
&lt;p&gt;add the words as the rownames to the embedding matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;words &amp;lt;- data.frame(
  word = names(tokenizer$word_index), 
  id = as.integer(unlist(tokenizer$word_index))
)

words &amp;lt;- words %&amp;gt;%
  dplyr::filter(id &amp;lt;= tokenizer$num_words) %&amp;gt;%
  dplyr::arrange(id)

rownames(embedding_weights)&amp;lt;- c(&amp;quot;UNKNOWN&amp;quot;, words$word)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now find words that are close to each other in the embedding. We will use the cosine similarity:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(text2vec)

find_similar_words &amp;lt;- function(word, embedding_matrix, n = 5) {
  similarities &amp;lt;- embedding_matrix[word, , drop = FALSE] %&amp;gt;%
    sim2(embedding_matrix, y = ., method = &amp;quot;cosine&amp;quot;)
  
  similarities[,1] %&amp;gt;% sort(decreasing = TRUE) %&amp;gt;% head(n)
}


find_similar_words(&amp;quot;bad&amp;quot;, embedding_weights)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;       bad     worst     awful     waste    sucked 
#&amp;gt; 1.0000000 0.8764589 0.8717442 0.8703569 0.8615548&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;find_similar_words(&amp;quot;wonderful&amp;quot;, embedding_weights)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;   wonderful   excellent        rare     perfect excellently 
#&amp;gt;   1.0000000   0.7535562   0.7349462   0.7308548   0.7235736&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can plot the embeddings in a 2-D plot after TSNE or UMAP (just like in single-cell data analysis):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Perform t-SNE dimensionality reduction
set.seed(123)
tsne_embeddings &amp;lt;- Rtsne::Rtsne(embedding_weights)

# Create a data frame for visualization
tsne_df &amp;lt;- data.frame(
  x = tsne_embeddings$Y[, 1],
  y = tsne_embeddings$Y[, 2],
  word = rownames(embedding_weights)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Plot the t-SNE visualization&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;words_to_plot&amp;lt;- c(&amp;quot;good&amp;quot;, &amp;quot;fantastic&amp;quot;, &amp;quot;cool&amp;quot;, &amp;quot;wonderful&amp;quot;, &amp;quot;nice&amp;quot;, &amp;quot;best&amp;quot;, &amp;quot;brilliant&amp;quot;, &amp;quot;amazing&amp;quot;, &amp;quot;bad&amp;quot;, &amp;quot;horrible&amp;quot;,&amp;quot;nasty&amp;quot;, &amp;quot;poor&amp;quot;, &amp;quot;awful&amp;quot;)

ggplot(tsne_df, aes(x, y)) +
  geom_point(size = 0.2, alpha = 0.5) +
  geom_point(data = tsne_df %&amp;gt;% 
               dplyr::filter(word %in% words_to_plot), 
             color = &amp;quot;red&amp;quot;) +
  ggrepel::geom_label_repel(data = tsne_df %&amp;gt;% 
                              dplyr::filter(word %in% words_to_plot), 
                            aes(label = word ), max.overlaps = 1000) +
  theme_minimal(base_size = 13) +
  labs(title = &amp;quot;t-SNE Visualization of Word Embeddings&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-31-understand-word-embedding-and-use-deep-learning-to-classify-movie-reviews_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We do see those positive words and negative words are clustered in the same area, respectively. That’s cool!!&lt;/p&gt;
&lt;p&gt;We can also use a pre-trained word embedding weights matrix (&lt;code&gt;word2vec&lt;/code&gt; or &lt;code&gt;GloVe&lt;/code&gt;) when the training data is very small(we have 25000 data points for training, which is a lot),
e.g., if we only had 200 samples to train, using a pre-trained model can be beneficial.&lt;/p&gt;
&lt;p&gt;In my next blog post, I will try to implement the Long short-term Recurrent Neural Network (RNN) to take into the context of the word to better classify the reviews.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Most of the codes are adapted from &lt;a href=&#34;https://www.manning.com/books/deep-learning-with-r&#34;&gt;Deep Learning with R&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://rpubs.com/nabiilahardini/word2vec&#34; class=&#34;uri&#34;&gt;https://rpubs.com/nabiilahardini/word2vec&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://blogs.rstudio.com/ai/posts/2017-12-22-word-embeddings-with-keras/&#34; class=&#34;uri&#34;&gt;https://blogs.rstudio.com/ai/posts/2017-12-22-word-embeddings-with-keras/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://smltar.com/&#34;&gt;Supervised Machine Learning for Text Analysis in R&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>multi-omics data integration: a case study with transcriptomics and genomics mutation data</title>
      <link>/post/multi-omics-data-integration-a-case-study-with-transcriptomics-and-genomics-mutation-data/</link>
      <pubDate>Tue, 22 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/multi-omics-data-integration-a-case-study-with-transcriptomics-and-genomics-mutation-data/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Multi-omics data analysis is a cutting-edge approach in biology that involves studying and integrating information from multiple biological “omics” sources. These omics sources include genomics (genes and their variations), transcriptomics (gene expression and RNA data), proteomics (proteins and their interactions), metabolomics (small molecules and metabolites), epigenomics (epigenetic modifications), and more. By analyzing data from various omics levels together, we can gain a more comprehensive and detailed understanding of biological systems and their complexities.&lt;/p&gt;
&lt;p&gt;The idea behind multi-omics analysis is that biological systems are incredibly intricate, with different levels of molecules interacting and influencing each other. Traditional single-omics approaches provide valuable insights into specific aspects of these systems, but they often miss out on the bigger picture. Multi-omics analysis, on the other hand, enables scientists to uncover connections and relationships that might not be apparent when looking at individual omics data in isolation.&lt;/p&gt;
&lt;p&gt;In this blog post, I am going to show you how to integrate transcriptomics (RNA-seq) data and the genomics (DNA-seq) data using cancer cell line data from &lt;a href=&#34;https://depmap.org&#34;&gt;Depmap&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;download-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Download data&lt;/h3&gt;
&lt;p&gt;Download the gene expression and the gene mutation data from &lt;a href=&#34;https://depmap.org/portal/download/custom/&#34; class=&#34;uri&#34;&gt;https://depmap.org/portal/download/custom/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Make sure you check the box “Add cell line metadata to download”.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/depmap.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this post, let’s try to predict cancer type from the CCLE cell lines by integrating both gene expression data and the mutation data.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;ls -1 *csv
Copy_Number_Public_23Q2.csv
Damaging_Mutations.csv
Expression_Public_23Q2.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;read-in-to-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Read in to R&lt;/h3&gt;
&lt;p&gt;read in the expression data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
expression&amp;lt;- read_csv(&amp;quot;~/blog_data/Expression_Public_23Q2.csv&amp;quot;)

colnames(expression) %&amp;gt;% head(n = 15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1] &amp;quot;depmap_id&amp;quot;              &amp;quot;cell_line_display_name&amp;quot; &amp;quot;lineage_1&amp;quot;             
#&amp;gt;  [4] &amp;quot;lineage_2&amp;quot;              &amp;quot;lineage_3&amp;quot;              &amp;quot;lineage_5&amp;quot;             
#&amp;gt;  [7] &amp;quot;lineage_6&amp;quot;              &amp;quot;lineage_4&amp;quot;              &amp;quot;TSPAN6&amp;quot;                
#&amp;gt; [10] &amp;quot;TNMD&amp;quot;                   &amp;quot;DPM1&amp;quot;                   &amp;quot;SCYL3&amp;quot;                 
#&amp;gt; [13] &amp;quot;C1orf112&amp;quot;               &amp;quot;FGR&amp;quot;                    &amp;quot;CFH&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colnames(expression) %&amp;gt;% tail()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;C8orf44-SGK3&amp;quot; &amp;quot;ELOA3B&amp;quot;       &amp;quot;NPBWR1&amp;quot;       &amp;quot;ELOA3D&amp;quot;       &amp;quot;ELOA3&amp;quot;       
#&amp;gt; [6] &amp;quot;CDR1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(expression)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]  1450 19152&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;read in the mutation data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mutation&amp;lt;- read_csv(&amp;quot;~/blog_data/Damaging_Mutations.csv&amp;quot;)

head(mutation)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 6 × 16,971
#&amp;gt;   depmap_id  cell_line_displa… lineage_1 lineage_2 lineage_3 lineage_5 lineage_6
#&amp;gt;   &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;             &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;    
#&amp;gt; 1 ACH-001270 127399            Soft Tis… Synovial… Synovial… &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt;     
#&amp;gt; 2 ACH-002680 170MGBA           CNS/Brain Diffuse … Glioblas… Glioblas… &amp;lt;NA&amp;gt;     
#&amp;gt; 3 ACH-002089 201T              Lung      Non-Smal… Lung Ade… NSCLC Ad… &amp;lt;NA&amp;gt;     
#&amp;gt; 4 ACH-002399 21NT              Breast    Invasive… Breast I… &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt;     
#&amp;gt; 5 ACH-001002 451LU             Skin      Melanoma  Cutaneou… &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt;     
#&amp;gt; 6 ACH-000520 59M               Ovary/Fa… Ovarian … High-Gra… High Gra… &amp;lt;NA&amp;gt;     
#&amp;gt; # … with 16,964 more variables: lineage_4 &amp;lt;lgl&amp;gt;, A1BG &amp;lt;dbl&amp;gt;, A1CF &amp;lt;dbl&amp;gt;,
#&amp;gt; #   A2M &amp;lt;dbl&amp;gt;, A2ML1 &amp;lt;dbl&amp;gt;, A3GALT2 &amp;lt;dbl&amp;gt;, A4GALT &amp;lt;dbl&amp;gt;, A4GNT &amp;lt;dbl&amp;gt;,
#&amp;gt; #   AAAS &amp;lt;dbl&amp;gt;, AACS &amp;lt;dbl&amp;gt;, AADAC &amp;lt;dbl&amp;gt;, AADACL2 &amp;lt;dbl&amp;gt;, AADACL3 &amp;lt;dbl&amp;gt;,
#&amp;gt; #   AADACL4 &amp;lt;dbl&amp;gt;, AADAT &amp;lt;dbl&amp;gt;, AAGAB &amp;lt;dbl&amp;gt;, AAK1 &amp;lt;dbl&amp;gt;, AAMDC &amp;lt;dbl&amp;gt;,
#&amp;gt; #   AAMP &amp;lt;dbl&amp;gt;, AAR2 &amp;lt;dbl&amp;gt;, AARS1 &amp;lt;dbl&amp;gt;, AARS2 &amp;lt;dbl&amp;gt;, AASDH &amp;lt;dbl&amp;gt;,
#&amp;gt; #   AASDHPPT &amp;lt;dbl&amp;gt;, AASS &amp;lt;dbl&amp;gt;, AATF &amp;lt;dbl&amp;gt;, AATK &amp;lt;dbl&amp;gt;, ABAT &amp;lt;dbl&amp;gt;,
#&amp;gt; #   ABCA1 &amp;lt;dbl&amp;gt;, ABCA10 &amp;lt;dbl&amp;gt;, ABCA12 &amp;lt;dbl&amp;gt;, ABCA13 &amp;lt;dbl&amp;gt;, ABCA2 &amp;lt;dbl&amp;gt;, …&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;View(mutation)

dim(mutation)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]  1738 16971&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not all cell lines have both mutation and expression data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setdiff(expression$depmap_id, mutation$depmap_id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  [1] &amp;quot;ACH-002981&amp;quot; &amp;quot;ACH-000742&amp;quot; &amp;quot;ACH-002475&amp;quot; &amp;quot;ACH-000578&amp;quot; &amp;quot;ACH-000731&amp;quot;
#&amp;gt;  [6] &amp;quot;ACH-000690&amp;quot; &amp;quot;ACH-000575&amp;quot; &amp;quot;ACH-000049&amp;quot; &amp;quot;ACH-000642&amp;quot; &amp;quot;ACH-000299&amp;quot;
#&amp;gt; [11] &amp;quot;ACH-000088&amp;quot; &amp;quot;ACH-000539&amp;quot; &amp;quot;ACH-000413&amp;quot; &amp;quot;ACH-000229&amp;quot; &amp;quot;ACH-001712&amp;quot;
#&amp;gt; [16] &amp;quot;ACH-000194&amp;quot; &amp;quot;ACH-000629&amp;quot; &amp;quot;ACH-000216&amp;quot; &amp;quot;ACH-001109&amp;quot; &amp;quot;ACH-000282&amp;quot;
#&amp;gt; [21] &amp;quot;ACH-000033&amp;quot; &amp;quot;ACH-000904&amp;quot; &amp;quot;ACH-000710&amp;quot; &amp;quot;ACH-001142&amp;quot; &amp;quot;ACH-000116&amp;quot;
#&amp;gt; [26] &amp;quot;ACH-000854&amp;quot; &amp;quot;ACH-000494&amp;quot; &amp;quot;ACH-000057&amp;quot; &amp;quot;ACH-000034&amp;quot; &amp;quot;ACH-000170&amp;quot;
#&amp;gt; [31] &amp;quot;ACH-001743&amp;quot; &amp;quot;ACH-000064&amp;quot; &amp;quot;ACH-000016&amp;quot; &amp;quot;ACH-000300&amp;quot; &amp;quot;ACH-000600&amp;quot;
#&amp;gt; [36] &amp;quot;ACH-001207&amp;quot; &amp;quot;ACH-000314&amp;quot; &amp;quot;ACH-000084&amp;quot; &amp;quot;ACH-000580&amp;quot; &amp;quot;ACH-000923&amp;quot;
#&amp;gt; [41] &amp;quot;ACH-000737&amp;quot; &amp;quot;ACH-000306&amp;quot; &amp;quot;ACH-000850&amp;quot; &amp;quot;ACH-000071&amp;quot; &amp;quot;ACH-000185&amp;quot;
#&amp;gt; [46] &amp;quot;ACH-000230&amp;quot; &amp;quot;ACH-000526&amp;quot; &amp;quot;ACH-000931&amp;quot; &amp;quot;ACH-000014&amp;quot; &amp;quot;ACH-000003&amp;quot;
#&amp;gt; [51] &amp;quot;ACH-000333&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setdiff(mutation$depmap_id, expression$depmap_id) %&amp;gt;%
        head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;ACH-002089&amp;quot; &amp;quot;ACH-002399&amp;quot; &amp;quot;ACH-001002&amp;quot; &amp;quot;ACH-002389&amp;quot; &amp;quot;ACH-002209&amp;quot;
#&amp;gt; [6] &amp;quot;ACH-002210&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;common_cell_lines&amp;lt;- intersect(mutation$depmap_id, expression$depmap_id)

length(common_cell_lines)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 1399&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;expression_sub&amp;lt;- expression %&amp;gt;%
  filter(depmap_id %in% common_cell_lines)


mutation_sub&amp;lt;- mutation %&amp;gt;%
  filter(depmap_id %in% common_cell_lines)

dim(expression_sub)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]  1399 19152&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(mutation_sub)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]  1399 16971&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are total 1399 cell lines with both mutation and expression data.&lt;/p&gt;
&lt;p&gt;There are different levels of lineages annotations&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(mutation_sub$lineage_1, useNA = &amp;quot;always&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 
#&amp;gt;             Adrenal Gland          Ampulla of Vater             Biliary Tract 
#&amp;gt;                         1                         4                        38 
#&amp;gt;     Bladder/Urinary Tract                      Bone                     Bowel 
#&amp;gt;                        37                        39                        74 
#&amp;gt;                    Breast                    Cervix                 CNS/Brain 
#&amp;gt;                        67                        20                        95 
#&amp;gt;         Esophagus/Stomach                       Eye                Fibroblast 
#&amp;gt;                        82                        18                        25 
#&amp;gt;             Head and Neck                    Kidney                     Liver 
#&amp;gt;                        60                        38                        26 
#&amp;gt;                      Lung                  Lymphoid                   Myeloid 
#&amp;gt;                       181                       154                        58 
#&amp;gt;      Ovary/Fallopian Tube                  Pancreas Peripheral Nervous System 
#&amp;gt;                        63                        58                        39 
#&amp;gt;                    Pleura                  Prostate                      Skin 
#&amp;gt;                        21                        11                        86 
#&amp;gt;               Soft Tissue                    Testis                   Thyroid 
#&amp;gt;                        43                         3                        16 
#&amp;gt;                    Uterus              Vulva/Vagina                      &amp;lt;NA&amp;gt; 
#&amp;gt;                        40                         2                         0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# deeper lineages, but some NAs
table(mutation_sub$lineage_5, useNA = &amp;quot;always&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 
#&amp;gt;                         Acral                       Adrenal 
#&amp;gt;                             4                             1 
#&amp;gt;                      Alveolar                    Amelanotic 
#&amp;gt;                             6                             3 
#&amp;gt;                    Anaplastic                   Astrocytoma 
#&amp;gt;                             3                            14 
#&amp;gt;                        B-cell                B-cell Burkitt 
#&amp;gt;                            40                            13 
#&amp;gt;            B-cell Mantle Cell                      Basaloid 
#&amp;gt;                             6                             1 
#&amp;gt;              Bladder Squamous     Bladder Transitional Cell 
#&amp;gt;                             2                            24 
#&amp;gt;                  Blast Crisis                 Buccal Mucosa 
#&amp;gt;                            12                             3 
#&amp;gt;                    Clear Cell                         DDLPS 
#&amp;gt;                            20                             3 
#&amp;gt;               Diffuse Gastric                         DLBCL 
#&amp;gt;                             6                            20 
#&amp;gt;                     Embryonal                  Endocervical 
#&amp;gt;                             5                             2 
#&amp;gt;                  Endometrioid        Epithelial-Endometroid 
#&amp;gt;                             6                             1 
#&amp;gt;                 ERneg HER2neg                 ERneg HER2pos 
#&amp;gt;                            33                             9 
#&amp;gt;                 ERpos HER2neg                 ERpos HER2pos 
#&amp;gt;                            12                             8 
#&amp;gt;       Exocrine Adenocarcinoma        Exocrine Adenosquamous 
#&amp;gt;                            54                             2 
#&amp;gt;                  Extrahepatic                    Follicular 
#&amp;gt;                            10                             4 
#&amp;gt;                    Giant Cell                      Gingival 
#&amp;gt;                             1                             1 
#&amp;gt;                  Glioblastoma           HBs Antigen Carrier 
#&amp;gt;                            48                             1 
#&amp;gt;             High Grade Serous                Hypopharyngeal 
#&amp;gt;                            21                             1 
#&amp;gt;                  Intrahepatic               Keratoacanthoma 
#&amp;gt;                            25                             1 
#&amp;gt;                     Laryngeal              Low Grade Serous 
#&amp;gt;                             5                             1 
#&amp;gt;                            M2                            M3 
#&amp;gt;                             3                             3 
#&amp;gt;                            M4                            M5 
#&amp;gt;                             3                             8 
#&amp;gt;                            M6                            M7 
#&amp;gt;                             4                             2 
#&amp;gt;                   Med Group 3 Mixed Endometrioid Clear Cell 
#&amp;gt;                             4                             1 
#&amp;gt;       Mixed Serous Clear Cell                      Mucinous 
#&amp;gt;                             1                             6 
#&amp;gt;                       Mucosal          NSCLC Adenocarcinoma 
#&amp;gt;                             1                            71 
#&amp;gt;           NSCLC Adenosquamous              NSCLC Large Cell 
#&amp;gt;                             4                            16 
#&amp;gt;          NSCLC Mucoepidermoid                NSCLC Squamous 
#&amp;gt;                             1                            25 
#&amp;gt;             Oligodendroglioma                          Oral 
#&amp;gt;                             3                            17 
#&amp;gt;                     Papillary                Papillotubular 
#&amp;gt;                             3                             1 
#&amp;gt;                       Pharynx                  Plasmacytoma 
#&amp;gt;                             1                             4 
#&amp;gt;     Renal Medullary Carcinoma                Salivary Gland 
#&amp;gt;                             1                             1 
#&amp;gt;                        Serous              Signet Ring Cell 
#&amp;gt;                             5                             2 
#&amp;gt;                         Sinus               Somatostatinoma 
#&amp;gt;                             1                             1 
#&amp;gt;              Splenic Lymphoma                        T-cell 
#&amp;gt;                             1                            26 
#&amp;gt;                   T-cell ALCL              T-cell Cutaneous 
#&amp;gt;                             6                             3 
#&amp;gt;                    Testicular                        Tongue 
#&amp;gt;                             1                             5 
#&amp;gt;             Transitional Cell                       Tubular 
#&amp;gt;                             1                             5 
#&amp;gt;                         Uveal                      WD/DDPLS 
#&amp;gt;                             1                             1 
#&amp;gt;                         WDLPS                          &amp;lt;NA&amp;gt; 
#&amp;gt;                             3                           721&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;let’s focus on level 1. To make the analysis more robust, let’s pick some cancer types with at least 20 cell lines&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lineages&amp;lt;- c(&amp;quot;Bone&amp;quot;, &amp;quot;Bowel&amp;quot;, &amp;quot;Breast&amp;quot;, &amp;quot;Cervix&amp;quot;, &amp;quot;Head and Neck&amp;quot;, &amp;quot;CNS/Brain&amp;quot;)
  
expression_sub&amp;lt;- expression_sub %&amp;gt;%
  filter(lineage_1 %in% lineages)

mutation_sub&amp;lt;- mutation_sub %&amp;gt;%
  filter(lineage_1 %in% lineages)

dim(expression_sub)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]   355 19152&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(mutation_sub)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]   355 16971&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;clustering-by-gene-expression-only&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Clustering by gene expression only&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cancer_types&amp;lt;- factor(expression_sub$lineage_1)
expression_sub&amp;lt;- expression_sub %&amp;gt;%
  select(-(2:8))%&amp;gt;%
  tibble::column_to_rownames(var=&amp;quot;depmap_id&amp;quot;)


expression_sub[1:6, 1:6]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;              TSPAN6      TNMD     DPM1    SCYL3 C1orf112        FGR
#&amp;gt; ACH-002680 4.155425 0.1243281 6.681730 2.430285 2.799087 0.81557543
#&amp;gt; ACH-000283 3.618239 0.0000000 7.209941 1.922198 3.918386 0.00000000
#&amp;gt; ACH-001016 2.456806 0.0000000 7.383877 2.776104 3.578939 0.00000000
#&amp;gt; ACH-000160 2.835924 0.0000000 6.361944 1.550901 3.257011 0.00000000
#&amp;gt; ACH-001020 4.846995 0.0000000 6.911212 2.114367 4.040016 0.00000000
#&amp;gt; ACH-000818 3.531069 0.0000000 6.585864 3.726831 3.237258 0.07038933&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ComplexHeatmap)

expression_mat&amp;lt;- as.matrix(expression_sub)

# transpose it to gene by sample
expression_mat&amp;lt;- t(expression_mat)
dim(expression_mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 19144   355&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## filter only the most variable genes
library(genefilter)

top_genes&amp;lt;- genefilter::rowVars(expression_mat) %&amp;gt;% 
  sort(decreasing = TRUE) %&amp;gt;%
  names() %&amp;gt;%
  head(200)

expression_mat_sub&amp;lt;- expression_mat[top_genes, ]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(RColorBrewer)
#RColorBrewer::display.brewer.all()

cols&amp;lt;- RColorBrewer::brewer.pal(n = 6, name = &amp;quot;Set1&amp;quot;)
unique(cancer_types)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] CNS/Brain     Breast        Bowel         Bone          Cervix       
#&amp;gt; [6] Head and Neck
#&amp;gt; Levels: Bone Bowel Breast Cervix CNS/Brain Head and Neck&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ha&amp;lt;- HeatmapAnnotation(cancer_type = factor(cancer_types),
                       col=list(cancer_type = setNames(cols, unique(cancer_types) %&amp;gt;% sort())))

Heatmap(t(scale(t(expression_mat_sub))), top_annotation = ha,
         show_row_names = FALSE, show_column_names = FALSE,
         show_row_dend = FALSE,
        name = &amp;quot;scaled\nexpression&amp;quot;,
        column_dend_reorder = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-22-multi-omics-data-integration-a-case-study-with-transcriptomics-and-genomics-mutation-data_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Principal component analysis (PCA)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pca&amp;lt;- prcomp(t(expression_mat_sub),center = TRUE, scale. = TRUE) 

# check the order of the samples are the same.
all.equal(rownames(pca$x), colnames(expression_mat_sub))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;PC1_and_PC2&amp;lt;- data.frame(PC1=pca$x[,1], PC2= pca$x[,2], type = cancer_types)

## plot PCA plot
library(ggplot2)
ggplot(PC1_and_PC2, aes(x=PC1, y=PC2)) + 
        geom_point(aes(color = type)) +
        scale_color_manual(values = cols) +
        theme_bw(base_size = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-22-multi-omics-data-integration-a-case-study-with-transcriptomics-and-genomics-mutation-data_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;576&#34; /&gt;
You can see gene expression data only do a pretty good job separating the cancer types for most of the cell lines although we do see some mis-classified cell lines.&lt;/p&gt;
&lt;p&gt;Since different cancer types have different mutation profiles, let’s see if we can add the mutation information and better stratify the cancer cell lines.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;clustering-the-mutation-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;clustering the mutation data&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mutation_sub&amp;lt;- mutation_sub %&amp;gt;%
  select(-(2:8))%&amp;gt;%
  tibble::column_to_rownames(var=&amp;quot;depmap_id&amp;quot;)

mutation_sub[1:5, 1:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;            A1BG A1CF A2M A2ML1 A3GALT2
#&amp;gt; ACH-002680    0    0   0     0       0
#&amp;gt; ACH-000283    0    0   0     0       0
#&amp;gt; ACH-001016    0    0   0     0       0
#&amp;gt; ACH-000160    0    0   0     0       0
#&amp;gt; ACH-001020    0    0   0     0       0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mutation_mat&amp;lt;- as.matrix(mutation_sub)

# transpose it to gene by sample
mutation_mat&amp;lt;- t(mutation_mat)
dim(mutation_mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 16963   355&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## order the columns the same as the expression

mutation_mat&amp;lt;- mutation_mat[, colnames(expression_mat)]

top_genes2&amp;lt;- genefilter::rowVars(mutation_mat) %&amp;gt;% 
  sort(decreasing = TRUE) %&amp;gt;%
  names() %&amp;gt;%
  head(200)

# binarize the matrix

mutation_mat[mutation_mat &amp;gt;0]&amp;lt;- 1

colors = structure(c(&amp;quot;blue&amp;quot;, &amp;quot;red&amp;quot;), names = c(0, 1))

mutation_mat_sub&amp;lt;- mutation_mat[rowSums(mutation_mat) &amp;gt; 15 ,]
Heatmap(mutation_mat_sub, top_annotation = ha,
        col = colors,
        show_row_names = TRUE, show_column_names = FALSE,
        show_row_dend = FALSE,
        name = &amp;quot;mutation&amp;quot;,
        row_names_gp = gpar(fontsize = 5),
        column_dend_reorder = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-22-multi-omics-data-integration-a-case-study-with-transcriptomics-and-genomics-mutation-data_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;576&#34; /&gt;
Mutation is not as good to separate cancer types.&lt;/p&gt;
&lt;p&gt;We can use Rand index or adjusted rand index to measure how well the clustering matches the ground truth using only the expression data. See this &lt;a href=&#34;https://davetang.org/muse/2017/09/21/adjusted-rand-index/&#34;&gt;blog post&lt;/a&gt; by &lt;code&gt;Dave Tang&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
kmeans1&amp;lt;- kmeans(t(expression_mat_sub), centers = 6)
kmeans1$cluster %&amp;gt;%
        head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; ACH-002680 ACH-000283 ACH-001016 ACH-000160 ACH-001020 ACH-000818 
#&amp;gt;          2          1          1          4          4          5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install.packages(&amp;quot;fossil&amp;quot;)
fossil::rand.index(as.numeric(cancer_types), kmeans1$cluster)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 0.8142437&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fossil::adj.rand.index(as.numeric(cancer_types), kmeans1$cluster)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 0.3787002&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, we can use &lt;a href=&#34;https://github.com/pkimes/sigclust2&#34;&gt;&lt;code&gt;sigclust2&lt;/code&gt;&lt;/a&gt; to determine the best clustering using hierarchical clustering which was used in the heatmap and then calculate the rand index.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-factor-analysis-mfa&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multiple Factor Analysis (MFA)&lt;/h3&gt;
&lt;p&gt;For any data matrix, it can be (approximately) decomposed into two matrices. Read this review &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0168952518301240&#34;&gt;Enter the Matrix: Factorization Uncovers Knowledge from Omics&lt;/a&gt; and my previous &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/matrix-factorization-for-single-cell-rnaseq-data/&#34;&gt;blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/posts_img/matrix_factorization.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For multiple matrices, there are three strategies for the integration as shown below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/multiomics1.png&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;For early integration, you can simply concatenate the matrices together (Note, in this figure, the rows are samples, columns are features, you use &lt;code&gt;cbind&lt;/code&gt; to concatenate the matrices. In the code below, the columns are samples, so I used &lt;code&gt;rbind&lt;/code&gt; to concatenate and then &lt;code&gt;t&lt;/code&gt; to transpose it to sample x features).
However, different omics data may have very different range of values, you may want to normalize the features within each omic dataset first (e.g., a z-score) and then concatenate.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The middle integration, we can use methods such as Multiple Factor Analysis (MFA), joint NMF, or even deep-learning (e.g., autoEncoder) to get a lower dimension embedding of the samples and use that as input for any downstream analysis.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The later integration is the most simple and straightforward method. We analyze each omic data independently and then integrate at a higher level. (e.g, if the up-regulated pathways are common from proteomics data and the transcriptomics data)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s try Multiple Factor Analysis (MFA). MFA is a statistical technique that takes root in PCA (or MCA if dealing with qualitative data).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/mfa.png&#34; /&gt;
Formally, we have:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X = \begin{bmatrix}
           X_{1} \\
           X_{2} \\
           \vdots \\
           X_{L}
         \end{bmatrix} = WH\]&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;a joint decomposition of the different data matrices &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt; into the factor matrix&lt;br /&gt;
&lt;code&gt;W&lt;/code&gt; and the latent variable matrix &lt;code&gt;H&lt;/code&gt;. This way, we can leverage the ability of PCA to find the highest variance decomposition of the data, when the data consists of different omics types.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;But because measurements from different experiments have different scales, they will also have variance (and co-variance) at different scales.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Multiple Factor Analysis addresses this issue and achieves balance among the data types by normalizing each of the data types, before stacking them and passing them on to PCA. Formally, MFA is given by&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X_n = \begin{bmatrix}
           X_{1} / \lambda^{(1)}_1 \\
           X_{2} / \lambda^{(2)}_1 \\
           \vdots \\
           X_{L} / \lambda^{(L)}_1
         \end{bmatrix} = WH\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\lambda^{(i)}_1\)&lt;/span&gt;is the first eigenvalue of the principal component decomposition of &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Following this normalization step, we apply PCA to &lt;span class=&#34;math inline&#34;&gt;\(X_n\)&lt;/span&gt;. From there on, MFA analysis is the same as PCA analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tictoc)
all.equal(colnames(expression_mat_sub), colnames(mutation_mat_sub))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic()
# run the MFA function from the FactoMineR package
r.mfa &amp;lt;- FactoMineR::MFA(
  t(rbind(expression_mat_sub, mutation_mat_sub)), 
  # binding the omics types together, the colnames are the same 
  c(dim(expression_mat_sub)[1], dim(mutation_mat_sub)[1]), 
  ncp = 30,
  # specifying the dimensions of each
  graph=FALSE)
toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 0.583 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mfa.h &amp;lt;- r.mfa$global.pca$ind$coord
mfa.w &amp;lt;- r.mfa$quanti.var$coord

# create a dataframe with the H matrix and the cancer type label
mfa_df &amp;lt;- as.data.frame(mfa.h)
mfa_df$subtype &amp;lt;- factor(cancer_types)

# create the plot
ggplot(mfa_df, ggplot2::aes(x=Dim.1, y=Dim.2, color=subtype)) +
  geom_point() + 
  scale_color_manual(values = cols) +
  ggplot2::ggtitle(&amp;quot;Scatter plot of MFA&amp;quot;) +
  theme_bw(base_size = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-22-multi-omics-data-integration-a-case-study-with-transcriptomics-and-genomics-mutation-data_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mfa_df, ggplot2::aes(x=Dim.2, y=Dim.3, color=subtype)) +
  geom_point() + 
  scale_color_manual(values = cols) +
  ggplot2::ggtitle(&amp;quot;Scatter plot of MFA&amp;quot;) +
  theme_bw(base_size = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-22-multi-omics-data-integration-a-case-study-with-transcriptomics-and-genomics-mutation-data_files/figure-html/unnamed-chunk-14-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Heatmap(t(mfa.h)[1:30,], top_annotation = ha,
                  name=&amp;quot;MFA multi-omics\nintegration&amp;quot;,
        show_column_names = FALSE,
        show_row_dend = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-22-multi-omics-data-integration-a-case-study-with-transcriptomics-and-genomics-mutation-data_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;576&#34; /&gt;
Each row is a different feature that we can use to do clustering or as a feature for a machine learning prediction (e.g., drug response).&lt;/p&gt;
&lt;p&gt;Let’s quantify if the adjusted rand index improved or not.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
kmeans2&amp;lt;- kmeans(mfa.h, centers = 6)

fossil::rand.index(as.numeric(cancer_types), kmeans2$cluster)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 0.8212143&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fossil::adj.rand.index(as.numeric(cancer_types), kmeans2$cluster)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 0.423766&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The rand index improved from &lt;code&gt;0.814&lt;/code&gt; to &lt;code&gt;0.821&lt;/code&gt; after we include the mutation data.&lt;/p&gt;
&lt;p&gt;You can also use &lt;a href=&#34;https://compgenomr.github.io/book/matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html&#34;&gt;joint &lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; to do the integration.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;You can add more omics data such as copy-number variation, proteomics, metabolomics data etc just by concatenating more matrices.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;However, Not necessary the more the better. Whether additional omic layer contribute to additional information to separate the samples is a question.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Related to above, the quality of the omics data matters. Garbage in Garbage out just like machine learning.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;K-means can give different results based on the initiation. If you change the seed, you may get different clusters and so for the rand index too.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The above methods works for samples have every type of omic data. However, in real life, there could be some samples missing some types of data. &lt;a href=&#34;https://biofam.github.io/MOFA2/&#34;&gt;&lt;code&gt;MOFA+&lt;/code&gt;&lt;/a&gt; seems to be able to deal with it. Other methods such as &lt;a href=&#34;https://www.nature.com/articles/s41587-022-01284-4&#34;&gt;GLUE&lt;/a&gt; even works on the un-paired data.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/img/glue.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references-and-further-readings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References and further readings&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://compgenomr.github.io/book/matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html&#34; class=&#34;uri&#34;&gt;https://compgenomr.github.io/book/matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2023.07.21.549899v1&#34;&gt;ChromatinHD connects single-cell DNA accessibility and conformation to gene expression through scale-adaptive machine learning&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02015-1&#34;&gt;MOFA+: a statistical framework for comprehensive integration of multi-modal single-cell data | Genome Biology&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41576-023-00618-5&#34;&gt;Gene regulatory network inference in the era of single-cell multi-omics | Nature Reviews Genetics&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.cell.com/cell-genomics/fulltext/S2666-979X(23)00142-8&#34;&gt;Multiset correlation and factor analysis enables exploration of multi-omics data: Cell Genomics&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/KChen-lab/bindSC&#34;&gt;GitHub - KChen-lab/bindSC: Bi-order integration (in silico multi-omics data) of single cell RNA sequencing, single cell ATAC sequencing, spatial transcriptomics and CyTOF data&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/cantinilab/HuMMuS&#34;&gt;GitHub - cantinilab/HuMMuS: Molecular interactions inference from single-cell multi-omics data&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41467-020-20430-7&#34;&gt;Benchmarking joint multi-omics dimensionality reduction approaches for the study of cancer | Nature Communications&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41587-022-01284-4&#34;&gt;Multi-omics single-cell data integration and regulatory inference with graph-linked embedding | Nature Biotechnology&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/35169688/&#34;&gt;Machine learning for multi-omics data integration in cancer&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41581-021-00463-x&#34;&gt;Multi-omics integration in the age of million single-cell data | Nature Reviews Nephrology&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://academic.oup.com/bioinformatics/article/38/20/4727/6677225&#34;&gt;Integration of networks&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>neighborhood/cellular niches analysis with spatial transcriptome data in Seurat and Bioconductor</title>
      <link>/post/neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor/</link>
      <pubDate>Tue, 08 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor/</guid>
      <description>&lt;div id=&#34;spatial-transcriptome-cellular-niche-analysis-using-10x-xenium-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Spatial transcriptome cellular niche analysis using 10x xenium data&lt;/h3&gt;
&lt;p&gt;go to &lt;a href=&#34;https://www.10xgenomics.com/resources/datasets&#34; class=&#34;uri&#34;&gt;https://www.10xgenomics.com/resources/datasets&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There is a lung cancer and a breast cancer dataset. Let’s work on the lung cancer one.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.10xgenomics.com/resources/datasets/xenium-human-lung-preview-data-1-standard&#34; class=&#34;uri&#34;&gt;https://www.10xgenomics.com/resources/datasets/xenium-human-lung-preview-data-1-standard&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;37G zipped file!&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;wget https://s3-us-west-2.amazonaws.com/10x.files/samples/xenium/1.3.0/Xenium_Preview_Human_Lung_Cancer_With_Add_on_2_FFPE/Xenium_Preview_Human_Lung_Cancer_With_Add_on_2_FFPE_outs.zip

unzip Xenium_Preview_Human_Lung_Cancer_With_Add_on_2_FFPE_outs.zip 

sudo tar xvzf cell_feature_matrix.tar.gz&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;cell_feature_matrix/&lt;/code&gt;
&lt;code&gt;cell_feature_matrix/barcodes.tsv.gz&lt;/code&gt;
&lt;code&gt;cell_feature_matrix/features.tsv.gz&lt;/code&gt;
&lt;code&gt;cell_feature_matrix/matrix.mtx.gz&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;read-in-the-data-with-seurat&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;read in the data with Seurat&lt;/h3&gt;
&lt;p&gt;We really only care about the cell by gene count matrix which is inside the &lt;code&gt;cell_feature_matrix&lt;/code&gt; folder,
and the cell location x,y coordinates: &lt;code&gt;cells.csv.gz&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;data/xenium&lt;/code&gt; folder below contains the &lt;code&gt;cells.csv.gz&lt;/code&gt; file and the &lt;code&gt;cell_feature_matrix&lt;/code&gt; folder.&lt;/p&gt;
&lt;p&gt;The transcripts.csv.gz contains the molecule location information which is not needed for
most of the analysis if you do not work on subcelluar locations of the RNAs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Seurat)
library(dplyr)
library(here)
library(tictoc)

xenium_input&amp;lt;- ReadXenium(
  data.dir = &amp;quot;~/github_repos/compbio_tutorials/data/xenium&amp;quot;,
  outs = &amp;quot;matrix&amp;quot;,
  type = &amp;quot;centroids&amp;quot;,
  mols.qv.threshold = 20
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;construct a seurat object.
&lt;a href=&#34;https://github.com/satijalab/seurat/blob/763259d05991d40721dee99c9919ec6d4491d15e/R/convenience.R#L186&#34; class=&#34;uri&#34;&gt;https://github.com/satijalab/seurat/blob/763259d05991d40721dee99c9919ec6d4491d15e/R/convenience.R#L186&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;segmentations.data &amp;lt;- list(
    &amp;quot;centroids&amp;quot; = CreateCentroids(xenium_input$centroids)
    #&amp;quot;segmentation&amp;quot; = CreateSegmentation(data$segmentations)
  )

coords &amp;lt;- CreateFOV(
    coords = segmentations.data,
    type = &amp;quot;centroids&amp;quot;,
    molecules = NULL,
    assay = &amp;quot;Xenium&amp;quot;
  )

xenium.obj &amp;lt;- CreateSeuratObject(counts = xenium_input$matrix[[&amp;quot;Gene Expression&amp;quot;]], assay = &amp;quot;Xenium&amp;quot;)
xenium.obj[[&amp;quot;NegativeControlCodeword&amp;quot;]] &amp;lt;- CreateAssayObject(counts = xenium_input$matrix[[&amp;quot;Negative Control Codeword&amp;quot;]])

xenium.obj[[&amp;quot;NegativeControlProbe&amp;quot;]] &amp;lt;- CreateAssayObject(counts = xenium_input$matrix[[&amp;quot;Negative Control Probe&amp;quot;]])

xenium.obj[[&amp;quot;fov&amp;quot;]] &amp;lt;- coords&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;filter the cells&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# remove cells with 0 counts
xenium.obj &amp;lt;- subset(xenium.obj, subset = nCount_Xenium &amp;gt; 0)

VlnPlot(xenium.obj, features = c(&amp;quot;nFeature_Xenium&amp;quot;, &amp;quot;nCount_Xenium&amp;quot;), ncol = 2, pt.size = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;median(xenium.obj$nCount_Xenium)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 105&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;median(xenium.obj$nFeature_Xenium)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 62&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;median number of detected genes is around 62, and the median counts per cell is 105.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ImageFeaturePlot(xenium.obj, features = c(&amp;quot;EPCAM&amp;quot;, &amp;quot;CD4&amp;quot;, &amp;quot;CD8A&amp;quot;, &amp;quot;CD79A&amp;quot;), max.cutoff = c(20,
    15, 6, 6), size = 0.75, cols = c(&amp;quot;white&amp;quot;, &amp;quot;red&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;EPCAM&lt;/code&gt; mark the epithelial/tumor cells, and we also see some CD4, CD8 T cells and B cells.&lt;/p&gt;
&lt;p&gt;standard processing&lt;/p&gt;
&lt;p&gt;This takes 30mins&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic()
xenium.obj &amp;lt;- SCTransform(xenium.obj, assay = &amp;quot;Xenium&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%
#&amp;gt; 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%
#&amp;gt; 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xenium.obj &amp;lt;- RunPCA(xenium.obj, npcs = 30, features = rownames(xenium.obj))
xenium.obj &amp;lt;- RunUMAP(xenium.obj, dims = 1:30)
xenium.obj &amp;lt;- FindNeighbors(xenium.obj, reduction = &amp;quot;pca&amp;quot;, dims = 1:30)
xenium.obj &amp;lt;- FindClusters(xenium.obj, resolution = 0.3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck
#&amp;gt; 
#&amp;gt; Number of nodes: 530893
#&amp;gt; Number of edges: 17467378
#&amp;gt; 
#&amp;gt; Running Louvain algorithm...
#&amp;gt; Maximum modularity in 10 random starts: 0.9360
#&amp;gt; Number of communities: 21
#&amp;gt; Elapsed time: 824 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 2232.137 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DimPlot(xenium.obj)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/plot-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FeaturePlot(xenium.obj, features = c(&amp;quot;CD4&amp;quot;, &amp;quot;CD8A&amp;quot;, &amp;quot;EPCAM&amp;quot;, &amp;quot;NKG7&amp;quot;, &amp;quot;GZMB&amp;quot;,
                                     &amp;quot;FOXP3&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/plot-2.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ImageDimPlot(xenium.obj, cols = &amp;quot;polychrome&amp;quot;, size = 0.75)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/plot-3.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;find-all-markers-of-the-clusters-and-annotate-the-clusters-with-marker-genes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Find all markers of the clusters and annotate the clusters with marker genes&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# devtools::install_github(&amp;quot;immunogenomics/presto&amp;quot;)
library(presto)

all_markers&amp;lt;- presto::wilcoxauc(xenium.obj, assay = &amp;quot;data&amp;quot;,
                                seurat_assay = &amp;quot;Xenium&amp;quot;)

all_markers %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;   feature group     avgExpr        logFC   statistic       auc          pval
#&amp;gt; 1     ACE     0 0.221668593 -0.253886240 15537669449 0.4531079  0.000000e+00
#&amp;gt; 2    ACE2     0 0.005328125 -0.002081364 17111525722 0.4990046  9.218905e-10
#&amp;gt; 3   ACKR1     0 0.021724399 -0.062837265 16836952359 0.4909975 2.384530e-141
#&amp;gt; 4   ACTR3     0 0.965692723 -0.381113472 14948197656 0.4359178  0.000000e+00
#&amp;gt; 5  ADAM17     0 0.339432110  0.106478761 18344176529 0.5349510  0.000000e+00
#&amp;gt; 6  ADAM28     0 0.036061174 -0.027966375 16783860239 0.4894492 4.246117e-134
#&amp;gt;            padj    pct_in    pct_out
#&amp;gt; 1  0.000000e+00 16.297950 24.8933350
#&amp;gt; 2  1.047481e-09  0.516868  0.7159286
#&amp;gt; 3 4.744851e-141  1.856207  3.6336342
#&amp;gt; 4  0.000000e+00 53.824690 62.5498209
#&amp;gt; 5  0.000000e+00 25.355762 18.6602346
#&amp;gt; 6 8.239989e-134  3.178273  5.2801384&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# presto is much faster than FindAllMarkers
presto::top_markers(all_markers, n = 10, auc_min = 0.5, pct_in_min = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 10 × 17
#&amp;gt;     rank `0`   `1`   `10`  `11`  `12`  `13`  `14`  `15`  `2`   `3`   `4`   `5`  
#&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
#&amp;gt;  1     1 LTBP2 MARCO CD24  FCGBP CHIT1 MMRN1 KIT   MS4A1 SFTPD VWF   CD2   EPCAM
#&amp;gt;  2     2 FBN1  CD68  AGR3  AIF1  CD68  VWF   IL1R… IRF8  MUC1  GNG11 IL7R  MET  
#&amp;gt;  3     3 SLIT3 VSIG4 CP    CD68  LGMN  ECSCR MS4A2 FCMR  SFTA3 TMEM… KLRB1 KRT7 
#&amp;gt;  4     4 THBS2 ALOX5 TMC5  S100B PLA2… LYVE1 SLC1… FDCSP DMBT1 CD34  CD3E  MUC1 
#&amp;gt;  5     5 COL5… MCEM… FOXJ1 FCGR… MS4A… ACKR1 HPGDS IL7R  ATP1… ECSCR GZMA  BAIA…
#&amp;gt;  6     6 SVEP1 FCGR… TACS… MMP12 MARCO SELP  PTGS1 TNFR… RNF1… ACE   CTLA4 TACS…
#&amp;gt;  7     7 SFRP2 CD163 ATP1… CD14  SLC1… GNG11 ALOX5 BANK1 TMPR… SHAN… CD3D  CDH1 
#&amp;gt;  8     8 CTSK  CTSL  EHF   CD4   CD163 PLVAP FCER… GPR1… C16o… APOL… STAT4 RBM3 
#&amp;gt;  9     9 COL8… MS4A… CCDC… IGSF6 CTSK  ADGR… P2RX1 CD2   MALL  ADGR… GPR1… TOMM7
#&amp;gt; 10    10 NID1  AIF1  BAIA… VSIG4 IGSF6 SHAN… AREG  RARR… AGR3  FCN3  CD247 HNRN…
#&amp;gt; # ℹ 4 more variables: `6` &amp;lt;chr&amp;gt;, `7` &amp;lt;chr&amp;gt;, `8` &amp;lt;chr&amp;gt;, `9` &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on the marker genes, I manually annotate the cell types.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cluster 0: fibroblast.&lt;/li&gt;
&lt;li&gt;cluster 1: M2-like macrophage.&lt;/li&gt;
&lt;li&gt;cluster 10: ciliated epithelial cells.&lt;/li&gt;
&lt;li&gt;cluster 11: M2-like macrophage.&lt;/li&gt;
&lt;li&gt;cluster 12: M2-like macrophage.&lt;/li&gt;
&lt;li&gt;cluster 13: endothelia-1.&lt;/li&gt;
&lt;li&gt;cluster 14: mast cell.&lt;/li&gt;
&lt;li&gt;cluster 15: B cells.&lt;/li&gt;
&lt;li&gt;cluster 2: alveolar epithelial cells.&lt;/li&gt;
&lt;li&gt;cluster 3: endothelial-2.&lt;/li&gt;
&lt;li&gt;cluster 4: T/NK cells.&lt;/li&gt;
&lt;li&gt;cluster 5: alveolar epithelial cells.&lt;/li&gt;
&lt;li&gt;cluster 6: smooth muscle cells.&lt;/li&gt;
&lt;li&gt;cluster 7: M2-like macrophage.&lt;/li&gt;
&lt;li&gt;cluster 8: M1-like macrophage.&lt;/li&gt;
&lt;li&gt;cluster 9: plasma cells.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Add the cell annotations&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;annotations&amp;lt;- c(&amp;quot;fibroblast&amp;quot;, &amp;quot;M2-like macrophage-1&amp;quot;, &amp;quot;ciliated epithelial cells&amp;quot;, &amp;quot;M2-like macrophage-2&amp;quot;, &amp;quot;M2-like macrophage-3&amp;quot;, &amp;quot;endothelial-1&amp;quot;, &amp;quot;mast cell&amp;quot;, &amp;quot;B cells-1&amp;quot;, &amp;quot;alveolar epithelial cells-1&amp;quot;, &amp;quot;endothelial-2&amp;quot;, &amp;quot;T/NK cells&amp;quot;, &amp;quot;alveolar epithelial cells-2&amp;quot;, &amp;quot;smooth muscle cells&amp;quot;, &amp;quot;M2-like macrophage-4&amp;quot;, &amp;quot;M1-like macrophage&amp;quot;, &amp;quot;plasma cells&amp;quot;)

names(annotations)&amp;lt;- c(0,1,10,11,12,13,14,15,2,3,4,5,6,7,8,9)

xenium.obj$annotations&amp;lt;- annotations[as.character(xenium.obj$seurat_clusters)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;cluster 4 is the T/NK cells, I want to subcluster it to more fine-grained clusters&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(xenium.obj$seurat_clusters)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 
#&amp;gt;     0     1     2     3     4     5     6     7     8     9    10    11    12 
#&amp;gt; 75261 64079 63996 61209 55166 52187 31937 31335 17504 16194 15057 13049 12487 
#&amp;gt;    13    14    15 
#&amp;gt; 12412  5525  3495&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xenium.obj&amp;lt;- FindSubCluster(xenium.obj, cluster = 4, graph.name = &amp;quot;SCT_snn&amp;quot;,
                            resolution = 0.2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck
#&amp;gt; 
#&amp;gt; Number of nodes: 55166
#&amp;gt; Number of edges: 1705627
#&amp;gt; 
#&amp;gt; Running Louvain algorithm...
#&amp;gt; Maximum modularity in 10 random starts: 0.8845
#&amp;gt; Number of communities: 12
#&amp;gt; Elapsed time: 19 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(xenium.obj$sub.cluster)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 
#&amp;gt;     0     1    10    11    12    13    14    15     2     3   4_0   4_1   4_2 
#&amp;gt; 75261 64079 15057 13049 12487 12412  5525  3495 63996 61209 24009 11719  5917 
#&amp;gt;   4_3   4_4   4_5   4_6     5     6     7     8     9 
#&amp;gt;  5624  5068  1862   967 52187 31937 31335 17504 16194&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Idents(xenium.obj)&amp;lt;- xenium.obj$sub.cluster
scCustomize::Clustered_DotPlot(xenium.obj[, xenium.obj$sub.cluster %&amp;gt;%
                                            stringr::str_detect(&amp;quot;^4_&amp;quot;)], 
                               features = c(&amp;quot;CD4&amp;quot;, &amp;quot;CD8A&amp;quot;, &amp;quot;NKG7&amp;quot;, &amp;quot;GZMB&amp;quot;, 
                               &amp;quot;PDCD1&amp;quot;, &amp;quot;FOXP3&amp;quot;), plot_km_elbow = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_markers2&amp;lt;- presto::wilcoxauc(xenium.obj[,xenium.obj$sub.cluster %&amp;gt;%
                                            stringr::str_detect(&amp;quot;^4_&amp;quot;)],
                                 assay = &amp;quot;data&amp;quot;, seurat_assay = &amp;quot;Xenium&amp;quot;)

presto::top_markers(all_markers2, n = 20, auc_min = 0.5, pct_in_min = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 20 × 8
#&amp;gt;     rank `4_0`    `4_1`  `4_2`   `4_3`  `4_4`   `4_5`    `4_6`  
#&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  
#&amp;gt;  1     1 IL7R     KLRD1  SFRP2   CXCL13 CXCL9   PRG4     CHIT1  
#&amp;gt;  2     2 CD3E     KLRB1  THBS2   CTLA4  CCR7    SLIT3    CD68   
#&amp;gt;  3     3 CD2      GZMA   CTSK    CXCL9  IDO1    LTBP2    LGMN   
#&amp;gt;  4     4 CTLA4    FGFBP2 LTBP2   CD2    UBD     SVEP1    CTSK   
#&amp;gt;  5     5 CD3D     GZMB   THY1    CD8A   FSCN1   FBN1     IGSF6  
#&amp;gt;  6     6 CD28     FCGR3A COL5A2  UBD    IL7R    SERPINA3 MS4A4A 
#&amp;gt;  7     7 GPR171   CD247  RARRES1 GPI    CD83    TGM2     PLA2G7 
#&amp;gt;  8     8 GPR183   KRT7   FBN1    CHI3L1 CXCL10  APOD     MARCO  
#&amp;gt;  9     9 CD4      MUC1   COL8A1  MUC1   IRF8    NID1     CTSA   
#&amp;gt; 10    10 TC2N     ADGRE5 ALDH1A3 KRT7   NFKB1   ENAH     AIF1   
#&amp;gt; 11    11 LCK      AREG   IGF1    AIF1   GRINA   IL7R     RARRES1
#&amp;gt; 12    12 FCMR     SFTPD  PLA2G2A CD3E   GPR183  EPHX1    CD4    
#&amp;gt; 13    13 CXCR6    EPCAM  PDPN    PSMA1  S100B   PDPN     SLC1A3 
#&amp;gt; 14    14 ANKRD36C SFTA3  APOD    EPCAM  CD86    HIF1A    LAMP2  
#&amp;gt; 15    15 GPSM3    ATP1B1 SLIT3   CD68   IRF1    RARRES1  FCGR1A 
#&amp;gt; 16    16 STAT4    GNG11  NID1    CD27   CMTM6   CD4      CTSL   
#&amp;gt; 17    17 TMEM123  DMBT1  TGM2    CTSL   ACTR3   CTSK     FCGR3A 
#&amp;gt; 18    18 SRSF7    VWF    ENAH    SRSF2  AIF1    COL8A1   HEXA   
#&amp;gt; 19    19 CD163    RUNX3  EIF3E   CD3D   ALOX5   PCBP2    FCMR   
#&amp;gt; 20    20 CD8A     EPHX1  SVEP1   HNRNPC TMEM123 LGALS3BP ACE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;more fine-grained annotation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;4_0: CD4 Tcells.&lt;/li&gt;
&lt;li&gt;4_1: NK cells.&lt;/li&gt;
&lt;li&gt;4_2: fibroblast.&lt;/li&gt;
&lt;li&gt;4_3: CD8 Tcells.&lt;/li&gt;
&lt;li&gt;4_5: PRG4 is a fibroblast marker we also see CD4 in this cluster.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;4_6: macrophage.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Interesting, subcluster the NK/T cells revealed fibroblasts and macrophage (4_6) populations.
My experience with spatial data from 10x, nanostring and Vizgen are similar, they all have spill out transcripts of cells that maybe contaminating the nearby cells. Also, there is no clear cut of CD4 T cells and CD8 T cells.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;neighorhoods-analysis-in-seurat&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;neighorhoods analysis in Seurat&lt;/h3&gt;
&lt;p&gt;Cellular neighborhood/niche is aggregation of cells can result in ‘cellular neighbourhoods’. A neighbourhood is defined as a group of cells that with a similar composition together. These can be homotypic, containing cells of a single class (e.g. immune cells), or heterotypic (e.g. a mixture of tumour and immune cells).&lt;/p&gt;
&lt;p&gt;In one of my &lt;a href=&#34;https://divingintogeneticsandgenomics.com/post/how-to-do-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data/&#34;&gt;previous post&lt;/a&gt;, I showed you how to identify cellular neighborhood/niches within seurat.&lt;/p&gt;
&lt;p&gt;Let’s repeat it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xenium_input$centroids %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;          x        y       cell
#&amp;gt; 1 366.5239 849.1828 aaaaaacg-1
#&amp;gt; 2 364.5222 863.8438 aaaaafen-1
#&amp;gt; 3 381.3140 863.7556 aaaaanfe-1
#&amp;gt; 4 388.0256 864.1576 aaaabekh-1
#&amp;gt; 5 394.2588 869.2458 aaaacacf-1
#&amp;gt; 6 390.1672 846.2146 aaaakgka-1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat&amp;lt;- xenium_input$centroids[,1:2] 
mat&amp;lt;- as.matrix(mat)
rownames(mat)&amp;lt;- xenium_input$centroids$cell&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Reorder the cells in the coordinates matrix as the same order as in the Seurat object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Cells(xenium.obj) %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;aaaaaacg-1&amp;quot; &amp;quot;aaaaafen-1&amp;quot; &amp;quot;aaaaanfe-1&amp;quot; &amp;quot;aaaabekh-1&amp;quot; &amp;quot;aaaacacf-1&amp;quot;
#&amp;gt; [6] &amp;quot;aaaakgka-1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## make sure the order of the cells is the same 
all.equal(Cells(xenium.obj), rownames(mat))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] &amp;quot;Lengths (530893, 531165) differ (string compare on first 530893)&amp;quot;
#&amp;gt; [2] &amp;quot;519130 string mismatches&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                   x        y
#&amp;gt; aaaaaacg-1 366.5239 849.1828
#&amp;gt; aaaaafen-1 364.5222 863.8438
#&amp;gt; aaaaanfe-1 381.3140 863.7556
#&amp;gt; aaaabekh-1 388.0256 864.1576
#&amp;gt; aaaacacf-1 394.2588 869.2458
#&amp;gt; aaaakgka-1 390.1672 846.2146&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# reorder the matrix rows
mat&amp;lt;- mat[Cells(xenium.obj), ]
head(mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                   x        y
#&amp;gt; aaaaaacg-1 366.5239 849.1828
#&amp;gt; aaaaafen-1 364.5222 863.8438
#&amp;gt; aaaaanfe-1 381.3140 863.7556
#&amp;gt; aaaabekh-1 388.0256 864.1576
#&amp;gt; aaaacacf-1 394.2588 869.2458
#&amp;gt; aaaakgka-1 390.1672 846.2146&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(Cells(xenium.obj), rownames(mat))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Find the closest cells for each cell within 50 um radius.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dbscan)
eps &amp;lt;- 50
tic()
nn &amp;lt;- frNN(x= mat, eps = eps)
toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 21.538 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn$id %&amp;gt;%
  head(n=3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; $`aaaaaacg-1`
#&amp;gt;  [1]     2     3     6 82996     4 82999 40480 82992  6704 82997   120     5
#&amp;gt; [13]     7     8 83001 82998 82991 40489     9 83009 82995 83004 83006 83007
#&amp;gt; 
#&amp;gt; $`aaaaafen-1`
#&amp;gt;  [1] 82996     1 82992     3 82997 82999     4  6704 82998 82991 83001   120
#&amp;gt; [13]     5     6 82995     7     8 83000 83006 40480 83004 83009 84185 83007
#&amp;gt; [25] 83002 84187  6707     9 83010
#&amp;gt; 
#&amp;gt; $`aaaaanfe-1`
#&amp;gt;  [1]     4  6704 82999     5     7     2 82996 83001 82997     6     1     8
#&amp;gt; [13] 83009 82998 83004 82992 83007 83006 40480     9 83010 83000 82995 83014
#&amp;gt; [25] 83002 82991 83008 83015 40489 83005    10    11   120 40481    12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is a list of list containing the indices of the cells that are within 50um radius.&lt;/p&gt;
&lt;p&gt;Create the neighborhood count matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the same cell order
all.equal(colnames(xenium.obj), names(nn$id))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn$id %&amp;gt;%
  stack() %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;   values        ind
#&amp;gt; 1      2 aaaaaacg-1
#&amp;gt; 2      3 aaaaaacg-1
#&amp;gt; 3      6 aaaaaacg-1
#&amp;gt; 4  82996 aaaaaacg-1
#&amp;gt; 5      4 aaaaaacg-1
#&amp;gt; 6  82999 aaaaaacg-1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## make it to a dataframe 
nn_df&amp;lt;- nn$id %&amp;gt;%
  stack()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;get the annotations for cells that are within the 50 um of each cell.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cluster_ids&amp;lt;- xenium.obj$annotations %&amp;gt;% unname()

## vectorization, so much faster than the solution in my old post
nn_df$cluster_id&amp;lt;- cluster_ids[nn_df$values]

head(nn_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;   values        ind                  cluster_id
#&amp;gt; 1      2 aaaaaacg-1        M2-like macrophage-2
#&amp;gt; 2      3 aaaaaacg-1 alveolar epithelial cells-1
#&amp;gt; 3      6 aaaaaacg-1                   mast cell
#&amp;gt; 4  82996 aaaaaacg-1                   B cells-1
#&amp;gt; 5      4 aaaaaacg-1                   mast cell
#&amp;gt; 6  82999 aaaaaacg-1                   B cells-1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_df$cluster_id&amp;lt;- factor(nn_df$cluster_id)
tic()
nn_count&amp;lt;- nn_df %&amp;gt;%
  group_by(ind) %&amp;gt;%
  count(cluster_id, .drop = FALSE)
toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 64.036 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(nn_count)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 6 × 3
#&amp;gt; # Groups:   ind [1]
#&amp;gt;   ind        cluster_id                      n
#&amp;gt;   &amp;lt;fct&amp;gt;      &amp;lt;fct&amp;gt;                       &amp;lt;int&amp;gt;
#&amp;gt; 1 aaaaaacg-1 alveolar epithelial cells-1     1
#&amp;gt; 2 aaaaaacg-1 alveolar epithelial cells-2     0
#&amp;gt; 3 aaaaaacg-1 B cells-1                       5
#&amp;gt; 4 aaaaaacg-1 ciliated epithelial cells       0
#&amp;gt; 5 aaaaaacg-1 endothelial-1                   0
#&amp;gt; 6 aaaaaacg-1 endothelial-2                   0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;pivot it to a wide format and create a &lt;code&gt;cell x cluster_id&lt;/code&gt; matrix&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_count&amp;lt;- nn_count %&amp;gt;%
  tidyr::pivot_wider(names_from = cluster_id, values_from = n)

head(nn_count)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 6 × 17
#&amp;gt; # Groups:   ind [6]
#&amp;gt;   ind        `alveolar epithelial cells-1` alveolar epithelial cel…¹ `B cells-1`
#&amp;gt;   &amp;lt;fct&amp;gt;                              &amp;lt;int&amp;gt;                     &amp;lt;int&amp;gt;       &amp;lt;int&amp;gt;
#&amp;gt; 1 aaaaaacg-1                             1                         0           5
#&amp;gt; 2 aaaaafen-1                             1                         0           4
#&amp;gt; 3 aaaaanfe-1                             0                         2           5
#&amp;gt; 4 aaaabekh-1                             1                         3           5
#&amp;gt; 5 aaaacacf-1                             1                         3           5
#&amp;gt; 6 aaaakgka-1                             1                         3           5
#&amp;gt; # ℹ abbreviated name: ¹​`alveolar epithelial cells-2`
#&amp;gt; # ℹ 13 more variables: `ciliated epithelial cells` &amp;lt;int&amp;gt;,
#&amp;gt; #   `endothelial-1` &amp;lt;int&amp;gt;, `endothelial-2` &amp;lt;int&amp;gt;, fibroblast &amp;lt;int&amp;gt;,
#&amp;gt; #   `M1-like macrophage` &amp;lt;int&amp;gt;, `M2-like macrophage-1` &amp;lt;int&amp;gt;,
#&amp;gt; #   `M2-like macrophage-2` &amp;lt;int&amp;gt;, `M2-like macrophage-3` &amp;lt;int&amp;gt;,
#&amp;gt; #   `M2-like macrophage-4` &amp;lt;int&amp;gt;, `mast cell` &amp;lt;int&amp;gt;, `plasma cells` &amp;lt;int&amp;gt;,
#&amp;gt; #   `smooth muscle cells` &amp;lt;int&amp;gt;, `T/NK cells` &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert to a matrix
nn_mat&amp;lt;- nn_count[,-1] %&amp;gt;% as.matrix()
rownames(nn_mat)&amp;lt;- nn_count$ind

head(nn_mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;            alveolar epithelial cells-1 alveolar epithelial cells-2 B cells-1
#&amp;gt; aaaaaacg-1                           1                           0         5
#&amp;gt; aaaaafen-1                           1                           0         4
#&amp;gt; aaaaanfe-1                           0                           2         5
#&amp;gt; aaaabekh-1                           1                           3         5
#&amp;gt; aaaacacf-1                           1                           3         5
#&amp;gt; aaaakgka-1                           1                           3         5
#&amp;gt;            ciliated epithelial cells endothelial-1 endothelial-2 fibroblast
#&amp;gt; aaaaaacg-1                         0             0             0          0
#&amp;gt; aaaaafen-1                         0             0             0          0
#&amp;gt; aaaaanfe-1                         0             0             0          0
#&amp;gt; aaaabekh-1                         0             0             0          0
#&amp;gt; aaaacacf-1                         0             0             0          0
#&amp;gt; aaaakgka-1                         1             0             0          0
#&amp;gt;            M1-like macrophage M2-like macrophage-1 M2-like macrophage-2
#&amp;gt; aaaaaacg-1                  0                    0                    3
#&amp;gt; aaaaafen-1                  0                    0                    2
#&amp;gt; aaaaanfe-1                  0                    0                    3
#&amp;gt; aaaabekh-1                  0                    0                    2
#&amp;gt; aaaacacf-1                  0                    0                    3
#&amp;gt; aaaakgka-1                  0                    0                    4
#&amp;gt;            M2-like macrophage-3 M2-like macrophage-4 mast cell plasma cells
#&amp;gt; aaaaaacg-1                    1                    0        14            0
#&amp;gt; aaaaafen-1                    1                    0        20            1
#&amp;gt; aaaaanfe-1                    1                    0        23            1
#&amp;gt; aaaabekh-1                    1                    0        24            1
#&amp;gt; aaaacacf-1                    1                    0        25            1
#&amp;gt; aaaakgka-1                    1                    0        17            1
#&amp;gt;            smooth muscle cells T/NK cells
#&amp;gt; aaaaaacg-1                   0          0
#&amp;gt; aaaaafen-1                   0          0
#&amp;gt; aaaaanfe-1                   0          0
#&amp;gt; aaaabekh-1                   0          0
#&amp;gt; aaaacacf-1                   0          0
#&amp;gt; aaaakgka-1                   0          0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(rownames(nn_mat), Cells(xenium.obj))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;k-means-clustering&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;k-means clustering&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)

# I cheated here to make k=13 so I can compare it with the Louvian clustering later
k_means_res&amp;lt;- kmeans(nn_mat, centers = 13)

k_means_id&amp;lt;- k_means_res$cluster %&amp;gt;%
  tibble::enframe(name = &amp;quot;cell_id&amp;quot;, value = &amp;quot;kmeans_cluster&amp;quot;)

head(k_means_id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 6 × 2
#&amp;gt;   cell_id    kmeans_cluster
#&amp;gt;   &amp;lt;chr&amp;gt;               &amp;lt;int&amp;gt;
#&amp;gt; 1 aaaaaacg-1             11
#&amp;gt; 2 aaaaafen-1             11
#&amp;gt; 3 aaaaanfe-1             11
#&amp;gt; 4 aaaabekh-1             11
#&amp;gt; 5 aaaacacf-1             11
#&amp;gt; 6 aaaakgka-1             11&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add it to the metadata solot for nn_obj below
k_means_df&amp;lt;- as.data.frame(k_means_id)
rownames(k_means_df)&amp;lt;- k_means_id$cell_id&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;louvian-clustering-just-like-scranseq-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Louvian clustering just like scRANseq data&lt;/h4&gt;
&lt;p&gt;Create a Seurat object and do a regular single-cell count matrix analysis, but now we only have 16 features (clusters) instead of 20,000 genes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_obj&amp;lt;- CreateSeuratObject(counts = t(nn_mat),  min.features = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;routine processing&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_obj&amp;lt;- SCTransform(nn_obj, vst.flavor = &amp;quot;v2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%
#&amp;gt; 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%
#&amp;gt; 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## we only have 16 clusters/celltypes, max pc 16
nn_obj &amp;lt;- RunPCA(nn_obj, npcs = 15, features = rownames(nn_obj))
ElbowPlot(nn_obj)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_obj &amp;lt;- FindNeighbors(nn_obj, reduction = &amp;quot;pca&amp;quot;, dims = 1:15)
nn_obj &amp;lt;- FindClusters(nn_obj, resolution = 0.3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck
#&amp;gt; 
#&amp;gt; Number of nodes: 483243
#&amp;gt; Number of edges: 12786808
#&amp;gt; 
#&amp;gt; Running Louvain algorithm...
#&amp;gt; Maximum modularity in 10 random starts: 0.9186
#&amp;gt; Number of communities: 13
#&amp;gt; Elapsed time: 286 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_obj &amp;lt;- RunUMAP(nn_obj, dims = 1:10)


DimPlot(nn_obj)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-20-2.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;suerat-v5-has-a-function-to-detect-neighborhood&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Suerat V5 has a function to detect neighborhood&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://satijalab.org/seurat/articles/seurat5_spatial_vignette_2&#34; class=&#34;uri&#34;&gt;https://satijalab.org/seurat/articles/seurat5_spatial_vignette_2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I do not have Seurat V5 installed, so the code below is not run.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xenium.obj &amp;lt;- BuildNicheAssay(object = xenium.obj, group.by = &amp;quot;annotations&amp;quot;,
    niches.k = 5, neighbors.k = 30)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;compare-k-means-and-the-louvian-clustering&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;compare k-means and the Louvian clustering&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_obj&amp;lt;- AddMetaData(nn_obj, metadata = k_means_df )

nn_obj@meta.data %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;               orig.ident nCount_RNA nFeature_RNA nCount_SCT nFeature_SCT
#&amp;gt; aaaaaacg-1 SeuratProject         24            5         44            5
#&amp;gt; aaaaafen-1 SeuratProject         29            6         45            6
#&amp;gt; aaaaanfe-1 SeuratProject         35            6         44            6
#&amp;gt; aaaabekh-1 SeuratProject         37            7         44            7
#&amp;gt; aaaacacf-1 SeuratProject         39            7         44            7
#&amp;gt; aaaakgka-1 SeuratProject         33            8         43            8
#&amp;gt;            SCT_snn_res.0.3 seurat_clusters    cell_id kmeans_cluster
#&amp;gt; aaaaaacg-1               3               3 aaaaaacg-1             11
#&amp;gt; aaaaafen-1               3               3 aaaaafen-1             11
#&amp;gt; aaaaanfe-1               3               3 aaaaanfe-1             11
#&amp;gt; aaaabekh-1               3               3 aaaabekh-1             11
#&amp;gt; aaaacacf-1               3               3 aaaacacf-1             11
#&amp;gt; aaaakgka-1               3               3 aaaakgka-1             11&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(nn_obj$kmeans_cluster, nn_obj$seurat_clusters)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;     
#&amp;gt;          0     1     2     3     4     5     6     7     8     9    10    11
#&amp;gt;   1      0     0     0     0     0     0     0     0 10316     0     0     0
#&amp;gt;   2  14180  4543  1409  4753 11705  2406  3303  6691  5165    13   475   395
#&amp;gt;   3  62713   568   884  4075  5189   685  6473  4867   607   128   102     0
#&amp;gt;   4   8065  1942  2310 18508  5356 12663 22928 10179  8409  1015  1219   107
#&amp;gt;   5     23  3466     0  1097  1528 23703  2949   711  1570  5675  1102   541
#&amp;gt;   6      0   494 13303     8   752     0    33   139   188     0    20     0
#&amp;gt;   7      0 20142     0     0     0     0     0     0   471    10     3     0
#&amp;gt;   8      0   405     0     3     1   101     1     0   203  9862    38     0
#&amp;gt;   9   1578  1986 39849  1011  5615   212  2465  8996  1369     7   331     2
#&amp;gt;   10     0  6485     0     0     0     0     0     0    68     0     0     0
#&amp;gt;   11     0   362     1 16396    49  1479     8     0  1189    67    50     9
#&amp;gt;   12     0 25085     0    15    11    42     0    17   874   246  1178     8
#&amp;gt;   13     0  1189     0   344 12245  1038    23   567   426   543 12502  2816
#&amp;gt;     
#&amp;gt;         12
#&amp;gt;   1      0
#&amp;gt;   2     43
#&amp;gt;   3      0
#&amp;gt;   4     96
#&amp;gt;   5      0
#&amp;gt;   6      0
#&amp;gt;   7    307
#&amp;gt;   8      8
#&amp;gt;   9     56
#&amp;gt;   10    10
#&amp;gt;   11     0
#&amp;gt;   12  1022
#&amp;gt;   13    60&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some help functions from &lt;code&gt;scclusteval&lt;/code&gt; to calculate the jaccard distances for two difference clustering methods:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#devtools::install_github(&amp;quot;crazyhottommy/scclusteval&amp;quot;)

library(scclusteval)
PairWiseJaccardSetsHeatmap(Idents(nn_obj), k_means_res$cluster, best_match = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;1152&#34; /&gt;
x-axis is the k-means clustering: cluster1-13.
y-axis is the Louvian clustering: cluster0-12.&lt;/p&gt;
&lt;p&gt;There are some 1-1 cluster mapping for the two different clustering methods.&lt;/p&gt;
&lt;p&gt;Add the niche information to the original seurat object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_meta&amp;lt;- nn_obj@meta.data %&amp;gt;%
  select(cell_id, SCT_snn_res.0.3, kmeans_cluster) 

xenium.obj&amp;lt;- AddMetaData(xenium.obj, nn_meta)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;characterize the neighborhoods/niches by looking at the composition of cell types&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ComplexHeatmap)

# calculate the average abundance of cell types per niche
average_cell_type_abundance&amp;lt;- AverageExpression(
  nn_obj,
  assays = NULL,
  features = rownames(nn_obj),
  return.seurat = FALSE,
  group.by = &amp;quot;SCT_snn_res.0.3&amp;quot;,
)

cell_fun = function(j, i, x, y, width, height, fill) {
                grid::grid.rect(x = x, y = y, width = width *0.99, 
                                height = height *0.99,
                                gp = grid::gpar(col = &amp;quot;grey&amp;quot;, 
                                                fill = fill, lty = 1, lwd = 0.5))
}

col_fun=circlize::colorRamp2(c(-2, 0, 2), c(&amp;quot;blue&amp;quot;, &amp;quot;white&amp;quot;, &amp;quot;red&amp;quot;))


Heatmap(t(scale(t(average_cell_type_abundance$SCT))),
        show_row_dend = FALSE,
        show_column_dend = FALSE,
        rect_gp = grid::gpar(type = &amp;quot;none&amp;quot;),
        cell_fun = cell_fun,
        col = col_fun,
        column_names_rot = 45)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;T/NK cells are mainly in niche 8 and 12.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scCustomize::Clustered_DotPlot(nn_obj, features= rownames(nn_obj), plot_km_elbow = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scCustomize::Stacked_VlnPlot(nn_obj, features= rownames(nn_obj))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-26-2.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Niche 1 contains most of the endothelia-1 cells and looks likely there is a blood vessel there.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1&amp;lt;- ImageDimPlot(xenium.obj, fov = &amp;quot;fov&amp;quot;, cols = &amp;quot;polychrome&amp;quot;, axes = TRUE, 
                  group.by = &amp;quot;annotations&amp;quot;)


## the cells are colored by the clustering of the cells by neighborhood 
p2&amp;lt;- ImageDimPlot(xenium.obj, fov = &amp;quot;fov&amp;quot;, cols = &amp;quot;polychrome&amp;quot;, axes = TRUE, 
                  group.by = &amp;quot;SCT_snn_res.0.3&amp;quot; )
        
p1 + p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;or table it using the tally counts&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat2&amp;lt;- table(xenium.obj$SCT_snn_res.0.3, xenium.obj$annotations) 

head(mat2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;    
#&amp;gt;     alveolar epithelial cells-1 alveolar epithelial cells-2 B cells-1
#&amp;gt;   0                         474                         352      7004
#&amp;gt;   1                        2992                        2431      1870
#&amp;gt;   2                         447                         478      2684
#&amp;gt;   3                         638                         597      3232
#&amp;gt;   4                        3541                         456      3819
#&amp;gt;   5                         445                         424      2632
#&amp;gt;    
#&amp;gt;     ciliated epithelial cells endothelial-1 endothelial-2 fibroblast
#&amp;gt;   0                     22020            87           309      13367
#&amp;gt;   1                      4829         33208           700       7492
#&amp;gt;   2                      8012            71           140       4601
#&amp;gt;   3                      4798            47           903       7517
#&amp;gt;   4                      5621           135           647       4325
#&amp;gt;   5                      2184            66          8190      12937
#&amp;gt;    
#&amp;gt;     M1-like macrophage M2-like macrophage-1 M2-like macrophage-2
#&amp;gt;   0                817                 7618                25948
#&amp;gt;   1                542                 3383                 2315
#&amp;gt;   2                369                29140                 6498
#&amp;gt;   3                741                  987                 5026
#&amp;gt;   4                463                 4054                 4424
#&amp;gt;   5                775                  498                 2809
#&amp;gt;    
#&amp;gt;     M2-like macrophage-3 M2-like macrophage-4 mast cell plasma cells
#&amp;gt;   0                 6919                  392       487          220
#&amp;gt;   1                 4802                  223       759          217
#&amp;gt;   2                 3401                  122       526          197
#&amp;gt;   3                 4014                 1410     15572          163
#&amp;gt;   4                12405                  761       577          600
#&amp;gt;   5                 5486                 1372      3180          265
#&amp;gt;    
#&amp;gt;     smooth muscle cells T/NK cells
#&amp;gt;   0                 422        123
#&amp;gt;   1                 637        267
#&amp;gt;   2                 967        103
#&amp;gt;   3                 464        101
#&amp;gt;   4                 512        111
#&amp;gt;   5                 956        110&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Heatmap(t(scale(mat2)),
        show_row_dend = FALSE,
        show_column_dend = FALSE,
        rect_gp = grid::gpar(type = &amp;quot;none&amp;quot;),
        cell_fun = cell_fun,
        col = col_fun,
        column_names_rot = 45)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat3&amp;lt;- table(xenium.obj$kmeans_cluster, xenium.obj$annotations)
Heatmap(t(scale(mat3)),
        show_row_dend = FALSE,
        show_column_dend = FALSE,
        rect_gp = grid::gpar(type = &amp;quot;none&amp;quot;),
        cell_fun = cell_fun)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-28-2.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Tally the counts may obscure the fine structures of the niches. For example,
it only shows T/NK cells in niche 8 but not so clear in niche 12.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;neigbhorhood-analysis-in-spatialexperiment&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;neigbhorhood analysis in SpatialExperiment&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&#34;https://trigosteam.github.io/SPIAT/articles/neighborhood.html&#34;&gt;SPIAT bioconductor package&lt;/a&gt; provides functions to do it and more functions to analyze the spatial data.
But it only works with &lt;code&gt;SpatialExperiment&lt;/code&gt; object. &lt;a href=&#34;https://www.nature.com/articles/s41467-023-37822-0&#34;&gt;Paper&lt;/a&gt; describing it.&lt;/p&gt;
&lt;p&gt;Convert the seurat object to &lt;a href=&#34;https://lmweber.org/OSTA-book/spatialexperiment.html&#34;&gt;SpatialExperiment&lt;/a&gt; object.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/drighelli/SpatialExperiment/issues/115&#34; class=&#34;uri&#34;&gt;https://github.com/drighelli/SpatialExperiment/issues/115&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(SpatialExperiment)
library(Seurat)
# BiocManager::install(&amp;quot;SpatialExperiment&amp;quot;)
library(dplyr)
# BiocManager::install(&amp;quot;SPIAT&amp;quot;)
library(SPIAT)


## Function
seurat_to_spe &amp;lt;- function(seu, sample_id, img_id) {
    ## Convert to SCE
    sce &amp;lt;- Seurat::as.SingleCellExperiment(seu)
    
    ## Extract spatial coordinates
    spatialCoords &amp;lt;- as.matrix(
        seu@images[[img_id]]@boundaries$centroids@coords[, c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;)])
    
    # the column names are specific for SPAIT
    colnames(spatialCoords)&amp;lt;- c(&amp;quot;Cell.X.Position&amp;quot;, &amp;quot;Cell.Y.Position&amp;quot;)
    
    ## Extract and process image data
    #img &amp;lt;- SpatialExperiment::SpatialImage(
    #    x = as.raster(seu@images[[img_id]]@image))
    
    #imgData &amp;lt;- DataFrame(
    #    sample_id = sample_id,
    #    image_id = img_id,
    #    data = I(list(img)),
    #    scaleFactor = seu@images[[img_id]]@scale.factors$lowres)
    
    # Convert to SpatialExperiment
    spe &amp;lt;- SpatialExperiment(
        assays = assays(sce),
        rowData = rowData(sce),
        colData = colData(sce),
        metadata = metadata(sce),
        reducedDims = reducedDims(sce),
        altExps = altExps(sce),
        sample_id = sample_id,
        spatialCoords = spatialCoords,
        #imgData = imgData
    )
    # indicate all spots are on the tissue
    spe$in_tissue &amp;lt;- 1
    spe$sample_id &amp;lt;- sample_id
    # Return Spatial Experiment object
    spe
}


spe&amp;lt;- seurat_to_spe(seu = xenium.obj, sample_id = &amp;quot;1&amp;quot;, img_id = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;inspect the data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# what&amp;#39;s the gene and cell number
dim(spe)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1]    392 530893&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;assay(spe)[1:5, 1:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 5 x 5 sparse Matrix of class &amp;quot;dgCMatrix&amp;quot;
#&amp;gt;        aaaaaacg-1 aaaaafen-1 aaaaanfe-1 aaaabekh-1 aaaacacf-1
#&amp;gt; ACE             .          .          .          .          .
#&amp;gt; ACE2            .          .          .          .          .
#&amp;gt; ACKR1           .          .          .          .          .
#&amp;gt; ACTR3           1          3          .          .          .
#&amp;gt; ADAM17          .          .          .          .          .&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colData(spe)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; DataFrame with 530893 rows and 18 columns
#&amp;gt;               orig.ident nCount_Xenium nFeature_Xenium
#&amp;gt;                 &amp;lt;factor&amp;gt;     &amp;lt;numeric&amp;gt;       &amp;lt;integer&amp;gt;
#&amp;gt; aaaaaacg-1 SeuratProject           147              80
#&amp;gt; aaaaafen-1 SeuratProject           104              60
#&amp;gt; aaaaanfe-1 SeuratProject            78              56
#&amp;gt; aaaabekh-1 SeuratProject            51              36
#&amp;gt; aaaacacf-1 SeuratProject            46              36
#&amp;gt; ...                  ...           ...             ...
#&amp;gt; oilgiagl-1 SeuratProject           174              82
#&amp;gt; oilgidkk-1 SeuratProject           178              93
#&amp;gt; oilgkofb-1 SeuratProject           109              53
#&amp;gt; oilglapp-1 SeuratProject           183              87
#&amp;gt; oilhbjia-1 SeuratProject            50              39
#&amp;gt;            nCount_NegativeControlCodeword nFeature_NegativeControlCodeword
#&amp;gt;                                 &amp;lt;numeric&amp;gt;                        &amp;lt;integer&amp;gt;
#&amp;gt; aaaaaacg-1                              0                                0
#&amp;gt; aaaaafen-1                              0                                0
#&amp;gt; aaaaanfe-1                              0                                0
#&amp;gt; aaaabekh-1                              0                                0
#&amp;gt; aaaacacf-1                              0                                0
#&amp;gt; ...                                   ...                              ...
#&amp;gt; oilgiagl-1                              0                                0
#&amp;gt; oilgidkk-1                              0                                0
#&amp;gt; oilgkofb-1                              0                                0
#&amp;gt; oilglapp-1                              0                                0
#&amp;gt; oilhbjia-1                              0                                0
#&amp;gt;            nCount_NegativeControlProbe nFeature_NegativeControlProbe nCount_SCT
#&amp;gt;                              &amp;lt;numeric&amp;gt;                     &amp;lt;integer&amp;gt;  &amp;lt;numeric&amp;gt;
#&amp;gt; aaaaaacg-1                           0                             0        125
#&amp;gt; aaaaafen-1                           0                             0        104
#&amp;gt; aaaaanfe-1                           0                             0         86
#&amp;gt; aaaabekh-1                           0                             0         89
#&amp;gt; aaaacacf-1                           0                             0         89
#&amp;gt; ...                                ...                           ...        ...
#&amp;gt; oilgiagl-1                           0                             0        121
#&amp;gt; oilgidkk-1                           0                             0        127
#&amp;gt; oilgkofb-1                           0                             0        109
#&amp;gt; oilglapp-1                           0                             0        123
#&amp;gt; oilhbjia-1                           0                             0         89
#&amp;gt;            nFeature_SCT SCT_snn_res.0.3 seurat_clusters            annotations
#&amp;gt;               &amp;lt;integer&amp;gt;        &amp;lt;factor&amp;gt;        &amp;lt;factor&amp;gt;            &amp;lt;character&amp;gt;
#&amp;gt; aaaaaacg-1           80               3              15           plasma cells
#&amp;gt; aaaaafen-1           60               3              3    M2-like macrophage-2
#&amp;gt; aaaaanfe-1           56               3              8  alveolar epithelial ..
#&amp;gt; aaaabekh-1           36               3              6               mast cell
#&amp;gt; aaaacacf-1           37               3              6               mast cell
#&amp;gt; ...                 ...             ...             ...                    ...
#&amp;gt; oilgiagl-1           77               0               2 ciliated epithelial ..
#&amp;gt; oilgidkk-1           90               0               2 ciliated epithelial ..
#&amp;gt; oilgkofb-1           53               2               1   M2-like macrophage-1
#&amp;gt; oilglapp-1           83               2               1   M2-like macrophage-1
#&amp;gt; oilhbjia-1           39               2               1   M2-like macrophage-1
#&amp;gt;            sub.cluster     cell_id kmeans_cluster    ident   sample_id
#&amp;gt;            &amp;lt;character&amp;gt; &amp;lt;character&amp;gt;      &amp;lt;integer&amp;gt; &amp;lt;factor&amp;gt; &amp;lt;character&amp;gt;
#&amp;gt; aaaaaacg-1          15  aaaaaacg-1             11       15           1
#&amp;gt; aaaaafen-1           3  aaaaafen-1             11       3            1
#&amp;gt; aaaaanfe-1           8  aaaaanfe-1             11       8            1
#&amp;gt; aaaabekh-1           6  aaaabekh-1             11       6            1
#&amp;gt; aaaacacf-1           6  aaaacacf-1             11       6            1
#&amp;gt; ...                ...         ...            ...      ...         ...
#&amp;gt; oilgiagl-1           2  oilgiagl-1              3        2           1
#&amp;gt; oilgidkk-1           2  oilgidkk-1              3        2           1
#&amp;gt; oilgkofb-1           1  oilgkofb-1              4        1           1
#&amp;gt; oilglapp-1           1  oilglapp-1              4        1           1
#&amp;gt; oilhbjia-1           1  oilhbjia-1              4        1           1
#&amp;gt;            in_tissue
#&amp;gt;            &amp;lt;numeric&amp;gt;
#&amp;gt; aaaaaacg-1         1
#&amp;gt; aaaaafen-1         1
#&amp;gt; aaaaanfe-1         1
#&amp;gt; aaaabekh-1         1
#&amp;gt; aaaacacf-1         1
#&amp;gt; ...              ...
#&amp;gt; oilgiagl-1         1
#&amp;gt; oilgidkk-1         1
#&amp;gt; oilgkofb-1         1
#&amp;gt; oilglapp-1         1
#&amp;gt; oilhbjia-1         1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spe$seurat_clusters %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 15 3  8  6  6  6 
#&amp;gt; Levels: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spatialCoords(spe)[1:5, ]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;      Cell.X.Position Cell.Y.Position
#&amp;gt; [1,]        366.5239        849.1828
#&amp;gt; [2,]        364.5222        863.8438
#&amp;gt; [3,]        381.3140        863.7556
#&amp;gt; [4,]        388.0256        864.1576
#&amp;gt; [5,]        394.2588        869.2458&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;average_minimum_distance(spe)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] 10.12947&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic()
spe &amp;lt;- identify_neighborhoods(
  spe, method = &amp;quot;dbscan&amp;quot;, min_neighborhood_size = 100,
  cell_types_of_interest = annotations, radius = 50, 
  feature_colname = &amp;quot;annotations&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-32-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 18.81 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It adds a new column of the niche ID in the &lt;code&gt;colData&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colData(spe) %&amp;gt;% head(n = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; DataFrame with 3 rows and 20 columns
#&amp;gt;       Cell.ID    orig.ident nCount_Xenium nFeature_Xenium
#&amp;gt;   &amp;lt;character&amp;gt;      &amp;lt;factor&amp;gt;     &amp;lt;numeric&amp;gt;       &amp;lt;integer&amp;gt;
#&amp;gt; 1  aaaaaacg-1 SeuratProject           147              80
#&amp;gt; 2  aaaaafen-1 SeuratProject           104              60
#&amp;gt; 3  aaaaanfe-1 SeuratProject            78              56
#&amp;gt;   nCount_NegativeControlCodeword nFeature_NegativeControlCodeword
#&amp;gt;                        &amp;lt;numeric&amp;gt;                        &amp;lt;integer&amp;gt;
#&amp;gt; 1                              0                                0
#&amp;gt; 2                              0                                0
#&amp;gt; 3                              0                                0
#&amp;gt;   nCount_NegativeControlProbe nFeature_NegativeControlProbe nCount_SCT
#&amp;gt;                     &amp;lt;numeric&amp;gt;                     &amp;lt;integer&amp;gt;  &amp;lt;numeric&amp;gt;
#&amp;gt; 1                           0                             0        125
#&amp;gt; 2                           0                             0        104
#&amp;gt; 3                           0                             0         86
#&amp;gt;   nFeature_SCT SCT_snn_res.0.3 seurat_clusters            annotations
#&amp;gt;      &amp;lt;integer&amp;gt;        &amp;lt;factor&amp;gt;        &amp;lt;factor&amp;gt;            &amp;lt;character&amp;gt;
#&amp;gt; 1           80               3              15           plasma cells
#&amp;gt; 2           60               3              3    M2-like macrophage-2
#&amp;gt; 3           56               3              8  alveolar epithelial ..
#&amp;gt;   sub.cluster     cell_id kmeans_cluster    ident   sample_id in_tissue
#&amp;gt;   &amp;lt;character&amp;gt; &amp;lt;character&amp;gt;      &amp;lt;integer&amp;gt; &amp;lt;factor&amp;gt; &amp;lt;character&amp;gt; &amp;lt;numeric&amp;gt;
#&amp;gt; 1          15  aaaaaacg-1             11       15           1         1
#&amp;gt; 2           3  aaaaafen-1             11       3            1         1
#&amp;gt; 3           8  aaaaanfe-1             11       8            1         1
#&amp;gt;   Neighborhood
#&amp;gt;    &amp;lt;character&amp;gt;
#&amp;gt; 1    Cluster_1
#&amp;gt; 2    Cluster_1
#&amp;gt; 3    Cluster_1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;plot the cell type composition:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;neighorhoods_vis &amp;lt;- 
  composition_of_neighborhoods(spe, feature_colname = &amp;quot;annotations&amp;quot;)

neighorhoods_vis &amp;lt;- 
  neighorhoods_vis[neighorhoods_vis$Total_number_of_cells &amp;gt;=5,]

plot_composition_heatmap(neighorhoods_vis,
                         feature_colname=&amp;quot;annotations&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-08-08-neighborhood-cellular-niches-analysis-with-spatial-transcriptome-data-in-seurat-and-bioconductor_files/figure-html/unnamed-chunk-34-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is no parameters exposed to fine-tune the number of neighborhoods with &lt;code&gt;dbscan&lt;/code&gt; in the &lt;code&gt;identify_neighborhoods&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;There are many other functions you can use from the &lt;code&gt;SPAIT&lt;/code&gt; package. Make sure you go through the tutorial.&lt;/p&gt;
&lt;p&gt;That’s it for today! Happy Learning.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>scRNAseq clustering significance test: an unsolvable problem?</title>
      <link>/post/scrnaseq-clustering-significant-test-an-unsolvable-problem/</link>
      <pubDate>Sun, 23 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/scrnaseq-clustering-significant-test-an-unsolvable-problem/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introductioon&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introductioon&lt;/h3&gt;
&lt;p&gt;In scRNA-seq data analysis, one of the most crucial and demanding tasks is determining the optimal resolution and cluster number. Achieving an appropriate balance between over-clustering and under-clustering is often intricate, as it directly impacts the identification of distinct cell populations and biological insights.&lt;/p&gt;
&lt;p&gt;The clustering algorithms have many parameters to tune and it can generate more clusters if e.g., you increase the &lt;code&gt;resolution&lt;/code&gt; parameter. However, whether the newly generated clusters are meaningful or not is a question.&lt;/p&gt;
&lt;p&gt;I previously published a tool &lt;a href=&#34;https://github.com/crazyhottommy/scclusteval&#34;&gt;scclusteval&lt;/a&gt; trying to help with this problem.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;testing-scrnaseq-clustering-significance&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Testing scRNAseq clustering significance&lt;/h3&gt;
&lt;p&gt;Several days ago, I saw this paper came out &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/37429993/&#34;&gt;Significance analysis for clustering with single-cell RNA-sequencing data&lt;/a&gt; in &lt;em&gt;Nature Methods&lt;/em&gt;. I am eager to give it a try.&lt;/p&gt;
&lt;p&gt;The biorxiv version can be found at &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2022.08.01.502383v1&#34; class=&#34;uri&#34;&gt;https://www.biorxiv.org/content/10.1101/2022.08.01.502383v1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The idea is based on the &lt;a href=&#34;https://github.com/pkimes/sigclust2&#34; class=&#34;uri&#34;&gt;https://github.com/pkimes/sigclust2&lt;/a&gt; which test significant clusters in hierarchical clustering.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;However, it assumes an underlying parametric distribution for the data, specifically Gaussian distributions, where distinct populations have different centers. A given set of clusters can then be assessed in a formal and statistically rigorous manner by asking whether or not these clusters could have plausibly arisen under data from a single Gaussian distribution. If so, then the set of clusters likely indicates over-clustering.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Significance of Hierarchical Clustering (SHC) addresses this limitation by incorporating hypothesis testing within the hierarchical procedure. However, SHC is not directly applicable to scRNA-seq data due to the Gaussian distributional assumption, which is inappropriate for these sparse count data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/igrabski/sc-SHC&#34;&gt;&lt;code&gt;scSHC&lt;/code&gt;&lt;/a&gt; implements the significance testing extending to single cell data which is sparse. It models the counts with poisson distribution and use a permutation test to test the significance for the testing statistics: &lt;code&gt;Silhouette width&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To calculate a Silhouette width score for a member of a cluster, you first calculate the average within cluster distances &lt;code&gt;C(i)&lt;/code&gt; and the average closest neighbor distance &lt;code&gt;N(i)&lt;/code&gt; and use the formula shown in Figure 1 to calculate &lt;code&gt;S(i)&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:unnamed-chunk-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/img/sihouette1.png&#34; alt=&#34;Silhouette width&#34; width=&#34;100%&#34; /&gt;&lt;img src=&#34;/img/silhouette2.png&#34; alt=&#34;Silhouette width&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Silhouette width
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;Silhouette width&lt;/code&gt; ranges from -1 to 1. 1 means that member is perfectly match to the cluster it was assigned to. -1 means that member should be placed in the neighboring cluster.&lt;/p&gt;
&lt;p&gt;Then, one does hypothesis testing by first stating the null hypothesis:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;H0: there is only one cluster&lt;/li&gt;
&lt;li&gt;H1: there are two clusters&lt;/li&gt;
&lt;/ul&gt;
The figure below shows two scenarios:
&lt;div class=&#34;figure&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:unnamed-chunk-3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/img/scHSC.png&#34; alt=&#34;significance test by permutation&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: significance test by permutation
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The first scenario is that the truth is 2 clusters and we identified two clusters by clustering algorithms. The second scenario is that the truth is only 1 cluster but we also identified two clusters by clustering algorithms.&lt;/p&gt;
&lt;p&gt;Under the null hypothesis, one can estimate the distribution parameters and simulate the same distribution by e.g., 100 times and for each time, calculate the Silhouette width for all cells. we plot the simulated average silhouette width (for all cells) as a histogram and then compare the observed silhouette width in the data.&lt;/p&gt;
&lt;p&gt;For the two scenarios, we choose a significance level alpha = 0.05.&lt;/p&gt;
&lt;p&gt;In the first scenario, the observed silhouette width is greater than all the simulated silhouette width, so we reject the null and accept the alternative: there are two clusters.&lt;/p&gt;
&lt;p&gt;In the second scenario, out of 100 permutations, 33 times of the permutation based silhouette score is greater than observed one, so the p-value is &lt;code&gt;33/100 = 0.33&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It is greater than &lt;code&gt;0.05&lt;/code&gt;, so we fail to reject the null and accept that there is only one cluster in the data.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;scSHC&lt;/code&gt; tests the clustering significance at every splitting point hierarchically.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;install-the-package&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;install the package&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# dependency
BiocManager::install(&amp;quot;scry&amp;quot;)
devtools::install_github(&amp;quot;igrabski/sc-SHC&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Load the libraries&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(scSHC)
library(dplyr)
library(Seurat)
library(scCustomize)
library(patchwork)
library(ggplot2)
library(ComplexHeatmap)
library(SeuratData)
set.seed(1234)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;pbmc3k&amp;quot;)

pbmc3k&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; An object of class Seurat 
#&amp;gt; 13714 features across 2700 samples within 1 assay 
#&amp;gt; Active assay: RNA (13714 features, 0 variable features)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;routine-processing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;routine processing&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbmc3k&amp;lt;- pbmc3k %&amp;gt;% 
  NormalizeData(normalization.method = &amp;quot;LogNormalize&amp;quot;, scale.factor = 10000) %&amp;gt;%
  FindVariableFeatures(selection.method = &amp;quot;vst&amp;quot;, nfeatures = 2000) %&amp;gt;%
  ScaleData() %&amp;gt;%
  RunPCA(verbose = FALSE) %&amp;gt;%
  FindNeighbors(dims = 1:10, verbose = FALSE) %&amp;gt;%
  FindClusters(resolution = 0.5, verbose = FALSE) %&amp;gt;%
  RunUMAP(dims = 1:10, verbose = FALSE)

pbmc3k&amp;lt;- pbmc3k[, !is.na(pbmc3k$seurat_annotations)]

p1&amp;lt;- DimPlot_scCustom(pbmc3k, reduction = &amp;quot;umap&amp;quot;, label = TRUE, group.by = 
                        &amp;quot;RNA_snn_res.0.5&amp;quot;)

p2&amp;lt;- DimPlot_scCustom(pbmc3k, reduction = &amp;quot;umap&amp;quot;, label = TRUE, group.by = &amp;quot;seurat_annotations&amp;quot;, label.size = 3)

p1 + p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-07-23-scrnaseq-clustering-significant-test-an-unsolvable-problem_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;768&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;janitor::tabyl(pbmc3k@meta.data, seurat_annotations, RNA_snn_res.0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  seurat_annotations   0   1   2   3   4   5   6  7  8
#&amp;gt;         Naive CD4 T 608   0  66   0  23   0   0  0  0
#&amp;gt;        Memory CD4 T  69   0 396   0  16   0   2  0  0
#&amp;gt;          CD14+ Mono   0 472   0   0   0   3   0  4  1
#&amp;gt;                   B   0   0   0 343   1   0   0  0  0
#&amp;gt;               CD8 T   2   0   3   0 265   0   1  0  0
#&amp;gt;        FCGR3A+ Mono   0   7   0   0   0 155   0  0  0
#&amp;gt;                  NK   0   0   0   0  16   0 139  0  0
#&amp;gt;                  DC   0   0   0   0   0   0   0 32  0
#&amp;gt;            Platelet   0   0   0   0   0   0   0  0 14&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s artificially increase the resolution (to 1) to over-cluster it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## artificially increase the resolution
pbmc3k&amp;lt;- pbmc3k %&amp;gt;%
  FindNeighbors(dims = 1:10, verbose = FALSE) %&amp;gt;%
  FindClusters(resolution = 1, verbose = FALSE) 


p3&amp;lt;- DimPlot_scCustom(pbmc3k, reduction = &amp;quot;umap&amp;quot;, label = TRUE, group.by = &amp;quot;RNA_snn_res.1&amp;quot;)

(p1 + p3) / p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-07-23-scrnaseq-clustering-significant-test-an-unsolvable-problem_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;768&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;CD4 naive cell cluster is split to 2 clusters (0 -&amp;gt; 0, 5)
the CD14+ monocyte cluster is split into 2 clusters (1 -&amp;gt; 4, 6)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;janitor::tabyl(pbmc3k@meta.data, RNA_snn_res.1, RNA_snn_res.0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  RNA_snn_res.1   0   1   2   3   4   5   6  7  8
#&amp;gt;              0 470   0  49   0   0   0   0  0  0
#&amp;gt;              1   3   0 413   0   1   0   0  0  0
#&amp;gt;              2   0   0   0 343   0   0   0  0  0
#&amp;gt;              3   0   0   0   0 279   0   0  0  0
#&amp;gt;              4   0 262   0   0   0   1   0  0  0
#&amp;gt;              5 206   0   3   0  41   0   0  0  0
#&amp;gt;              6   0 217   0   0   0   0   0  0  1
#&amp;gt;              7   0   0   0   0   0 157   0  0  0
#&amp;gt;              8   0   0   0   0   0   0 142  0  0
#&amp;gt;              9   0   0   0   0   0   0   0 36  0
#&amp;gt;             10   0   0   0   0   0   0   0  0 14&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;use-scshc-to-do-the-clustering&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;use scSHC to do the clustering&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tictoc)

tic()
clusters&amp;lt;- scSHC(pbmc3k@assays$RNA@counts, cores = 6,
                 num_PCs = 30,
                 num_features = 2000)
toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 162.082 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;visualize the data&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;scSHC&lt;/code&gt; output is a list of 2 elements, the first element contains the cluster id for each cell and the second element contains&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(clusters[[1]])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; 
#&amp;gt;   1   2   3   4   5   6   7   8 
#&amp;gt; 448 105 130 154 521 334 426 520&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the second 
clusters[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                       levelName
#&amp;gt; 1  Node 0: 0                   
#&amp;gt; 2   ¦--Node 1: 0               
#&amp;gt; 3   ¦   ¦--Node 3: 0           
#&amp;gt; 4   ¦   ¦   ¦--Cluster 2: 1    
#&amp;gt; 5   ¦   ¦   °--Cluster 3: 1    
#&amp;gt; 6   ¦   °--Cluster 1: 1        
#&amp;gt; 7   °--Node 2: 0               
#&amp;gt; 8       ¦--Node 4: 0           
#&amp;gt; 9       ¦   ¦--Cluster 4: 1    
#&amp;gt; 10      ¦   °--Cluster 5: 1    
#&amp;gt; 11      °--Node 5: 0           
#&amp;gt; 12          ¦--Cluster 6: 1    
#&amp;gt; 13          °--Node 6: 0.01    
#&amp;gt; 14              ¦--Cluster 7: 1
#&amp;gt; 15              °--Cluster 8: 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clusters[[1]] %&amp;gt;%
  tibble::enframe() %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 6 × 2
#&amp;gt;   name           value
#&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
#&amp;gt; 1 AAACATACAACCAC     5
#&amp;gt; 2 AAACATTGAGCTAC     6
#&amp;gt; 3 AAACATTGATCAGC     5
#&amp;gt; 4 AAACCGTGCTTCCG     3
#&amp;gt; 5 AAACCGTGTATGCG     4
#&amp;gt; 6 AAACGCACTGGTAC     5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scSHC_clusters&amp;lt;- clusters[[1]] %&amp;gt;%
  tibble::enframe(name = &amp;quot;barcode&amp;quot;, value = &amp;quot;scSHC_clusters&amp;quot;)

scSHC_clusters&amp;lt;- as.data.frame(scSHC_clusters)
rownames(scSHC_clusters)&amp;lt;- scSHC_clusters$barcode
head(scSHC_clusters)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                       barcode scSHC_clusters
#&amp;gt; AAACATACAACCAC AAACATACAACCAC              5
#&amp;gt; AAACATTGAGCTAC AAACATTGAGCTAC              6
#&amp;gt; AAACATTGATCAGC AAACATTGATCAGC              5
#&amp;gt; AAACCGTGCTTCCG AAACCGTGCTTCCG              3
#&amp;gt; AAACCGTGTATGCG AAACCGTGTATGCG              4
#&amp;gt; AAACGCACTGGTAC AAACGCACTGGTAC              5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;add the scSHC cluster to the seurat metadata slot&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbmc3k&amp;lt;- AddMetaData(pbmc3k, metadata = scSHC_clusters)
pbmc3k@meta.data %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;                orig.ident nCount_RNA nFeature_RNA seurat_annotations
#&amp;gt; AAACATACAACCAC     pbmc3k       2419          779       Memory CD4 T
#&amp;gt; AAACATTGAGCTAC     pbmc3k       4903         1352                  B
#&amp;gt; AAACATTGATCAGC     pbmc3k       3147         1129       Memory CD4 T
#&amp;gt; AAACCGTGCTTCCG     pbmc3k       2639          960         CD14+ Mono
#&amp;gt; AAACCGTGTATGCG     pbmc3k        980          521                 NK
#&amp;gt; AAACGCACTGGTAC     pbmc3k       2163          781       Memory CD4 T
#&amp;gt;                RNA_snn_res.0.5 seurat_clusters RNA_snn_res.1        barcode
#&amp;gt; AAACATACAACCAC               0               5             5 AAACATACAACCAC
#&amp;gt; AAACATTGAGCTAC               3               2             2 AAACATTGAGCTAC
#&amp;gt; AAACATTGATCAGC               2               1             1 AAACATTGATCAGC
#&amp;gt; AAACCGTGCTTCCG               5               7             7 AAACCGTGCTTCCG
#&amp;gt; AAACCGTGTATGCG               6               8             8 AAACCGTGTATGCG
#&amp;gt; AAACGCACTGGTAC               2               1             1 AAACGCACTGGTAC
#&amp;gt;                scSHC_clusters
#&amp;gt; AAACATACAACCAC              5
#&amp;gt; AAACATTGAGCTAC              6
#&amp;gt; AAACATTGATCAGC              5
#&amp;gt; AAACCGTGCTTCCG              3
#&amp;gt; AAACCGTGTATGCG              4
#&amp;gt; AAACGCACTGGTAC              5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(rownames(pbmc3k@meta.data), unname(pbmc3k$barcode))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;plotting&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p4&amp;lt;- DimPlot_scCustom(pbmc3k, group.by = &amp;quot;scSHC_clusters&amp;quot;)

(p2 + p4) / (p1 + p3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2023-07-23-scrnaseq-clustering-significant-test-an-unsolvable-problem_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;768&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;janitor::tabyl(pbmc3k@meta.data, seurat_annotations, scSHC_clusters)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt;  seurat_annotations   1   2  3   4   5   6   7   8
#&amp;gt;         Naive CD4 T   0   0  0   0  80   0 150 467
#&amp;gt;        Memory CD4 T   0   0  0   0 161   0 274  48
#&amp;gt;          CD14+ Mono 398   1 81   0   0   0   0   0
#&amp;gt;                   B   0   0  0   0   8 334   1   1
#&amp;gt;               CD8 T   0   0  0  11 255   0   1   4
#&amp;gt;        FCGR3A+ Mono   9 104 49   0   0   0   0   0
#&amp;gt;                  NK   0   0  0 143  12   0   0   0
#&amp;gt;                  DC  29   0  0   0   3   0   0   0
#&amp;gt;            Platelet  12   0  0   0   2   0   0   0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What surprises me is that &lt;code&gt;scSHC&lt;/code&gt; does not separate the CD14+ monocytes and the dendritic cells. (cluster 1 is a mix of CD14+ monocytes, DCs and platelet)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;conclusions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;One may fine tune &lt;code&gt;num_features&lt;/code&gt; and &lt;code&gt;num_PCs&lt;/code&gt; to get a better results. My conclusion is that although it seems statistically attractive, significance testing for scRNAseq clustering is still an unsolved problem. Cell type or cell state is inherently complicated and sometimes in a continuum.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Also, we do not have a ground truth here. The Seurat cell annotations provided by the developers may not be 100% correct.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It took ~3mins using 6 CPUs for 3000 cells. It can take long time if you have a lot of cells and many clusters as &lt;code&gt;scSHC&lt;/code&gt; test the cluster significance at every splitting node.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;further-reading&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Further reading&lt;/h3&gt;
&lt;p&gt;what is a cell type? &lt;a href=&#34;https://twitter.com/tangming2005/status/1680932947619201025&#34; class=&#34;uri&#34;&gt;https://twitter.com/tangming2005/status/1680932947619201025&lt;/a&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0092867422007838&#34;&gt;A reference cell tree will serve science better than a reference cell atlas&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0092867422007838&#34;&gt;What is a cell type, and how to define it?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://journals.biologists.com/dev/article/146/12/dev169748/19444/The-evolving-concept-of-cell-identity-in-the&#34;&gt;The evolving concept of cell identity in the single cell era&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://journals.biologists.com/dev/article/146/12/dev169854/19451/A-periodic-table-of-cell-types&#34;&gt;A periodic table of cell types&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bonus, a blog post by &lt;a href=&#34;https://twitter.com/Matthew_N_B&#34;&gt;Matthew Bernstein&lt;/a&gt;
On cell types and cell states &lt;a href=&#34;https://mbernste.github.io/posts/cell_types_cell_states/&#34; class=&#34;uri&#34;&gt;https://mbernste.github.io/posts/cell_types_cell_states/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Dissecting myeloid and T cells interaction niches in the TME using spatial transcriptome </title>
      <link>/talk/2023-myeloid-talk/</link>
      <pubDate>Mon, 17 Jul 2023 12:00:00 -0400</pubDate>
      
      <guid>/talk/2023-myeloid-talk/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;/img/myeloid_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/myeloid_2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
